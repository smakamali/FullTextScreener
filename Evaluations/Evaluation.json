{
  "ALECE An Attention-based Learned Cardinality Estimator for SPJ Queries on Dynamic Workloads.pdf.json": {
    "metadata": {
      "paper_id": "15",
      "pdf_filename": "ALECE An Attention-based Learned Cardinality Estimator for SPJ Queries on Dynamic Workloads.pdf",
      "title": "ALECE: An Attention-based Learned Cardinality Estimator for SPJ Queries on Dynamic Workloads",
      "authors": "Pengfei Li, Wenqing Wei, Rong Zhu, Bolin Ding, Jingren Zhou, and Hua Lu",
      "year": "2023"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The query engine tool provided the answer 'No'.",
        "Evidence": "Not Applicable"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "The study implicitly define robustness to being less sensitive to data changes.",
        "Reasoning": "The query engine tool provided the answer 'Not provided'.",
        "Evidence": "Not Applicable"
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "No Definitions Provided",
        "correct_short_answer": "cardinality estimation",
        "Reasoning": "The query engine tool provided the answer 'No Definitions Provided'.",
        "Evidence": "Not Applicable"
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study mentions that ALECE is designed to handle dynamic workloads, which include queries, inserts, deletes, and updates. This indicates that the model is intended to be robust in the context of query optimization and processing.",
        "Evidence": "In addition, existing models have a more critical problem: They do not perform well on dynamic workloads that mix queries and data manipulation statements including inserts, deletes and updates. Such statements tend to make estimations difficult as they influence the data distribution and shift the mapping between queries and true cardinalities. When the underlying data changes, the joint data distributions among relations and attributes as well as the mapping between queries and true cardinalities also become different. Thus, pure data- or query-driven methods can hardly work on dynamic workloads."
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The paper introduces ALECE, an attention-based learned cardinality estimator for SPJ queries on dynamic workloads. This model combines data and query-driven methods to improve cardinality estimation, which is a significant contribution to the theory of cardinality estimation in database management systems.",
        "Evidence": "ALECE is designed to be a \u2018whitebox\u2019 which not only gives estimates but also clear rationales to integrate the SPJ queries and underlying data together in processing dynamic workloads. We experimentally validate ALECE\u2019s advantages over more than half dozen representative alternatives on real datasets."
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study mentions that it experimentally validates ALECE's advantages over more than half dozen representative alternatives on real datasets. This indicates a significant experimental evaluation.",
        "Evidence": "ALECE is designed to be a \u2018whitebox\u2019 which not only gives estimates but also clear rationales to integrate the SPJ queries and underlying data together in processing dynamic workloads. We experimentally validate ALECE\u2019s advantages over more than half dozen representative alternatives on real datasets."
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "correct_short_answer": "experimental evaluation",
        "Reasoning": "The study mentions that it experimentally validates ALECE's advantages over more than half dozen representative alternatives on real datasets. This indicates that the evaluation of robustness and its improvements is done through experimental evaluation.",
        "Evidence": "ALECE is designed to be a \u2018whitebox\u2019 which not only gives estimates but also clear rationales to integrate the SPJ queries and underlying data together in processing dynamic workloads. We experimentally validate ALECE\u2019s advantages over more than half dozen representative alternatives on real datasets."
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "a summary of the proposed approach",
        "correct_short_answer": "The study improve robustness by using an attention-based estimator that featurizes the evolving database as updatable histograms (DB states), applies self-attention to capture joint attribute distributions, and uses cross-attention with query features, thus adapting estimates immediately when data changes.",
        "Reasoning": "The study improves robustness by introducing ALECE, an attention-based learned cardinality estimator that combines data and query-driven methods to handle dynamic workloads. This approach allows the model to adapt to changes in data distribution and query patterns, thereby enhancing its robustness.",
        "Evidence": "In addition, existing models have a more critical problem: They do not perform well on dynamic workloads that mix queries and data manipulation statements including inserts, deletes and updates. Such statements tend to make estimations difficult as they influence the data distribution and shift the mapping between queries and true cardinalities. When the underlying data changes, the joint data distributions among relations and attributes as well as the mapping between queries and true cardinalities also become different. Thus, pure data- or query-driven methods can hardly work on dynamic workloads."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "End-to-end query execution time, Q-error, and P-error under dynamic (including distribution-shift) workloads.",
        "Reasoning": "The study does not explicitly mention any specific measures used to evaluate robustness.",
        "Evidence": "Not Applicable"
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": ["STATS", "Joblight", "TPC-H"],
        "Reasoning": "The study does not explicitly mention any specific benchmarks used in the experimental evaluations.",
        "Evidence": "Not Applicable"
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Real",
        "correct_short_answer": "Both",
        "Reasoning": "The study mentions that it experimentally validates ALECE's advantages on real datasets.",
        "Evidence": "ALECE is designed to be a \u2018whitebox\u2019 which not only gives estimates but also clear rationales to integrate the SPJ queries and underlying data together in processing dynamic workloads. We experimentally validate ALECE\u2019s advantages over more than half dozen representative alternatives on real datasets."
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "Ratios of inserts/deletes/updates (2:1:1 for Insert-heavy, 1:1:2 for Update-heavy), and skewed distribution of inserted records in the Dist-shift workload. ",
        "Reasoning": "The study does not explicitly mention any specific characteristics controlled in training data, query, or plan generation.",
        "Evidence": "Not Applicable"
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study mentions that ALECE is designed to handle dynamic workloads, which include queries, inserts, deletes, and updates. This indicates that the experiments are designed to evaluate the model's robustness in handling such dynamic workloads.",
        "Evidence": "In addition, existing models have a more critical problem: They do not perform well on dynamic workloads that mix queries and data manipulation statements including inserts, deletes and updates. Such statements tend to make estimations difficult as they influence the data distribution and shift the mapping between queries and true cardinalities. When the underlying data changes, the joint data distributions among relations and attributes as well as the mapping between queries and true cardinalities also become different. Thus, pure data- or query-driven methods can hardly work on dynamic workloads."
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study introduces ALECE, an attention-based learned cardinality estimator, which is a machine learning model designed to improve cardinality estimation for SPJ queries on dynamic workloads.",
        "Evidence": "In this paper, we propose ALECE, an attention-based learned cardinality estimator for SPJ queries on dynamic workloads."
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Supervised",
        "correct_short_answer": "Supervised",
        "Reasoning": "The study mentions that ALECE is trained on a dataset of queries and their true cardinalities, which indicates that it uses supervised learning.",
        "Evidence": "ALECE is designed to be a \u2018whitebox\u2019 which not only gives estimates but also clear rationales to integrate the SPJ queries and underlying data together in processing dynamic workloads. We experimentally validate ALECE\u2019s advantages over more than half dozen representative alternatives on real datasets."
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Regression",
        "correct_short_answer": "Regression",
        "Reasoning": "The study focuses on cardinality estimation, which is a regression problem where the model predicts a continuous value (cardinality) based on input features.",
        "Evidence": "In this paper, we propose ALECE, an attention-based learned cardinality estimator for SPJ queries on dynamic workloads."
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study mentions that ALECE is an attention-based learned cardinality estimator, which indicates the use of deep learning techniques.",
        "Evidence": "In this paper, we propose ALECE, an attention-based learned cardinality estimator for SPJ queries on dynamic workloads."
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The study does not mention the use of transfer learning in the proposed approach.",
        "Evidence": "Not Applicable"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "The study generate its training data by executing a historical stream of queries (with intervening inserts/deletes/updates), updating the DB-state histograms accordingly, and pairing each query\u2019s featurization and current DB states with its true cardinality.",
        "Reasoning": "The study does not explicitly describe the process of generating its training data.",
        "Evidence": "Not Applicable"
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "Data are encoded as fixed-dimensional histograms per attribute (DB states); queries are encoded by concatenating join-predicate bit-vectors and filter-range boundary vectors.",
        "Reasoning": "The study does not explicitly describe the process of encoding the samples.",
        "Evidence": "Not Applicable"
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The study does not mention accounting for predictive uncertainties in its approach.",
        "Evidence": "Not Applicable"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "Unsure",
        "correct_short_answer": "Yes",
        "Reasoning": "The query engine tool provided the answer 'Unsure'.",
        "Evidence": "Not Applicable"
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "No",
        "correct_short_answer": "Yes",
        "Reasoning": "The study does not mention evaluating generalization to out-of-distribution in its approach.",
        "Evidence": "Not Applicable"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Transformer (Trm)",
        "correct_short_answer": "Transformer (Trm)",
        "Reasoning": "The study proposes ALECE, an attention-based learned cardinality estimator, which indicates the use of a Transformer architecture.",
        "Evidence": "In this paper, we propose ALECE, an attention-based learned cardinality estimator for SPJ queries on dynamic workloads."
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "No",
        "Reasoning": "The study mentions that ALECE is designed to handle dynamic workloads, which include queries, inserts, deletes, and updates. This indicates that enhancing robustness was a primary motivation behind the model design.",
        "Evidence": "In addition, existing models have a more critical problem: They do not perform well on dynamic workloads that mix queries and data manipulation statements including inserts, deletes and updates. Such statements tend to make estimations difficult as they influence the data distribution and shift the mapping between queries and true cardinalities. When the underlying data changes, the joint data distributions among relations and attributes as well as the mapping between queries and true cardinalities also become different. Thus, pure data- or query-driven methods can hardly work on dynamic workloads."
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "Not provided",
        "Reasoning": "The study does not explicitly mention any other techniques used for improving robustness.",
        "Evidence": "Not Applicable"
      }
    }
  },
  "Balsa Learning a Query Optimizer Without Expert.pdf.json": {
    "metadata": {
      "paper_id": "19",
      "pdf_filename": "Balsa Learning a Query Optimizer Without Expert.pdf",
      "title": "Balsa: Learning a Query Optimizer Without Expert Demonstrations",
      "authors": "Yang, Zongheng and Chiang, Wei-Lin and Luan, Sifei and Mittal, Gautam and Luo, Michael and Stoica, Ion",
      "year": "2022"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not introduce any new definitions for robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "The study defines robustness implicitly as the ability of the Balsa system to generalize well to unseen queries, despite not learning from an expert optimizer.",
        "Reasoning": "The study does not provide an explicit definition of robustness but implies it through the performance and capabilities of the Balsa system.",
        "Evidence": "To our knowledge, Balsa is the first approach to show that learning an optimizer without expert demonstrations is both possible and efficient. Balsa learns by iteratively planning a given set of queries, executing them, and learning from their latencies to build better execution plans in the future. To make learning practical, Balsa must avoid disastrous plans that can dramatically hinder learning. We address this key challenge with three simple techniques: bootstrapping from a simulator, safe execution, and safe exploration. Balsa paves the road towards automatically learning a query optimizer tailored to a workload and a compute environment. New data systems may have execution models or objectives that go beyond our knowledge of query optimization. By learning on its own and not learning from an expert system, Balsa may alleviate the significant optimizer development cost for systems yet to be developed. Balsa is a first step towards this exciting direction.",
        "correct_short_answer": "Robustness is implicitly defined as the ability of a learned query optimizer to consistently generalize well to unseen queries with stable performance. The authors particularly emphasize robustness as maintaining good performance when faced with queries that have different join templates, predicates, or characteristics from those seen during training."
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "No Definitions Provided",
        "Reasoning": "The study does not provide any new definitions for robustness or risk.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions the robustness of Balsa in the context of query optimization and processing. For example, it states that 'Balsa is much more robust' and 'Balsa consistently generates faster plans than the expert for unseen queries, with a 2\u00d7 maximum speedup.' This indicates that the study addresses the problem of robustness.",
        "Evidence": "In contrast, Balsa is much more robust. Balsa consistently generates faster plans than the expert for unseen queries, with a 2\u00d7 maximum speedup.",
        "correct_short_answer": "Yes"
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper introduces Balsa, a learned query optimizer that does not rely on an existing expert optimizer. This approach demonstrates for the first time that learning to optimize queries without expert demonstrations is both possible and efficient. This contribution is significant as it paves the way towards automatically learning to optimize in new data systems where a mature optimizer does not exist.",
        "Evidence": "To our knowledge, Balsa demonstrates for the first time that learning to optimize queries without learning from an expert optimizer is both possible and efficient. This can have a far-reaching impact, as it paves the road towards automatically learning to optimize in new data systems [19,20] where a mature optimizer does not exist.",
        "correct_short_answer": "No"
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study includes a comprehensive experimental evaluation, comparing Balsa against several baselines and expert optimizers across various workloads and datasets. The results demonstrate Balsa's ability to generalize well to unseen queries and its robustness in different scenarios.",
        "Evidence": "We compare Balsa against several baselines and expert optimizers across various workloads and datasets. We show that Balsa can generalize well to unseen queries and is robust in different scenarios.",
        "correct_short_answer": "Yes"
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation. It compares Balsa against several baselines and expert optimizers across various workloads and datasets, demonstrating Balsa's ability to generalize well to unseen queries and its robustness in different scenarios.",
        "Evidence": "We compare Balsa against several baselines and expert optimizers across various workloads and datasets. We show that Balsa can generalize well to unseen queries and is robust in different scenarios.",
        "correct_short_answer": "experimental evaluation"
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "a summary of the proposed approach",
        "Reasoning": "The study improves robustness through the Balsa system, which learns to optimize queries without relying on an expert optimizer. Balsa uses techniques such as bootstrapping from a simulator, safe execution, and safe exploration to avoid disastrous plans and improve learning efficiency.",
        "Evidence": "To make learning practical, Balsa must avoid disastrous plans that can dramatically hinder learning. We address this key challenge with three simple techniques: bootstrapping from a simulator, safe execution, and safe exploration.",
        "correct_short_answer": "Balsa improves robustness in learned query optimization through five key techniques: (1) simulation-to-reality learning to gain broad plan space coverage before real execution, (2) dynamic timeouts to prevent learning stalls from disastrous plans, (3) safe exploration among only promising plans, (4) merging experiences from multiple independently trained agents to cover diverse optimization strategies, and (5) efficient on-policy learning to maximize plan exploration. These techniques enable Balsa to reliably generalize to unseen queries with different join patterns, even outperforming expert optimizers on challenging workloads."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "a list of the measures used",
        "Reasoning": "The study evaluates robustness using measures such as the ability to generalize well to unseen queries, the consistency in generating faster plans than expert optimizers, and the maximum speedup achieved.",
        "Evidence": "In contrast, Balsa is much more robust. Balsa consistently generates faster plans than the expert for unseen queries, with a 2\u00d7 maximum speedup.",
        "correct_short_answer": [
          "generalization to out-of-distirbution",
          "Runtime variance",
          "tail-end Speedup",
          "performance on challenging workloads"
        ]
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": ["JOB", "TPC-H", "Ext-JOB"],
        "Reasoning": "The study uses the JOB, TPC-H, and Ext-JOB benchmarks for the experimental evaluations.",
        "Evidence": "We evaluate Balsa on three benchmarks: JOB, TPC-H, and Ext-JOB.",
        "correct_short_answer": ["JOB", "TPC-H", "Ext-JOB", "JOB-Slow"]
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Real",
        "Reasoning": "The study uses real benchmarks such as JOB, TPC-H, and Ext-JOB for the experimental evaluations.",
        "Evidence": "We evaluate Balsa on three benchmarks: JOB, TPC-H, and Ext-JOB.",
        "correct_short_answer": "Both"
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in trianing data, query, or plan generation?",
        "ShortAnswer": ["query", "plan"],
        "Reasoning": "The study controls characteristics related to query and plan generation in the training data.",
        "Evidence": "Not Applicable",
        "correct_short_answer": [
          "Number of joins",
          "Join templates",
          "Join patterns",
          "Query execution timeout",
          "Number of explored plans",
          "Beam search parameters",
          "Plan diversity via diversified experiences"
        ]
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "Reasoning": "The experiments are designed to evaluate the robustness of Balsa by comparing it against baselines and expert optimizers across various workloads and datasets. The study demonstrates Balsa's ability to generalize well to unseen queries and its robustness in different scenarios.",
        "Evidence": "We compare Balsa against several baselines and expert optimizers across various workloads and datasets. We show that Balsa can generalize well to unseen queries and is robust in different scenarios.",
        "correct_short_answer": "Yes"
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study uses machine learning in its proposed approach, Balsa, which learns to optimize queries without relying on an expert optimizer.",
        "Evidence": "To our knowledge, Balsa is the first approach to show that learning an optimizer without expert demonstrations is both possible and efficient.",
        "correct_short_answer": "Yes"
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Reinforcement learning",
        "Reasoning": "The study uses reinforcement learning in its proposed approach, Balsa, which learns to optimize queries through iterative planning, execution, and learning from latencies.",
        "Evidence": "Balsa learns by iteratively planning a given set of queries, executing them, and learning from their latencies to build better execution plans in the future.",
        "correct_short_answer": "Reinforcement learning"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Other",
        "Reasoning": "The ML approach used in the study, Balsa, involves learning to optimize queries through iterative planning, execution, and learning from latencies, which does not fit into typical categories like regression or classification.",
        "Evidence": "Balsa learns by iteratively planning a given set of queries, executing them, and learning from their latencies to build better execution plans in the future.",
        "correct_short_answer": "Reinforcement learning"
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "Yes",
        "Reasoning": "The text mentions that Balsa is built by deep reinforcement learning and uses a value network, which is a type of deep learning model.",
        "Evidence": "Balsa learns by iteratively planning a given set of queries, executing them, and learning from their latencies to build better execution plans in the future. ... Balsa learns the real-execution value network, V (query, plan) \u2192 overall latency, using reinforcement learning.",
        "correct_short_answer": "Yes"
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of transfer learning in its approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Yes"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "a description of the data generation process",
        "Reasoning": "The study generates its training data by iteratively planning a given set of queries, executing them, and learning from their latencies to build better execution plans in the future.",
        "Evidence": "Balsa learns by iteratively planning a given set of queries, executing them, and learning from their latencies to build better execution plans in the future.",
        "correct_short_answer": "Balsa generates training data through three main processes: (1) simulation phase using dynamic programming to enumerate possible plans with a minimal cost model, (2) real execution phase by running actual query plans on the database engine and measuring latencies, and (3) diversified experiences by merging data from multiple independently trained agents. Throughout both phases, data augmentation is applied where each subplan generates a training example, while timeouts and safe exploration techniques ensure efficient learning."
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "a description of the encoding process",
        "Reasoning": "The study encodes the samples using a featurization process that converts queries and plans into feature vectors. These feature vectors are then used to train the value network.",
        "Evidence": "We featurize queries and plans into feature vectors and use them to train the value network.",
        "correct_short_answer": "Balsa encodes input samples using two main components: 1) query features represented as a vector mapping tables to their estimated selectivity values (with zeros for absent tables), and 2) plan features encoded using tree convolution networks that capture the hierarchical structure of query plans and their operators. These combined features serve as input to the value network, which is implemented as a tree convolution network with approximately 0.7M parameters."
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention whether it accounts for predictive uncertainties.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "Yes",
        "Reasoning": "The text explicitly mentions 'generalization to out-of-distribution' as a challenge and a criterion for robustness. For example, it states 'This confirms that Ext-JOB is a highly challenging generalization workload' and discusses the performance on out-of-distribution queries.",
        "Evidence": "This confirms that Ext-JOB is a highly challenging generalization workload.",
        "correct_short_answer": "Yes"
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study evaluates generalization to out-of-distribution by testing Balsa on the Ext-JOB workload, which is designed to be a challenging generalization task.",
        "Evidence": "This confirms that Ext-JOB is a highly challenging generalization workload.",
        "correct_short_answer": "Yes"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Tree-Convolutional Neural Network (TCNN)",
        "Reasoning": "The study uses a Tree-Convolutional Neural Network (TCNN) as the model architecture for the proposed method, Balsa.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Tree-Convolutional Neural Network (TCNN)"
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "No",
        "Reasoning": "The primary motivation behind the model or encoding scheme design in the paper is to learn a query optimizer without expert demonstrations, focusing on improving performance and generalization rather than enhancing robustness specifically.",
        "Evidence": "Balsa: Learning a Query Optimizer Without Expert Demonstrations",
        "correct_short_answer": "No"
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": [
          "simulation learning",
          "safe execution",
          "safe exploration",
          "diversified experiences",
          "timeout mechanism",
          "on-policy learning"
        ],
        "Reasoning": "The study uses several techniques to improve robustness, including simulation learning, safe execution, safe exploration, diversified experiences, a timeout mechanism, and on-policy learning.",
        "Evidence": "Not Applicable",
        "correct_short_answer": [
          "simulation learning",
          "safe execution",
          "safe exploration",
          "diversified experiences",
          "on-policy learning"
        ]
      }
    }
  },
  "Bao Making Learned Query Optimization Practical.pdf.json": {
    "metadata": {
      "paper_id": "20",
      "pdf_filename": "Bao Making Learned Query Optimization Practical.pdf",
      "title": "Bao: Making Learned Query Optimization Practical",
      "authors": "Ryan Marcus, Parimarjan Negi, Hongzi Mao, Nesime Tatbul, Mohammad Alizadeh, and Tim Kraska",
      "year": "2021"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The study does not introduce any new definitions for robustness.",
        "Evidence": "Not Applicable"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "It implicitly defines robustness as the optimizer\u2019s ability to maintain stable (in particular low tail) query performance by adapting to changes in workload, data, and schema.",
        "Reasoning": "The study does not explicitly define robustness or risk. However, it implicitly discusses risk in terms of 'regret,' which is the difference between the decision Bao selected and the optimal choice. This is mentioned in the context of evaluating Bao's effectiveness as a bandit system.",
        "Evidence": "Not Applicable"
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "No Definitions Provided",
        "correct_short_answer": "No Definitions Provided",
        "Reasoning": "The study does not provide any new definitions for robustness or risk.",
        "Evidence": "Not Applicable"
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions robustness in the context of query optimization and processing. It states that Bao can maintain performance even in the presence of workload, data, and schema changes, which is a key aspect of robustness.",
        "Evidence": "Bao can maintain performance even in the presence of workload, data, and schema changes. Bao does this by leveraging a traditional query optimizer\u2019s cost and cardinality estimates."
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study introduces Bao, a bandit optimizer that combines tree convolutional neural networks with Thompson sampling to improve query optimization. It addresses several fundamental problems in learned query optimization, such as long training times, inability to adapt to changes, tail catastrophe, and black-box decisions. The experimental results demonstrate that Bao can quickly learn strategies that improve end-to-end query execution performance, including tail latency, for several workloads containing long-running queries. Additionally, the study shows that Bao can offer both reduced costs and better performance compared with a commercial system in cloud environments.",
        "Evidence": "Recenteffortsapplyingmachinelearningtechniquestoqueryopti-mizationhaveshownfewpracticalgainsduetosubstantivetrain-ingoverhead,inabilitytoadapttochanges,andpoortailperfor-mance.Motivatedbythesedifficulties,weintroduceBao(theBanditoptimizer).Baotakesadvantageofthewisdombuiltintoexistingqueryoptimizersbyprovidingper-queryoptimizationhints.BaocombinesmoderntreeconvolutionalneuralnetworkswithThomp-sonsampling,awell-studiedreinforcementlearningalgorithm.Asaresult,Baoautomaticallylearnsfromitsmistakesandadaptstochangesinqueryworkloads,data,andschema.Experimentally,wedemonstratethatBaocanquicklylearnstrategiesthatimproveend-to-endqueryexecutionperformance,includingtaillatency,forseveralworkloadscontaininglong-runningqueries.Incloudenvironments,weshowthatBaocanofferbothreducedcostsandbetterperformancecomparedwithacommercialsystem."
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The text explicitly mentions an experimental evaluation in Section 6, where the key question posed is whether Bao could have a positive, practical impact on real-world database workloads. The evaluation includes quantifying query performance and the dollar-cost of executing a workload on cloud infrastructure against PostgreSQL and a commercial database system.",
        "Evidence": "The key question we pose in our evaluation is whether or not Bao could have a positive, practical impact on real-world database workloads that include changes in queries, data, and/or schema. To answer this, we focus on quantifying not only query performance, but also the dollar-cost of executing a workload (including the training overhead introduced by Bao) on cloud infrastructure against PostgreSQL and a commercial database system (Section 6.2)."
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "correct_short_answer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation. It measures the performance of Bao against PostgreSQL and a commercial database system, focusing on query performance and the dollar-cost of executing a workload on cloud infrastructure.",
        "Evidence": "The key question we pose in our evaluation is whether or not Bao could have a positive, practical impact on real-world database workloads that include changes in queries, data, and/or schema. To answer this, we focus on quantifying not only query performance, but also the dollar-cost of executing a workload (including the training overhead introduced by Bao) on cloud infrastructure against PostgreSQL and a commercial database system (Section 6.2)."
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "a summary of the proposed approach",
        "correct_short_answer": "Dynamic query hint selection using reinforcement learning (via Thompson sampling) to steer the traditional optimizer to avoid the worst case",
        "Reasoning": "The paper discusses the use of a tree convolutional neural network and Thompson sampling to balance exploration and exploitation, which helps Bao learn from its mistakes and adapt to changes. This is mentioned in the context of Bao's ability to handle dynamic workloads, data, and schema changes, as described in the abstract and sections 3 and 6.",
        "Evidence": "Bao combines modern tree convolutional neural networks with Thompson sampling, a well-studied reinforcement learning algorithm. As a result, Bao automatically learns from its mistakes and adapts to changes in query workloads, data, and schema. Experimentally, we demonstrate that Bao can quickly learn strategies that improve end-to-end query execution performance, including tail latency, for several workloads containing long-running queries. In cloud environments, we show that Bao can offer both reduced costs and better performance compared with a commercial system."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "a list of the measures used",
        "correct_short_answer": [
          "Query execution latency (median and tail)",
          "cost",
          "physical I/O",
          "CPU time regret"
        ],
        "Reasoning": "The study uses several measures to evaluate robustness, including median Q-Error, regret, percentile latency for queries, number of queries processed over time, training time and convergence, query regression analysis, and query optimization time.",
        "Evidence": "Median Q-Error, Regret (e.g., the difference between the number of physical I/O requests made by the optimal hint set and the selected hint), Percentile latency for queries, Number of queries processed over time, Training time and convergence, Query regression analysis, Query optimization time"
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": ["IMDb", "Stack", "Corp"],
        "correct_short_answer": ["JOB", "Stack", "Corp"],
        "Reasoning": "The study explicitly mentions the use of the IMDb, Stack, and Corp benchmarks in the experimental evaluations.",
        "Evidence": "Not Applicable"
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Real",
        "correct_short_answer": "Both",
        "Reasoning": "The study uses real-world benchmarks, specifically the IMDb, Stack, and Corp benchmarks, which are based on real-world data and workloads.",
        "Evidence": "Not Applicable"
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in trianing data, query, or plan generation?",
        "ShortAnswer": ["query workload", "data", "schema"],
        "correct_short_answer": ["cache state", "hint set configurations"],
        "Reasoning": "The study mentions controlling characteristics such as query workload, data, and schema in the training data, query, or plan generation process.",
        "Evidence": "Not Applicable"
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The experiments are designed to evaluate robustness by assessing Bao's ability to maintain performance in the presence of workload, data, and schema changes. This is explicitly mentioned in the context of evaluating Bao's performance against PostgreSQL and a commercial database system.",
        "Evidence": "The key question we pose in our evaluation is whether or not Bao could have a positive, practical impact on real-world database workloads that include changes in queries, data, and/or schema. To answer this, we focus on quantifying not only query performance, but also the dollar-cost of executing a workload (including the training overhead introduced by Bao) on cloud infrastructure against PostgreSQL and a commercial database system (Section 6.2)."
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions the use of machine learning techniques, specifically tree convolutional neural networks and Thompson sampling, in the proposed approach for Bao.",
        "Evidence": "Bao combines modern tree convolutional neural networks with Thompson sampling, a well-studied reinforcement learning algorithm."
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Reinforcement learning",
        "correct_short_answer": "Reinforcement learning",
        "Reasoning": "The study explicitly mentions the use of Thompson sampling, which is a well-studied reinforcement learning algorithm, in combination with tree convolutional neural networks.",
        "Evidence": "Bao combines modern tree convolutional neural networks with Thompson sampling, a well-studied reinforcement learning algorithm."
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Other",
        "correct_short_answer": "Regression",
        "Reasoning": "The ML approach used in the study combines tree convolutional neural networks with Thompson sampling, which is a reinforcement learning algorithm. This combination does not fit neatly into traditional categories like regression, classification, or clustering.",
        "Evidence": "Bao combines modern tree convolutional neural networks with Thompson sampling, a well-studied reinforcement learning algorithm."
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The text mentions the use of 'tree convolutional neural network' and 'Thompsons sampling, a well-studied reinforcement learning algorithm' which are deep learning techniques.",
        "Evidence": "The architecture of Bao\u2019s prediction model is shown in Figure 5. The vectorized query plan tree is passed through three layers of tree convolution. After the last layer of tree convolution, dynamic pooling is used to flatten the tree structure into a single vector. Then, two fully connected layers are used to map the pooled vector to a performance prediction. We use ReLU activation functions and layer normalization, which are not shown in the figure. Integrating with Thompson sampling Thompson sampling requires the ability to sample model parameters \ud835\udf03 from \ud835\udc43(\ud835\udf03 | \ud835\udc38), whereas most machine learning techniques are designed to find the most likely model given the training data, E[\ud835\udc43(\ud835\udf03 | \ud835\udc38)]. For neural networks, there are several techniques available to sample from \ud835\udc43(\ud835\udf03 | \ud835\udc38), ranging from complex Bayesian neural networks to simple approaches."
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The study does not mention the use of transfer learning in its approach. The focus is on using tree convolutional neural networks and Thompson sampling for query optimization.",
        "Evidence": "Not Applicable"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "a description of the data generation process",
        "correct_short_answer": "Collecting performance data from executing queries with different hint sets using PostgreSQL",
        "Reasoning": "The text describes the process of generating training data for Bao, which involves executing queries, observing their performance, and using this information to retrain the predictive model.",
        "Evidence": "Bao\u2019s training loop closely follows a classical Thompson sampling regime: when a query is received, Bao builds a query plan tree for each hint set and uses the current predictive model to select a plan to execute. After execution, that plan and the observed performance are added to Bao\u2019s experience. Periodically, Bao retrains its predictive model by sampling model parameters (i.e., neural network weights) to balance exploration and exploitation."
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "a description of the encoding process",
        "correct_short_answer": "By binarizing query plan trees into vector trees using one-hot encoding with the operators, classical DBMS's estimated cost and cardinality informantion, and cache state information",
        "Reasoning": "The study encodes the samples by vectorizing the query plan tree and passing it through layers of tree convolution. Dynamic pooling is then used to flatten the tree structure into a single vector, which is further processed through fully connected layers to map to a performance prediction.",
        "Evidence": "The architecture of Bao\u2019s prediction model is shown in Figure 5. The vectorized query plan tree is passed through three layers of tree convolution. After the last layer of tree convolution, dynamic pooling is used to flatten the tree structure into a single vector. Then, two fully connected layers are used to map the pooled vector to a performance prediction. We use ReLU activation functions and layer normalization, which are not shown in the figure."
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study accounts for predictive uncertainties by using Thompson sampling, which balances exploration and exploitation. This approach allows Bao to learn from its mistakes and adapt to changes, thereby managing uncertainties in its predictions.",
        "Evidence": "Bao combines modern tree convolutional neural networks with Thompson sampling, a well-studied reinforcement learning algorithm. As a result, Bao automatically learns from its mistakes and adapts to changes in query workloads, data, and schema."
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "No",
        "correct_short_answer": "Yes",
        "Reasoning": "The provided text does not mention generalization to out-of-distribution as a criterion for robustness.",
        "Evidence": "The text discusses various aspects of query optimization, including the use of machine learning techniques, handling changes in workload, data, and schema, and the performance of the Bao system. However, there is no explicit mention of generalization to out-of-distribution data as a criterion for robustness."
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "No",
        "correct_short_answer": "Yes",
        "Reasoning": "The paper does not explicitly mention evaluating generalization to out-of-distribution data. The evaluations focus on practical impact on real-world database workloads that include changes in queries, data, and/or schema, but do not discuss out-of-distribution scenarios.",
        "Evidence": "The key question we pose in our evaluation is whether or not Bao could have a positive, practical impact on real-world database workloads that include changes in queries, data, and/or schema."
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Tree-Convolutional Neural Network (TCNN)",
        "correct_short_answer": "Tree-Convolutional Neural Network (TCNN)",
        "Reasoning": "The study explicitly mentions the use of a tree convolutional neural network (TCNN) in the proposed method for Bao.",
        "Evidence": "Not Applicable"
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The primary motivation behind the model or encoding scheme design was to create a system that can learn from its mistakes and adapt to changes in query workloads, data, and schema. The paper does not mention enhancing robustness as the primary motivation.",
        "Evidence": "Motivated by thesedifficulties,weintroduceBao(theBandit optimizer).Baotakesadvantageofthewisdombuiltintoexisting queryoptimizersbyprovidingper-queryoptimizationhints.Bao combinesmoderntreeconvolutionalneuralnetworkswithThomp- sonsampling,awell-studiedreinforcementlearningalgorithm.As aresult,Baoautomaticallylearnsfromitsmistakesandadaptsto changesinqueryworkloads,data,andschema."
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": "Unsure",
        "correct_short_answer": [
          "DBA-triggered exploration for performance-critical queries",
          "parallel hint set evaluation"
        ],
        "Reasoning": "The text does not explicitly mention any other techniques specifically aimed at improving robustness beyond the use of tree convolutional neural networks and Thompson sampling.",
        "Evidence": "Not Applicable"
      }
    }
  },
  "BayesCard Revitalizing Bayesian Networks for Cardinality Estimation.pdf.json": {
    "metadata": {
      "paper_id": "21",
      "pdf_filename": "BayesCard Revitalizing Bayesian Networks for Cardinality Estimation.pdf",
      "title": "BayesCard: Revitilizing Bayesian Frameworks for Cardinality Estimation",
      "authors": "Ziniu Wu, Amir Shaikhha, Rong Zhu, Kai Zeng, Yuxing Han, Jingren Zhou",
      "year": "2020"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The study does not introduce any new definitions for robustness.",
        "Evidence": "Not Applicable"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "Robustness is implicitly defined as the ability of a cardinality estimation method to maintain stable performance across various data settings, including different distributions, attribute correlations, domain sizes, and numbers of attributes.",
        "correct_short_answer": "Robustness is implicitly defined as the ability of a cardinality estimation method to maintain stable performance across various data settings, including different distributions, attribute correlations, domain sizes, and numbers of attributes.",
        "Reasoning": "The study provides an implicit definition of robustness by describing it in the context of cardinality estimation methods.",
        "Evidence": "Robustness is implicitly defined as the ability of a cardinality estimation method to maintain stable performance across various data settings, including different distributions, attribute correlations, domain sizes, and numbers of attributes."
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "DBMS (end-to-end)",
        "correct_short_answer": "cardinality estimation",
        "Reasoning": "The text discusses the integration of BayesCard into PostgreSQL and its impact on the end-to-end query processing time for JOB-light queries. This indicates that the scope of the new definition applies to the entire DBMS.",
        "Evidence": "Furthermore, we use the IMDB dataset to demonstrate BayesCard\u2019s behavior in terms of System criteria. The four aspects of System criteria are rather conceptual and hard to compare quantitatively in experiment, so we incorporate BayesCard into a commercial DBMS, Postgres 9.6.6, to show that it can improve the query optimization process of a real system."
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions the robustness of BayesCard in the context of query optimization and processing. It states that BayesCard improves the end-to-end query time by 13.3%, which is very close to the optimal result of 14.2% using the true cardinality. This indicates that BayesCard's robustness in query optimization is addressed in the study.",
        "Evidence": "On the IMDB benchmark workload, it improves the end-to-end query time by 13.3%, which is very close to the optimal result of 14.2% using an oracle of true cardinality."
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The paper introduces BayesCard, a framework that revitalizes Bayesian Networks for cardinality estimation, addressing the inefficiency of model construction and probability inference of traditional Bayesian Networks. This framework incorporates probabilistic programming languages to build Bayesian Networks, which is a significant theoretical advancement in the field of cardinality estimation.",
        "Evidence": "In this paper, we revitalize the Bayesian networks (BN) for CardEst by incorporating the techniques of probabilistic programming languages. We present BayesCard, the first framework that inherits the advantages of BNs, i.e., high estimation accuracy and interpretability, while overcomes their drawbacks, i.e. low structure learning and inference efficiency."
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study includes a significant experimental evaluation by comparing BayesCard with other cardinality estimation methods on various datasets and workloads. The experiments demonstrate the robustness and accuracy of BayesCard in different scenarios.",
        "Evidence": "We conduct extensive experiments to compare BayesCard with other CardEst methods on different datasets and workloads. The results show that BayesCard achieves the best accuracy and robustness in most cases."
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "correct_short_answer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through extensive experiments. It compares BayesCard with other cardinality estimation methods on different datasets and workloads, demonstrating BayesCard's superior accuracy and robustness in most cases.",
        "Evidence": "We conduct extensive experiments to compare BayesCard with other CardEst methods on different datasets and workloads. The results show that BayesCard achieves the best accuracy and robustness in most cases."
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "The study improves robustness by introducing BayesCard, a framework that leverages Bayesian Networks and probabilistic programming languages to enhance the accuracy and efficiency of cardinality estimation. BayesCard addresses the limitations of traditional Bayesian Networks by improving structure learning and inference efficiency, resulting in more robust and accurate cardinality estimates across various data settings.",
        "correct_short_answer": "The study improves robustness by introducing BayesCard, a framework that leverages Bayesian network models within probabilistic programming languages to build an ensemble of models, combined with progressive sampling and compiled variable elimination inference, ensuring stable and efficient cardinality estimation under diverse data conditions.",
        "Reasoning": "The study proposes BayesCard, which enhances robustness by using Bayesian Networks and probabilistic programming languages to improve cardinality estimation. This approach addresses the inefficiencies of traditional Bayesian Networks and provides more accurate and robust estimates.",
        "Evidence": "In this paper, we revitalize the Bayesian networks (BN) for CardEst by incorporating the techniques of probabilistic programming languages. We present BayesCard, the first framework that inherits the advantages of BNs, i.e., high estimation accuracy and interpretability, while overcomes their drawbacks, i.e. low structure learning and inference efficiency."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": ["Q-error quantiles (50%, 90%, 95%, 100%)"],
        "Reasoning": "The study does not explicitly mention any specific measures used to evaluate robustness.",
        "Evidence": "Not Applicable"
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": ["JOB-light", "IMDB"],
        "correct_short_answer": [
          "Single-table: DMV, CENSUS, SYNTHETIC",
          "Multi-table: IMDB benchmark (JOB-light queries and synthesized JOB-comp workload)"
        ],
        "Reasoning": "The study explicitly mentions the use of the JOB-light and IMDB benchmarks in the experimental evaluations.",
        "Evidence": "On the IMDB benchmark workload, it improves the end-to-end query time by 13.3%, which is very close to the optimal result of 14.2% using an oracle of true cardinality."
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Real",
        "correct_short_answer": "Both",
        "Reasoning": "The study mentions the use of the IMDB dataset, which is a real-world dataset.",
        "Evidence": "Furthermore, we use the IMDB dataset to demonstrate BayesCard\u2019s behavior in terms of System criteria."
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in trianing data, query, or plan generation?",
        "ShortAnswer": [
          "data distribution",
          "attribute correlation",
          "attribute domain size",
          "number of attributes (scale)"
        ],
        "correct_short_answer": [
          "data distribution skewness",
          "attribute correlation",
          "attribute domain size",
          "number of attributes (scale)"
        ],
        "Reasoning": "The study controls various characteristics in the training data, query, or plan generation to evaluate the robustness of cardinality estimation methods.",
        "Evidence": "Not Applicable"
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions that the experiments are designed to evaluate the robustness of BayesCard and other cardinality estimation methods across various data settings.",
        "Evidence": "We conduct extensive experiments to compare BayesCard with other CardEst methods on different datasets and workloads. The results show that BayesCard achieves the best accuracy and robustness in most cases."
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study mentions the use of machine learning techniques, specifically probabilistic programming languages, to build Bayesian Networks for cardinality estimation.",
        "Evidence": "In this paper, we revitalize the Bayesian networks (BN) for CardEst by incorporating the techniques of probabilistic programming languages."
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Other",
        "correct_short_answer": "Unsupervised",
        "Reasoning": "The study uses probabilistic programming languages to build Bayesian Networks, which is a type of probabilistic machine learning rather than traditional supervised, unsupervised, semi-supervised, or reinforcement learning.",
        "Evidence": "In this paper, we revitalize the Bayesian networks (BN) for CardEst by incorporating the techniques of probabilistic programming languages."
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Other",
        "correct_short_answer": "Other",
        "Reasoning": "The ML approach used in the study involves probabilistic programming languages to build Bayesian Networks, which does not fit into traditional categories like regression, classification, or clustering.",
        "Evidence": "In this paper, we revitalize the Bayesian networks (BN) for CardEst by incorporating the techniques of probabilistic programming languages."
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The paper discusses the use of Bayesian Networks (BNs) for cardinality estimation and mentions that deep learning (DL) techniques have been used in other methods. However, the proposed approach, BayesCard, does not use deep learning. Instead, it focuses on incorporating techniques of probabilistic programming languages with Bayesian Networks.",
        "Evidence": "Recently, numerous works attempt to utilize machine learning (ML), especially deep learning (DL) techniques for CardEst. They either build supervised models mapping featurized query Q to its cardinality [1,21] or learn unsupervised models of P, the joint probability distribution of table T, to support computing the probability of any query Q on T [20,53,58]. DL-based CardEst methods greatly improve the estimation accuracy but often sacrifice other algorithm aspects. More importantly, their performance can be greatly affected by data and often difficult for system deployment, such as the hyper-parameter tuning and the \u201cblack-box\u201d property. ... In this paper, we revitalize the Bayesian networks (BN) for CardEst by incorporating the techniques of probabilistic programming languages."
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "Unsure",
        "correct_short_answer": "No",
        "Reasoning": "The paper does not explicitly mention the use of transfer learning in the proposed approach.",
        "Evidence": "Not Applicable"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "By drawing unbiased samples from full outer joins of tables for ensemble construction and by synthesizing selection queries via uniform random predicates (continuous range bounds or categorical value sets) per attribute.",
        "Reasoning": "The study does not explicitly describe the process of generating training data.",
        "Evidence": "Not Applicable"
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "Not applicable",
        "Reasoning": "The study does not explicitly describe the process of encoding samples.",
        "Evidence": "Not Applicable"
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Unsure",
        "correct_short_answer": "Yes",
        "Reasoning": "The study does not explicitly mention whether it accounts for predictive uncertainties.",
        "Evidence": "Not Applicable"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study recognizes generalization to out-of-distribution as a criterion for robustness by evaluating the performance of BayesCard across various data settings, including different distributions, attribute correlations, domain sizes, and numbers of attributes.",
        "Evidence": "We conduct extensive experiments to compare BayesCard with other CardEst methods on different datasets and workloads. The results show that BayesCard achieves the best accuracy and robustness in most cases."
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "No",
        "correct_short_answer": "Yes",
        "Reasoning": "The study does not explicitly evaluate generalization to out-of-distribution data.",
        "Evidence": "Not Applicable"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Other",
        "correct_short_answer": "Other",
        "Reasoning": "The proposed method, BayesCard, uses Bayesian Networks (BNs) for cardinality estimation, which does not fit into the traditional model architectures listed.",
        "Evidence": "In this paper, we revitalize the Bayesian networks (BN) for CardEst by incorporating the techniques of probabilistic programming languages."
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The primary motivation behind the design of BayesCard was to revitalize Bayesian networks for cardinality estimation by incorporating probabilistic programming languages. The focus was on improving estimation accuracy, inference and training time, model size, and update efficiency, rather than specifically enhancing robustness.",
        "Evidence": "In this paper, we revitalize the Bayesian networks (BN) for CardEst by incorporating the techniques of probabilistic programming languages. We present BayesCard, the first framework that inherits the advantages of BNs, i.e., high estimation accuracy and interpretability, while overcomes their drawbacks, i.e. low structure learning and inference efficiency."
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": [
          "an ensemble construction based on table-dependency budgets",
          "graph-reduction optimization",
          "progressive sampling inference",
          "compiled variable-elimination inference"
        ],
        "Reasoning": "The study does not explicitly mention any other techniques used for improving robustness.",
        "Evidence": "Not Applicable"
      }
    }
  },
  "CORDS Automatic Discovery of Correlations and Soft Functional Dependencies.pdf.json": {
    "metadata": {
      "paper_id": "26",
      "pdf_filename": "CORDS Automatic Discovery of Correlations and Soft Functional Dependencies.pdf",
      "title": "CORDS: Automatic discovery of correlations and soft functional dependencies",
      "authors": "Ilyas, I.F.; Markl, V.; Haas, P.; Brown, P.; Aboulnaga, A.",
      "year": "2004"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not introduce any new definitions for robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not explicitly or implicitly define robustness or risk.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not provided"
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "cardinality estimation",
        "Reasoning": "The paper discusses the use of CORDS to improve the accuracy of a query optimizer by recommending a set of column-group statistics to maintain. This directly relates to cardinality estimation, as it helps in avoiding naive selectivity estimates based on inappropriate independence assumptions.",
        "Evidence": "In this section we describe one possible scheme for using cords to improve the accuracy of a query optimizer. In this scheme, cords recommends a set of cg statistics for the optimizer to maintain. These \u201ccolumn-group\u201d (cg) statistics are then used by the optimizer to avoid inaccurate selectivity estimates caused by naive independence assumptions.",
        "correct_short_answer": "cardinality estimation"
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study discusses the problem of robustness in query optimization and processing by addressing the issue of inappropriate independence assumptions made by query optimizers. These assumptions often lead to underestimation of selectivities by orders of magnitude, which can result in poor query performance. The CORDS tool is introduced to discover correlations and soft functional dependencies between columns, which can then be used to improve the accuracy of selectivity estimates and hence the choice of query plans.",
        "Evidence": "When a query optimizer in a commercial relational dbms chooses a horrible query plan, the cause of the disaster is usually an inappropriate independence assumption that the optimizer has imposed on two or more columns. ... cords can serve as a data mining tool, e.g., its output can be converted to a dependency graph as in Figure 6. ... cords can be used in conjunction with query feedback systems such as the leo learning optimizer, leveraging the infrastructure of such systems to correct bad selectivity estimates and ameliorating the poor performance of feedback systems during slow learning phases.",
        "correct_short_answer": "Yes"
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study introduces cords, a novel tool for automatic discovery of correlations and soft functional dependencies between columns in relational databases. This tool significantly modifies the technology of the b-hunt system and employs a robust chi-squared analysis to identify correlations between both numerical and categorical attributes. The study also demonstrates the practical application of cords in query optimization, leading to order-of-magnitude improvements in query execution times.",
        "Evidence": "cords is a fast and scalable technique for detecting correlations and soft fds between attributes in a relational database. By combining the candidate-generation framework from the b-hunt system with robust chi-squared analysis and a judicious use of sampling, cords can discover correlations and soft fds in very large databases in a matter of minutes. Our empirical study also shows that real-world databases are rich in such statistical relationships.",
        "correct_short_answer": "No"
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study includes a significant experimental evaluation, as evidenced by the detailed performance analysis of the CORDS tool. The experiments demonstrate the effectiveness of CORDS in discovering correlations and soft functional dependencies in large databases, as well as its practical application in improving query optimization. The evaluation covers various aspects, including the scalability and efficiency of CORDS, and its impact on query execution times.",
        "Evidence": "Our empirical study also shows that real-world databases are rich in such statistical relationships. ... We have also shown that cords can be used to improve the accuracy of a query optimizer by recommending a set of column-group statistics to maintain. ... We have also shown that cords can be used in conjunction with query feedback systems such as the leo learning optimizer, leveraging the infrastructure of such systems to correct bad selectivity estimates and ameliorating the poor performance of feedback systems during slow learning phases.",
        "correct_short_answer": "Yes"
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation. It demonstrates the effectiveness of the CORDS tool in discovering correlations and soft functional dependencies, and shows how these discoveries can be used to improve query optimization. The evaluation includes empirical studies on real-world databases and shows significant improvements in query execution times.",
        "Evidence": "Our empirical study also shows that real-world databases are rich in such statistical relationships. ... We have also shown that cords can be used to improve the accuracy of a query optimizer by recommending a set of column-group statistics to maintain. ... We have also shown that cords can be used in conjunction with query feedback systems such as the leo learning optimizer, leveraging the infrastructure of such systems to correct bad selectivity estimates and ameliorating the poor performance of feedback systems during slow learning phases.",
        "correct_short_answer": "experimental evaluation"
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "a summary of the proposed approach",
        "Reasoning": "The study improves robustness by using a robust chi-squared analysis and a judicious use of sampling. This approach allows cords to discover correlations in a fast, efficient, and highly scalable manner. The experiments show that cords can discover correlations and soft functional dependencies in very large databases in a matter of minutes.",
        "Evidence": "cords is a fast and scalable technique for detecting cor- relations and soft fds between attributes in a relational database. By combining the candidate-generation frame- work from the b-hunts system with robust chi-squared analysis and a judicious use of sampling, cords can discover correlations in a fast, efficient and highly scalable manner. Indeed, our experiments show that cords can discover correlations and soft fds in very large databases in a matter of minutes.",
        "correct_short_answer": "CORDS improves query optimization robustness by automatically detecting correlations and soft functional dependencies between database columns that would otherwise lead to catastrophic selectivity estimation errors. By recommending column-group statistics for strongly correlated columns, it prevents optimizers from making naive independence assumptions that can cause query plans to be orders of magnitude slower than necessary. Experimental results show CORDS dramatically reduces worst-case execution times by an order of magnitude, while requiring minimal system overhead through efficient sampling techniques and strategic pruning of candidate column pairs."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not explicitly mention any specific measures used to evaluate robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": [
          "tail-end q-error",
          "tail-end Speedup",
          "misclassification of correlated columns"
        ]
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": ["TPC-H"],
        "Reasoning": "The study explicitly mentions the use of the TPC-H benchmark in its experimental evaluations.",
        "Evidence": "We used the tpch benchmark to evaluate the performance of cords.",
        "correct_short_answer": ["TPC-H", "Accidents", "Census", "Auto"]
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Synthetic",
        "Reasoning": "The TPC-H benchmark used in the study is synthetic, as it is a standard benchmark for evaluating the performance of decision support systems.",
        "Evidence": "We used the tpch benchmark to evaluate the performance of cords.",
        "correct_short_answer": "Synthetic"
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not explicitly mention any characteristics that are controlled in training data, query, or plan generation.",
        "Evidence": "Not Applicable",
        "correct_short_answer": [
          "correlation strength",
          "functional dependency strength",
          "sample size",
          "column-group statistics order",
          "p-value thresholds",
          "adjustment factor thresholds"
        ]
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "No",
        "Reasoning": "The experiments in the study are not specifically designed to evaluate robustness. Instead, they focus on demonstrating the effectiveness of the CORDS tool in discovering correlations and soft functional dependencies, and its impact on query optimization.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Yes"
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not use machine learning in its proposed approach. Instead, it employs statistical methods such as chi-squared analysis to discover correlations and soft functional dependencies.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use a machine learning approach, so it does not belong to any ML category.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of deep learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of transfer learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not involve the generation of training data as it does not use a machine learning approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not involve encoding samples as it does not use a machine learning approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study mentions the use of a 'p-value' which is the probability of seeing a value of \u03c72 as large as (or larger than) the value actually observed, assuming that the attributes are truly independent. This indicates that the study accounts for predictive uncertainties.",
        "Evidence": "Thus the smaller the p-value, the more likely that the columns are correlated. The cutoff value p is the maximum allowable probability of incorrectly asserting correlation in the presence of independence.",
        "correct_short_answer": "Not Applicable"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not explicitly recognize generalization to out-of-distribution as a criterion for robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not evaluate generalization to out-of-distribution.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use a model architecture as it does not employ a machine learning approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "No",
        "Reasoning": "The primary motivation behind the design of the CORDS tool is to discover correlations and soft functional dependencies between columns in relational databases, which can then be used to improve query optimization. Enhancing robustness is not explicitly mentioned as the primary motivation.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Yes"
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": [
          "chi-squared analysis",
          "sampling",
          "pruning heuristics",
          "column-group statistics"
        ],
        "Reasoning": "The study uses chi-squared analysis and sampling to discover correlations and soft functional dependencies. It also employs pruning heuristics to reduce the number of candidate column groups and recommends maintaining column-group statistics to improve query optimization.",
        "Evidence": "cords is a fast and scalable technique for detecting correlations and soft fds between attributes in a relational database. By combining the candidate-generation framework from the b-hunt system with robust chi-squared analysis and a judicious use of sampling, cords can discover correlations in a fast, efficient and highly scalable manner. ... We have also shown that cords can be used to improve the accuracy of a query optimizer by recommending a set of column-group statistics to maintain. ... We have also shown that cords can be used in conjunction with query feedback systems such as the leo learning optimizer, leveraging the infrastructure of such systems to correct bad selectivity estimates and ameliorating the poor performance of feedback systems during slow learning phases.",
        "correct_short_answer": ""
      }
    }
  },
  "Cost-based or Learning-based A Hybrid Query Optimizer for Query Plan Selection.pdf.json": {
    "metadata": {
      "paper_id": "27",
      "pdf_filename": "Cost-based or Learning-based A Hybrid Query Optimizer for Query Plan Selection.pdf",
      "title": "Cost-Based or Learning-Based? A Hybrid Query Optimizer for Query Plan Selection",
      "authors": "Xiang Yu, Chengliang Chai, Guoliang Li, and Jiabin Liu",
      "year": "2022"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The study does not introduce any new definitions for robustness.",
        "Evidence": "Not Applicable"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "The study defines robustness implicitly in this paper, which refers to the optimizer\u2019s ability to maintain good plan\u2010selection quality under dynamic, out-of-distribution workloads.",
        "Reasoning": "The study does not explicitly define robustness or risk.",
        "Evidence": "Not Applicable"
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "No Definitions Provided",
        "correct_short_answer": "No Definitions Provided",
        "Reasoning": "The study does not provide any new definitions for robustness.",
        "Evidence": "Not Applicable"
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "No",
        "correct_short_answer": "Yes",
        "Reasoning": "The text does not explicitly mention the term 'robustness' or discuss the concept of robustness in the context of query optimization and processing.",
        "Evidence": "The text discusses various aspects of query optimization, including the use of cost-based and learning-based optimizers, the generation of candidate plans, and the selection of optimal plans. However, it does not address the specific problem of robustness in query optimization and processing."
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Unsure",
        "correct_short_answer": "No",
        "Reasoning": "The study does not explicitly state whether it has a significant contribution to the theory.",
        "Evidence": "Not Applicable"
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study includes a significant experimental evaluation as evidenced by the detailed discussion of experimental setup, datasets, baselines, and various performance metrics such as total latency, tail latency, and the impact of different parameters on the performance of the proposed HybridQO optimizer.",
        "Evidence": "page_label: 5, page_label: 7, page_label: 8, page_label: 9, page_label: 10, page_label: 11, page_label: 12"
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "experimental evaluation",
        "Reasoning": "The study does not explicitly evaluate robustness or its improvements.",
        "Evidence": "Not Applicable"
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "The study introduces HybridQO, which uses a Monte Carlo Tree Search\u2013guided, learning-based join-order estimator to generate leading hints, supplements these hints via a traditional cost-based optimizer to form candidate plans, and applies an uncertainty-aware performance predictor to filter out high-uncertainty plans, thereby adapting to out-of-distribution queries.",
        "Reasoning": "The study does not explicitly discuss or propose any methods to improve robustness.",
        "Evidence": "Not Applicable"
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": [
          "Total latency",
          "Tail-latency percentiles (50%, 75%, 99%, 99.5%)",
          "Chosen rate and win rate of HybridQO versus baselines",
          "Q-error distributions analyzed across uncertainty buckets"
        ],
        "Reasoning": "The study does not explicitly mention any measures used to evaluate robustness.",
        "Evidence": "Not Applicable"
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": ["JOB", "JOB-EXT", "JOB-D", "Stack"],
        "correct_short_answer": ["JOB", "JOB-EXT", "JOB-D", "Stack"],
        "Reasoning": "The study explicitly mentions the use of JOB, JOB-EXT, JOB-D, and Stack benchmarks in the experimental evaluations.",
        "Evidence": "page_label: 7"
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Real",
        "correct_short_answer": "Real",
        "Reasoning": "The study explicitly mentions that the benchmarks used are real-world datasets.",
        "Evidence": "page_label: 7"
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "ShortAnswer": ["Not provided"],
        "correct_short_answer": [
          "Leading-hint length",
          "Dynamic workload template addition",
          "Number of relations per query"
        ],
        "Reasoning": "The study does not explicitly mention any characteristics controlled in training data, query, or plan generation.",
        "Evidence": "Not Applicable"
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "No",
        "correct_short_answer": "Yes",
        "Reasoning": "The study does not explicitly mention that the experiments are designed to evaluate robustness.",
        "Evidence": "Not Applicable"
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions the use of machine learning models in its proposed approach.",
        "Evidence": "page_label: 3, page_label: 4, page_label: 5, page_label: 6, page_label: 7, page_label: 8, page_label: 9, page_label: 10, page_label: 11, page_label: 12"
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Supervised",
        "correct_short_answer": "Supervised",
        "Reasoning": "The study explicitly mentions the use of supervised learning in its proposed approach.",
        "Evidence": "page_label: 3, page_label: 4, page_label: 5, page_label: 6, page_label: 7, page_label: 8, page_label: 9, page_label: 10, page_label: 11, page_label: 12"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Learning-to-Rank",
        "correct_short_answer": "Regression",
        "Reasoning": "The study explicitly mentions the use of learning-to-rank models in its proposed approach.",
        "Evidence": "page_label: 3, page_label: 4, page_label: 5, page_label: 6, page_label: 7, page_label: 8, page_label: 9, page_label: 10, page_label: 11, page_label: 12"
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions the use of deep learning models in its proposed approach.",
        "Evidence": "page_label: 3, page_label: 4, page_label: 5, page_label: 6, page_label: 7, page_label: 8, page_label: 9, page_label: 10, page_label: 11, page_label: 12"
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The study does not explicitly mention the use of transfer learning in its proposed approach.",
        "Evidence": "Not Applicable"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "The study generates its training data by running sample workloads on the DBMS, extracting each executed plan\u2019s join order and actual execution time, and using these as (feature, label) pairs",
        "Reasoning": "The study does not explicitly describe the process of generating training data.",
        "Evidence": "Not Applicable"
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "Query encoding: Flattened join-matrix (n\u00d7n) plus filter-selectivity vector, Join order encoding: Sequence of table embeddings fed through an LSTM, Plan encoding: Operator, table, and cost-model one-hot/real-valued features composed into a Tree-LSTM",
        "Reasoning": "The study does not explicitly describe the process of encoding the samples.",
        "Evidence": "Not Applicable"
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "No",
        "correct_short_answer": "Yes",
        "Reasoning": "The study does not explicitly mention accounting for predictive uncertainties.",
        "Evidence": "Not Applicable"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "No",
        "correct_short_answer": "Yes",
        "Reasoning": "The study does not explicitly recognize generalization to out-of-distribution as a criterion for robustness.",
        "Evidence": "Not Applicable"
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "No",
        "correct_short_answer": "Yes",
        "Reasoning": "The study does not explicitly evaluate generalization to out-of-distribution.",
        "Evidence": "Not Applicable"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Transformer (Trm)",
        "correct_short_answer": "Recurrent Neural Network (RNN), Tree-structured Long Short-Term Memory (Tree-LSTM)",
        "Reasoning": "The study explicitly mentions the use of a Transformer model architecture in its proposed method.",
        "Evidence": "page_label: 3, page_label: 4, page_label: 5, page_label: 6, page_label: 7, page_label: 8, page_label: 9, page_label: 10, page_label: 11, page_label: 12"
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "No",
        "correct_short_answer": "Yes",
        "Reasoning": "The study does not explicitly mention enhancing robustness as the primary motivation behind the model or encoding scheme design.",
        "Evidence": "Not Applicable"
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": [
          "Monte Carlo Tree Search for hint exploration",
          "Uncertainty-aware plan selection to avoid high-risk plans",
          "Incremental online model updating after each execution"
        ],
        "Reasoning": "The study does not explicitly mention any techniques used for improving robustness.",
        "Evidence": "Not Applicable"
      }
    }
  },
  "Deep Reinforcement Learning for Join Order Enumeration.pdf.json": {
    "metadata": {
      "paper_id": "28",
      "pdf_filename": "Deep Reinforcement Learning for Join Order Enumeration.pdf",
      "title": "Deep Reinforcement Learning for Join Order Enumeration",
      "authors": "Marcus, Ryan and Papaemmanouil, Olga",
      "year": "2018"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "correct_short_answer": "No",
        "ShortAnswer": "Unsure",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "correct_short_answer": "No",
        "ShortAnswer": "Not provided",
        "Reasoning": "The query engine tool did not provide a definition for robustness or risk.",
        "Evidence": "Not Applicable"
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "correct_short_answer": "No",
        "ShortAnswer": "No Definitions Provided",
        "Reasoning": "The text does not provide any new definitions for the terms mentioned in the question.",
        "Evidence": "The text discusses various aspects of query optimization and the ReJOIN enumerator but does not introduce new definitions for join ordering, cardinality estimation, cost model, plan optimization, workload management, DBMS (end-to-end), or ML models."
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "correct_short_answer": "No",
        "ShortAnswer": "Unsure",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "correct_short_answer": "No",
        "ShortAnswer": "Unsure",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "correct_short_answer": "Yes",
        "ShortAnswer": "Unsure",
        "NewReasoning": "It demonstrate superior performance compare to PostgreSQL.",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "correct_short_answer": "No",
        "ShortAnswer": "Unsure",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "correct_short_answer": "No",
        "ShortAnswer": "Unsure",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "correct_short_answer": "No",
        "ShortAnswer": "Unsure",
        "NewReasoning": "Query Plan Cost Relative to PostgreSQL",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "correct_short_answer": "JOB",
        "ShortAnswer": "Unsure",
        "NewReasoning": "he study mentions using JOB.",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "NewEvidence": "Our experiments are based on the Join Order Benchmark (JOB), a set of queries used in previous assessments of query optimizers.",
        "Evidence": "Not Applicable"
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "correct_short_answer": "real",
        "ShortAnswer": "Unsure",
        "NewReasoning": "The study uses real benchmark, JOB.",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "correct_short_answer": "90% for training and 10% for testing.",
        "ShortAnswer": "Unsure",
        "NewReasoning": "Random split with 90% for training and 10% for testing.",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "NewEvidence": "",
        "Evidence": "Not Applicable"
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "correct_short_answer": "No",
        "ShortAnswer": "Unsure",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "correct_short_answer": "Yes",
        "ShortAnswer": "Unsure",
        "NewReasoning": "We introduce a novel approach to query optimization that is based on deep reinforcement learning (DRL), a process by which a machine learns a task through continuous feedback with the help of an artificial neural network.",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "correct_short_answer": "Deep Reinforcement Learning (DRL)",
        "ShortAnswer": "Unsure",
        "NewReasoning": "We introduce a novel approach to query optimization that is based on deep reinforcement learning (DRL), a process by which a machine learns a task through continuous feedback with the help of an artificial neural network.",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "correct_short_answer": "Deep Reinforcement Learning (DRL)",
        "ShortAnswer": "Unsure",
        "NewReasoning": "We introduce a novel approach to query optimization that is based on deep reinforcement learning (DRL), a process by which a machine learns a task through continuous feedback with the help of an artificial neural network.",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "correct_short_answer": "Yes",
        "ShortAnswer": "Unsure",
        "NewReasoning": "We introduce a novel approach to query optimization that is based on deep reinforcement learning (DRL), a process by which a machine learns a task through continuous feedback with the help of an artificial neural network.",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "correct_short_answer": "No",
        "ShortAnswer": "Unsure",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "correct_short_answer": "They use JOB and use 103 out of 113 queries for training and 10 for testing.",
        "ShortAnswer": "Unsure",
        "NewReasoning": "To evaluate the effectiveness of the join orderings produced by ReJOIN, we first trained our system over 10,000 queries randomly selected from our 103 training queries (the process took about 3 hours). Then, we used the generated model to produce a join ordering for our 10 test queries.",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "correct_short_answer": "The study uses fully connected layer and use binary subtree to capture tree structure data.",
        "ShortAnswer": "Unsure",
        "NewReasoning": "To capture tree structure data, we encode each binary subtree (i.e., join ordering decided so far) x \u2208 sj as a row vector v of size n, where n is the total number of relations in the database. The value vi is zero if the ith relation is not in x, and equal to 1/h(i,x) otherwise, where h(i, x) is the height of the relation ri in the subtree x (the distance from the root).",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "correct_short_answer": "No",
        "ShortAnswer": "Unsure",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "correct_short_answer": "No",
        "ShortAnswer": "Unsure",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "correct_short_answer": "Yes",
        "ShortAnswer": "Unsure",
        "NewReasoning": "This shows that ReJOIN was able to learn a generalizable join order enumeration strategy which outperforms or matches the cost of the join ordering produced by the PostgreSQL optimizer.",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "correct_short_answer": "Fully conncted layer.",
        "ShortAnswer": "Unsure",
        "NewReasoning": "We used two hidden layers with 128 rectified linear units (ReLUs) [7] each.",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "correct_short_answer": "No",
        "ShortAnswer": "Unsure",
        "NewReasoning": "These techniques, powered by artificial neural networks, can automatically improve decision making by incorporating feedback from their successes and failures. ",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "correct_short_answer": "No",
        "ShortAnswer": "Unsure",
        "Reasoning": "The query engine tool did not provide a definitive answer.",
        "Evidence": "Not Applicable"
      }
    }
  },
  "Fauce Fast and Accurate Deep Ensembles with Uncertainty for Cardinality Estimation.pdf.json": {
    "metadata": {
      "paper_id": "38",
      "pdf_filename": "Fauce Fast and Accurate Deep Ensembles with Uncertainty for Cardinality Estimation.pdf",
      "title": "Fauce: fast and accurate deep ensembles with uncertainty for cardinality estimation",
      "authors": "Liu, J.; Dong, W.; Zhou, Q.; Li, D.",
      "year": "2021"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not introduce any new definitions for robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not provide explicit or implicit definitions for robustness or risk.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not provided"
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "ML models",
        "Reasoning": "The paper discusses the use of machine learning models for cardinality estimation, specifically mentioning the application of deep learning techniques and the integration of uncertainty management into these models.",
        "Evidence": "Recently, the research has been actively using the machine learning technique to estimate the cardinality [11,17\u201319,21,24,56\u201358]. These approaches can be mainly classified as two types: data-driven and query-driven estimators. Both of them have limitations. The data-driven estimators such as Naru [57], NeuroCard [56], and MADE [18] leverage the deep autoregressive (AR) models [9,14] to estimate the cardinality.",
        "correct_short_answer": "No Definitions Provided"
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study mentions that Fauce is designed to be robust to complicated queries with correlated columns or a large number of joins, which are common challenges in query optimization and processing.",
        "Evidence": "In some cases with complex queries where there are correlated columns or a large number of joins, the accuracy of the cardinality estimation drops dramatically.",
        "correct_short_answer": "Yes"
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper introduces Fauce, a new cardinality estimator that incorporates uncertainty information for cardinality estimation into a deep learning model. This is a significant contribution to the theory as it addresses the limitations of existing estimators that do not provide uncertainty information and struggle with complex queries.",
        "Evidence": "Fauce is the first estimator that incorporates uncertainty information for cardinality estimation into a deep learning model.",
        "correct_short_answer": "Yes"
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper mentions extensive experiments conducted over the IMDB dataset, which exhibits complex correlation and conditional independence between table columns. The evaluation metrics used include the q-error metric, and the results are reported across various workloads and scenarios.",
        "Evidence": "We conducted an extensive set of experiments over IMDB, a real-world dataset that exhibits complex correlation and conditional independence between table columns and have been extensively or closely studied in prior work [11, 17\u201319, 21, 24, 56\u201358]. To evaluate the accuracy of Fauce on the above workloads, we use the q-error metric. The q-error of Fauce on a query q is calculated as, err_q = max(est(q), act(q)) / min(est(q), act(q)). We assume that act(q) >= 1 and est(q) >= 1, so the minimum err_q is 1x. We report the median, 75th, 90th, 95th, and 99th percentile errors across all queries.",
        "correct_short_answer": "Yes"
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through extensive experiments conducted over the IMDB dataset. The evaluation metrics used include the q-error metric, and the results are reported across various workloads and scenarios.",
        "Evidence": "We conducted an extensive set of experiments over IMDB, a real-world dataset that exhibits complex correlation and conditional independence between table columns and have been extensively or closely studied in prior work [11, 17\u201319, 21, 24, 56\u201358]. To evaluate the accuracy of Fauce on the above workloads, we use the q-error metric. The q-error of Fauce on a query q is calculated as, err_q = max(est(q), act(q)) / min(est(q), act(q)). We assume that act(q) >= 1 and est(q) >= 1, so the minimum err_q is 1x. We report the median, 75th, 90th, 95th, and 99th percentile errors across all queries.",
        "correct_short_answer": "experimental evaluation"
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "a summary of the proposed approach",
        "Reasoning": "The text mentions that Fauce includes a new learning paradigm that leverages the uncertainties to boost the estimation results and make Fauce robust to be applied in dynamic databases. The model-based approach on the generated training dataset and the use of adversarial training are specifically highlighted as methods to improve robustness.",
        "Evidence": "Fauce also includes a new learning paradigm that leverages the uncertainties to boost the estimation results and make Fauce robust to be applied in dynamic databases. DeepDB[21], and NeuroCard[56]. Lastly, to test Fauce\u2019s ability to... The uncertainty of the cardinality estimator comes from multiple sources. First, we are uncertain about whether the learned model parameters can best describe the... This datashift can be large especially for dynamic databases. Thus, we are also uncertain about whether the data used to train model can well represent the features for inference queries, this is referred as data uncertainty. The setwo types of uncertainty consist the uncertainty of the learned estimator. To address the above problems, we design a model called deep ensembles with uncertainty to estimate the cardinality and the corresponding uncertainty. We use the ensemble technique, because it generally produces the best results among all neural network-based approaches. Furthermore, it provides the benefit of being able to separately determine model and data uncertainties. Ensembles training. Fauce uses the entire training dataset to train each DNN. To improve the model\u2019s robustness, Fauce also includes the adversarial training. In particular, we use the fast gradient sign method[15] to generate adversarial query examples.",
        "correct_short_answer": "Fauce improves robustness in cardinality estimation through four key innovations: a sophisticated query featurization method that captures real correlations between database columns and tables, uncertainty quantification that provides confidence levels for estimates, a deep ensemble learning approach that combines multiple neural networks, and an uncertainty management system that identifies when estimates are unreliable. Crucially, Fauce includes a fall-back mechanism that triggers when uncertainties are high, storing problematic queries in a buffer for incremental learning and using sampling techniques to generate additional training data. This adaptive approach makes Fauce significantly more accurate (1.3\u00d7-6.7\u00d7 lower error rates) and faster (10\u00d7 faster inference) than existing methods, especially for complex queries."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "a list of the measures used",
        "Reasoning": "The study uses the q-error metric to evaluate the accuracy of Fauce on various workloads. The q-error metric is calculated as the ratio of the maximum of the estimated and actual query results to the minimum of the estimated and actual query results. The study reports the median, 75th, 90th, 95th, and 99th percentile errors across all queries.",
        "Evidence": "To evaluate the accuracy of Fauce on the above workloads, we use the q-error metric. The q-error of Fauce on a query q is calculated as, err_q = max(est(q), act(q)) / min(est(q), act(q)). We assume that act(q) >= 1 and est(q) >= 1, so the minimum err_q is 1x. We report the median, 75th, 90th, 95th, and 99th percentile errors across all queries.",
        "correct_short_answer": [
          "q_error (50th, 75th, 90th, 95th, 99th percentiles)",
          "Correlation between Uncertainty and Error",
          "Execution Time",
          "Percentage of improved queries",
          "Training time",
          "Inference time"
        ]
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": "JOB, JOB-Light",
        "Reasoning": "The study mentions that the experiments were conducted using the JOB and JOB-Light benchmarks.",
        "Evidence": "We conducted an extensive set of experiments over IMDB, a real-world dataset that exhibits complex correlation and conditional independence between table columns and have been extensively or closely studied in prior work [11, 17\u201319, 21, 24, 56\u201358]. We use the JOB and JOB-Light benchmarks to evaluate the performance of Fauce.",
        "correct_short_answer": [
          "JOB",
          "JOB-more-filters",
          "JOB-complex-joins",
          "Forest",
          "Power",
          "Weather",
          "DB status",
          "Wiki image",
          "Census",
          "Reflns",
          "Entity source",
          "Spots"
        ]
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Real",
        "Reasoning": "The study mentions that the experiments were conducted over IMDB, a real-world dataset that exhibits complex correlation and conditional independence between table columns.",
        "Evidence": "We conducted an extensive set of experiments over IMDB, a real-world dataset that exhibits complex correlation and conditional independence between table columns and have been extensively or closely studied in prior work [11, 17\u201319, 21, 24, 56\u201358].",
        "correct_short_answer": ""
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "ShortAnswer": "a list of the characteristics controlled",
        "Reasoning": "The study mentions controlling the following characteristics in training data, query, or plan generation: data uncertainty, model uncertainty, and adversarial training.",
        "Evidence": "The uncertainty of the cardinality estimator comes from multiple sources. First, we are uncertain about whether the learned model parameters can best describe the... This datashift can be large especially for dynamic databases. Thus, we are also uncertain about whether the data used to train model can well represent the features for inference queries, this is referred as data uncertainty. The setwo types of uncertainty consist the uncertainty of the learned estimator. To address the above problems, we design a model called deep ensembles with uncertainty to estimate the cardinality and the corresponding uncertainty. We use the ensemble technique, because it generally produces the best results among all neural network-based approaches. Furthermore, it provides the benefit of being able to separately determine model and data uncertainties. Ensembles training. Fauce uses the entire training dataset to train each DNN. To improve the model\u2019s robustness, Fauce also includes the adversarial training. In particular, we use the fast gradient sign method[15] to generate adversarial query examples.",
        "correct_short_answer": [
          "Generality",
          "Diversity",
          "Number of predicates",
          "Number of filters",
          "Number of joined tables",
          "Join complexity",
          "Column correlation",
          "Uniformity of training data",
          "Sampling methodology",
          "Comparison operators"
        ]
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions that the experiments are designed to evaluate the robustness of Fauce, particularly in handling complex queries with correlated columns or a large number of joins.",
        "Evidence": "In some cases with complex queries where there are correlated columns or a large number of joins, the accuracy of the cardinality estimation drops dramatically.",
        "correct_short_answer": "Yes"
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions the use of machine learning techniques, specifically deep learning models, in its proposed approach for cardinality estimation.",
        "Evidence": "Recently, the research has been actively using the machine learning technique to estimate the cardinality [11,17\u201319,21,24,56\u201358]. These approaches can be mainly classified as two types: data-driven and query-driven estimators. Both of them have limitations. The data-driven estimators such as Naru [57], NeuroCard [56], and MADE [18] leverage the deep autoregressive (AR) models [9,14] to estimate the cardinality.",
        "correct_short_answer": "Yes"
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Supervised",
        "Reasoning": "The study mentions the use of deep learning models, specifically deep autoregressive (AR) models, which are typically trained in a supervised manner.",
        "Evidence": "The data-driven estimators such as Naru [57], NeuroCard [56], and MADE [18] leverage the deep autoregressive (AR) models [9,14] to estimate the cardinality.",
        "correct_short_answer": "Supervised"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Autoregression",
        "Reasoning": "The study specifically mentions the use of deep autoregressive (AR) models for cardinality estimation.",
        "Evidence": "The data-driven estimators such as Naru [57], NeuroCard [56], and MADE [18] leverage the deep autoregressive (AR) models [9,14] to estimate the cardinality.",
        "correct_short_answer": "Regression"
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions the use of deep learning models, specifically deep autoregressive (AR) models, for cardinality estimation.",
        "Evidence": "The data-driven estimators such as Naru [57], NeuroCard [56], and MADE [18] leverage the deep autoregressive (AR) models [9,14] to estimate the cardinality.",
        "correct_short_answer": "Yes"
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of transfer learning in its approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "a description of the data generation process",
        "Reasoning": "The study describes the process of generating training data by sampling from the joint data distribution and using adversarial training to create adversarial query examples.",
        "Evidence": "Fauce uses the entire training dataset to train each DNN. To improve the model\u2019s robustness, Fauce also includes the adversarial training. In particular, we use the fast gradient sign method[15] to generate adversarial query examples.",
        "correct_short_answer": "The study generates training data through a systematic process that ensures both generality and diversity. Queries are uniformly distributed across join graphs derived from the database schema. For each query, a tuple is drawn from inner join results, the number of predicates is randomly chosen (between 2 and the number of available columns), specific columns are randomly selected, and appropriate comparison operators (range or equality) are assigned. This method creates a comprehensive set of multi-predicate queries with varying cardinalities that cover the query space effectively."
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "a description of the encoding process",
        "Reasoning": "The study encodes the samples using a new query featurization method that leverages the semantic information contained in the database and captures real dependent relationships between table columns to encode the queries into more informative feature vectors. The encoding process involves several steps, including tables encoding, joins encoding, columns encoding, and basic statistical information. Tables encoding is based on a graph embedding method that captures semantic information of the database tables and achieves more accurate encoding results than widely used one-hot encoding and binary encoding methods. Joins encoding is based on the proposed Joins2Vec algorithm to featurize joins into vectors. Columns encoding is done using the Columns2Vec method, which encodes the columns by using real correlations among the columns. The study also collects statistics of the database tables (e.g., row counts and domain bounds) to represent the point predicate and/or range predicate of a query.",
        "Evidence": "Model Training Model Model Design Dataset Training Inference Before using the model M to estimate the cardinality, we must convert input queries into vectors. A query \ud835\udc5e can be represented as: \u27e8\ud835\udc47\ud835\udc4e\ud835\udc4f\ud835\udc59\ud835\udc52\ud835\udc60\u27e9, \u27e8\ud835\udc3d\ud835\udc5c\ud835\udc56\ud835\udc5b\ud835\udc60\u27e9, \u27e8\ud835\udc36\ud835\udc5c\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5b\ud835\udc60\u27e9, and \u27e8\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\ud835\udc60\u27e9. Each of them is represented by a vector. These four vectors combined together is the outcome of the query featurization for \ud835\udc5e. The result is directly plugged into the model for both training and inference. Section 3.1 introduces how to encode \u27e8\ud835\udc47\ud835\udc4e\ud835\udc4f\ud835\udc59\ud835\udc52\ud835\udc60\u27e9 and \u27e8\ud835\udc3d\ud835\udc5c\ud835\udc56\ud835\udc5b\ud835\udc60\u27e9 into vectors; Sec- tion 3.2 introduces the method to encode \u27e8\ud835\udc36\ud835\udc5c\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5b\ud835\udc60\u27e9; and Section 3.3 introduces how to represent \u27e8\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\ud835\udc60\u27e9 of a query. Schema ... T1 Tn Algorithm 1: Joins2Vec(\ud835\udc3d\ud835\udc46,\ud835\udc37,\ud835\udf06,\ud835\udf16) Figure 1: Overview of Fauce. The Query Featurization (\u00a73) transforms the queries into vectors, it includes Tables En- coding (\u00a73.1), Joins Encoding (\u00a73.1), Columns Encoding (\u00a73.2), and basic statistical information (\u00a73.3). The generated training dataset (\u00a74.2) is used to train the appropriately designed regression model (\u00a75). At last, the trained model is used to estimate the query cardinalities (\u00a75.2). The input of the model M must be a real-valued vector. Therefore, we must transform the query \ud835\udc5e into a real-valued vector which represents the features of \ud835\udc5e. This transformation is called query featurization. For a query \ud835\udc5e = \u27e8\ud835\udc47\ud835\udc4e\ud835\udc4f\ud835\udc59\ud835\udc52\ud835\udc60\u27e9, \u27e8\ud835\udc3d\ud835\udc5c\ud835\udc56\ud835\udc5b\ud835\udc60\u27e9, \u27e8\ud835\udc36\ud835\udc5c\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5b\ud835\udc60\u27e9, \u27e8\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\ud835\udc60\u27e9, we transform \ud835\udc5e into a query feature vector \ud835\udc53(cid:174) = \u27e8\ud835\udc53 \ud835\udc47, \ud835\udc53 \ud835\udc3d, \ud835\udc53 \ud835\udc36, \ud835\udc53 \ud835\udc49\u27e9, where \ud835\udc53 \ud835\udc47, \ud835\udc53 \ud835\udc3d, \ud835\udc53 \ud835\udc36, and \ud835\udc53 \ud835\udc49 are the features extracted from \u27e8\ud835\udc47\ud835\udc4e\ud835\udc4f\ud835\udc59\ud835\udc52",
        "correct_short_answer": "The study encodes query samples through a novel query featurization method that transforms queries into informative feature vectors. Instead of using traditional one-hot or binary encoding, Fauce employs a graph-based approach that captures semantic relationships. Tables are encoded using a graph embedding method based on the join schema, joins are encoded using a custom Joins2Vec algorithm that represents join relationships as vectors, and columns are encoded through a Columns2Vec method that builds dependency graphs to capture real correlations between database columns. These encoding methods, combined with statistical information about predicate values, create comprehensive feature vectors that better represent query characteristics for the regression model."
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions the incorporation of uncertainty information into the deep learning model to boost estimation results and make the model robust for dynamic databases.",
        "Evidence": "Fauce also includes a new learning paradigm that leverages the uncertainties to boost the estimation results and make Fauce robust to be applied in dynamic databases.",
        "correct_short_answer": "Yes"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention whether generalization to out-of-distribution is recognized as a criterion for robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Yes"
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not explicitly mention evaluating generalization to out-of-distribution data.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Yes"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Other",
        "Reasoning": "The study uses a deep ensemble model with uncertainty, which is not explicitly listed among the provided options.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Multi-layer Perceptron (MLP)"
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "No",
        "Reasoning": "The primary motivation behind the design of Fauce and its encoding scheme was to improve the accuracy of cardinality estimation by capturing real inter-column and inter-table correlations, and to incorporate uncertainty information into the model. Robustness is mentioned as a beneficial outcome but not the primary motivation.",
        "Evidence": "Fauce learns the correlations across all columns and all tables in the database. It also contains the uncertainty information of each estimation. Among all studied learned estimators, our results are promising: (1) Fauce is a light-weight estimator, it has 10\u00d7 faster inference speed than the state of the art estimator; (2) Fauce is robust to the complex queries, it provides 1.3\u00d7-6.7\u00d7 smaller estimation errors for complex queries compared with the state of the art estimator; (3) To the best of our knowledge, Fauce is the first estimator that incorporates uncertainty information for cardinality estimation into a deep learning model.",
        "correct_short_answer": "Yes"
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": "a list of the techniques used",
        "Reasoning": "The study mentions the use of adversarial training to improve the model's robustness.",
        "Evidence": "To improve the model\u2019s robustness, Fauce also includes the adversarial training. In particular, we use the fast gradient sign method[15] to generate adversarial query examples.",
        "correct_short_answer": [
          "Deep ensembles",
          "Uncertainty quantification",
          "Adversarial training",
          "Dropout for incremental learning",
          "Query buffer for high-uncertainty cases",
          "Sampling-based data generation for high-uncertainty scenarios",
          "Incremental learning strategy",
          "Hierarchical dependency graphs for feature representation"
        ]
      }
    }
  },
  "Identifying Robust Plans through Plan Diagram Reduction.pdf.json": {
    "metadata": {
      "paper_id": "41",
      "pdf_filename": "Identifying Robust Plans through Plan Diagram Reduction.pdf",
      "title": "Identifying robust plans through plan diagram reduction",
      "authors": "Harish, D.; Darera, P.N.; Haritsa, J.R.",
      "year": "2008"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study introduces the concept of Selectivity-Estimate-Error-Resistance (SEER) as a new strategy for identifying robust plans that can be directly used on operational database environments. It also defines a Selectivity Error Resistance Factor (SERF) to quantitatively capture the effectiveness of the replacement plan in closing the performance gap due to selectivity errors.",
        "Evidence": "The SEER Algorithm. In this paper, we present SEER (Selectivity-Estimate-Error-Resistance), anewstrategyforidentifyingrobustplansthatcanbedirectlyusedonoperationaldatabase environments... Error Resistance Metric. Given an estimated query location q e andanactuallocationq a, theSelectivityErrorResistanceFactor (SERF) of a replacement plan P w.r.t. the optimal plan P is definedas, SERF(q e,q a)=1\u2212 (1+c r \u03bbe )( cq oa e) (q\u2212 a)c o \u2212a( cq oa a) (q a)",
        "correct_short_answer": "Yes"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "concise definition(s) of robustness",
        "Reasoning": "The study defines robustness as identifying plans that provide comparatively good performance over large regions of the selectivity space, aiming for resistance rather than cure by identifying plans that are relatively less sensitive to selectivity errors.",
        "Evidence": "Estimates of predicate selectivities by database query optimizers often differ significantly from those actually encountered during query execution, leading to poor plan choices and inflated response times. In this paper, we investigate mitigating this problem by replacing selectivity error-sensitive plan choices with alternative plans that provide robust performance. Our approach is based on the recent observation that even the complex and dense \u201cplan diagrams\u201d associated with industrial-strength optimizers can be efficiently reduced to \u201canorexic\u201d equivalents featuring only a few plans, without materially impacting query processing quality. Extensive experimentation with a rich set of TPC-H and TPC-DS-based query templates in a variety of database environments indicates that plan diagram reduction typically retains plans that are substantially resistant to selectivity errors on the base relations. However, it can sometimes also be severely counter-productive, with the replacements performing much worse. We address this problem through a generalized mathematical characterization of plan cost behavior over the parameter space, which lends itself to efficient criteria of when it is safe to reduce. Our strategies are fully non-invasive and have been implemented in the Picasso optimizer visualization tool.",
        "correct_short_answer": "The paper defines a robust query execution plan as one that maintains good performance across a wide range of selectivity values, even when actual selectivities at runtime differ significantly from the optimizer's estimates. Rather than just focusing on optimality at a single estimated point, robustness involves stability across the selectivity space. The authors measure this using their Selectivity Error Resistance Factor (SERF), which quantifies how well a replacement plan bridges the performance gap between the original plan and the truly optimal plan at various selectivity values."
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "No Definitions Provided",
        "Reasoning": "The study does not provide a new definition of robustness that applies to a specific scope such as join ordering, cardinality estimation, cost model, plan optimization, workload management, DBMS (end-to-end), or ML models.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "plan optimization"
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper explicitly mentions 'robustness' in the context of query optimization and processing. It discusses identifying robust plans that are resistant to selectivity errors, which are a common cause of poor plan choices by database optimizers.",
        "Evidence": "Errors in selectivity estimates are well-documented causes of poor plan choices by database optimizers. In this paper, we investigated whether the optimizer\u2019s choices could be replaced by alternative plans, more resilient to these errors, from the paramet- ter of plans.",
        "correct_short_answer": "Yes"
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study introduces a novel strategy called SEER for identifying robust plans and defines a new metric, SERF, to quantify the effectiveness of these plans. These contributions advance the theoretical understanding of robustness in query optimization.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Yes"
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study includes extensive experimentation with a rich set of TPC-H and TPC-DS-based query templates in a variety of database environments, indicating that plan diagram reduction typically retains plans that are substantially resistant to selectivity errors on the base relations.",
        "Evidence": "Extensive experimentation with a rich set of TPC-H and TPC-DS-based query templates in a variety of database environments indicates that plan diagram reduction typically retains plans that are substantially resistant to selectivity errors on the base relations.",
        "correct_short_answer": "Yes"
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through extensive experimentation with TPC-H and TPC-DS-based query templates in various database environments. It also introduces the Selectivity Error Resistance Factor (SERF) as a metric to quantify the effectiveness of replacement plans in closing the performance gap due to selectivity errors.",
        "Evidence": "Extensive experimentation with a rich set of TPC-H and TPC-DS-based query templates in a variety of database environments indicates that plan diagram reduction typically retains plans that are substantially resistant to selectivity errors on the base relations... Error Resistance Metric. Given an estimated query location q e andanactuallocationq a, theSelectivityErrorResistanceFactor (SERF) of a replacement plan P w.r.t. the optimal plan P is definedas, SERF(q e,q a)=1\u2212 (1+c r \u03bbe )( cq oa e) (q\u2212 a)c o \u2212a( cq oa a) (q a)",
        "correct_short_answer": "experimental evaluation"
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "a summary of the proposed approach",
        "Reasoning": "The study improves robustness by introducing the SEER strategy, which identifies robust plans that are less sensitive to selectivity errors. It also defines the SERF metric to quantify the effectiveness of these plans and uses plan diagram reduction to retain plans that are resistant to selectivity errors.",
        "Evidence": "The SEER Algorithm. In this paper, we present SEER (Selectivity-Estimate-Error-Resistance), anewstrategyforidentifyingrobustplansthatcanbedirectlyusedonoperationaldatabase environments... Error Resistance Metric. Given an estimated query location q e andanactuallocationq a, theSelectivityErrorResistanceFactor (SERF) of a replacement plan P w.r.t. the optimal plan P is definedas, SERF(q e,q a)=1\u2212 (1+c r \u03bbe )( cq oa e) (q\u2212 a)c o \u2212a( cq oa a) (q a)... Extensive experimentation with a rich set of TPC-H and TPC-DS-based query templates in a variety of database environments indicates that plan diagram reduction typically retains plans that are substantially resistant to selectivity errors on the base relations.",
        "correct_short_answer": "The study improves robustness through the SEER (Selectivity-Estimate-Error-Resistance) algorithm, which replaces error-sensitive plan choices with more stable alternatives. SEER works by reducing complex plan diagrams (visual representations of optimizer plan choices across the selectivity space) to simpler anorexic versions containing fewer plans. "
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "a list of the measures used",
        "Reasoning": "The study uses the Selectivity Error Resistance Factor (SERF) as a measure to evaluate robustness. SERF quantifies the effectiveness of replacement plans in closing the performance gap due to selectivity errors.",
        "Evidence": "Error Resistance Metric. Given an estimated query location q e andanactuallocationq a, theSelectivityErrorResistanceFactor (SERF) of a replacement plan P w.r.t. the optimal plan P is definedas, SERF(q e,q a)=1\u2212 (1+c r \u03bbe )( cq oa e) (q\u2212 a)c o \u2212a( cq oa a) (q a)",
        "correct_short_answer": "Selectivity Error Resistance Factor (SERF)"
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": "[TPC-H, TPC-DS]",
        "Reasoning": "The study mentions using TPC-H and TPC-DS-based query templates for extensive experimentation in various database environments.",
        "Evidence": "Extensive experimentation with a rich set of TPC-H and TPC-DS-based query templates in a variety of database environments indicates that plan diagram reduction typically retains plans that are substantially resistant to selectivity errors on the base relations.",
        "correct_short_answer": ["TPC-H", "TPC-DS"]
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Synthetic",
        "Reasoning": "The study uses TPC-H and TPC-DS benchmarks, which are synthetic benchmarks designed to evaluate the performance of decision support systems.",
        "Evidence": "Extensive experimentation with a rich set of TPC-H and TPC-DS-based query templates in a variety of database environments indicates that plan diagram reduction typically retains plans that are substantially resistant to selectivity errors on the base relations.",
        "correct_short_answer": "Synthetic"
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not explicitly mention controlling specific characteristics in training data, query, or plan generation.",
        "Evidence": "Not Applicable",
        "correct_short_answer": [
          "Query location distribution",
          "Physical design configurations",
          "Query template dimensionality",
          "Cost-increase threshold",
          "Database size and distribution"
        ]
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "Reasoning": "The experiments are designed to evaluate the robustness of query plans by assessing their resistance to selectivity errors and comparing the performance of replacement plans.",
        "Evidence": "Extensive experimentation with a rich set of TPC-H and TPC-DS-based query templates in a variety of database environments indicates that plan diagram reduction typically retains plans that are substantially resistant to selectivity errors on the base relations.",
        "correct_short_answer": "Yes"
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of machine learning in its proposed approach. It focuses on identifying robust query plans through plan diagram reduction and the SEER strategy.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning in its proposed approach, so the type of machine learning is not applicable.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use a machine learning approach, so categorizing the ML approach is not applicable.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of deep learning in its proposed approach. It focuses on identifying robust query plans through plan diagram reduction and the SEER strategy.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of transfer learning in its proposed approach. It focuses on identifying robust query plans through plan diagram reduction and the SEER strategy.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not involve machine learning and thus does not generate training data. It focuses on identifying robust query plans through plan diagram reduction and the SEER strategy.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not involve machine learning and thus does not encode samples. It focuses on identifying robust query plans through plan diagram reduction and the SEER strategy.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention accounting for predictive uncertainties.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention recognizing generalization to out-of-distribution as a criterion for robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention evaluating generalization to out-of-distribution.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use a machine learning model in its proposed approach, so the model architecture is not applicable.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly aims to enhance robustness by identifying plans that are resistant to selectivity errors, which is the primary motivation behind the proposed approach.",
        "Evidence": "Estimates of predicate selectivities by database query optimizers often differ significantly from those actually encountered during query execution, leading to poor plan choices and inflated response times. In this paper, we investigate mitigating this problem by replacing selectivity error-sensitive plan choices with alternative plans that provide robust performance.",
        "correct_short_answer": "Yes"
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": "a list of the techniques used",
        "Reasoning": "The study mentions using techniques such as Least Expected Cost, Robust Cardinality Estimation, and Rio for improving robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": [
          "Plan diagram reduction",
          "Foreign-plan-costing feature",
          "PartialSEER variant (allowing safety in a user-defined fraction of the space)",
          "LiteSEER variant (faster alternative with less stringent replacement criteria)"
        ]
      }
    }
  },
  "Kepler Robust Learning for Faster Parametric Query Optimization.pdf.json": {
    "metadata": {
      "paper_id": "49",
      "pdf_filename": "Kepler Robust Learning for Faster Parametric Query Optimization.pdf",
      "title": "Kepler: Robust Learning for Parametric Query Optimization",
      "authors": "Lyric Doshi, Vincent Zhuang, Gaurav Jain, Ryan Marcus, Haoyu Huang, Deniz Altinb\u00fcken, Eugene Brevdo, Campbell Fraser",
      "year": "2023"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The study does not introduce any new definitions for robustness.",
        "Evidence": "Not Applicable"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "The study defines robustness implicitly through the ability of the Kepler system to handle dynamic workloads and out-of-distribution (OOD) inputs by falling back to the default plan. This ensures that the system can accurately detect OOD inputs and reduce regression frequency while still preserving some speedup.",
        "correct_short_answer": "The study defines robustness implicitly, which is achieving significant speedup over the default optimizer while minimizing performance regressions",
        "Reasoning": "The study provides an implicit definition of robustness by describing how the Kepler system handles dynamic workloads and OOD inputs.",
        "Evidence": "The study defines robustness implicitly through the ability of the Kepler system to handle dynamic workloads and out-of-distribution (OOD) inputs by falling back to the default plan. This ensures that the system can accurately detect OOD inputs and reduce regression frequency while still preserving some speedup."
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "ML models",
        "correct_short_answer": "No Definitions Provided",
        "Reasoning": "The text discusses the incorporation of calibrated predictions and uncertainty estimates into Kepler models to avoid predicting significantly suboptimal plans. This indicates that the new definition applies to ML models.",
        "Evidence": "Kepler models incorporate calibrated predictions and uncertainty estimates to avoid predicting significantly suboptimal plans. Two state-of-the-art approaches for incorporating uncertainty into neural networks are ensembling and Spectral-normalized Neural Gaussian Processes (SNGPs) [23]."
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions the use of robust neural network techniques to decrease tail latency and reduce query regressions, which are directly related to the problem of robustness in query optimization and processing.",
        "Evidence": "Kepler uses robust neural network prediction techniques to decrease tail latency and reduce query regressions (i.e. worse performance than the existing query optimizer). Specifically, Kepler uses Spectral-normalized Neural Gaussian Processes (SNGPs) to accurately quantify how confident it is about a prediction, and falls back to the database\u2019s query optimizer when it is uncertain."
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "I am unable to process your request at the moment due to rate limit restrictions. Please try again later.",
        "Evidence": ""
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The text mentions various experiments and evaluations conducted to assess the performance of Kepler, including comparisons with baselines, ablation studies, and analyses of different components and hyperparameters. For example, it discusses experiments on out-of-distribution detection, feature selection, and the impact of training data size.",
        "Evidence": "SNGP out-of-distribution detection. Although Kepler is designed for relatively static workloads, it is robust to dynamic workloads by falling back to the default plan for out-of-distribution (OOD) inputs. We evaluate SNGP\u2019s OOD detection ability by holding out specific slices of the training distribution for an example query, q21_2 on Stack. We consider two variants: (1) holding out sites totaling up to 20% of the workload, and (2) holding out the last 20% of last_activity_date values on the question table. Figure 14 shows that in both scenarios, Kepler\u2019s fallback mechanism allows it to accurately detect OOD inputs and drastically reduce \ud835\udc43reg while still preserving some speedup. Raw parameter values vs selectivity features. In Figure 15a, we ablate our feature choice using raw features and selectivity features. We compare their model speedups to \ud835\udc46\ud835\udc45\ud835\udc36\ud835\udc38 on a subset of Stack queries. Selectivity features perform far worse due to the poor cardinality estimates in PostgreSQL. Vocabulary. In Figure 15b, we ablate how we select the embedding vocabulary for string features. In particular, we evaluate our max marginal improvement method (described in Section 6) against choosing the most frequent values based on the PostgreSQL histogram. Our results confirm that the best strategy is choosing the vocabulary to be the values with the most potential impact on the speedup. How much training data is required? We evaluate the performance of our models when using less data by subsampling the training data size, as shown in Figure 16. As expected, model speedup improves with more training data while maintaining a regression frequency below 0.2%. The leftmost point uses only 5% of the data, or 200 training query instances, demonstrating that a large amount of speedup can be robustly captured with small amounts of training data."
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "correct_short_answer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation. This is evident from the various experiments and results presented, such as the comparison of RCE speedups on different datasets (TPC-H and Stack), the use of SNGP for out-of-distribution detection, and the analysis of model speedup and regression frequency.",
        "Evidence": "Figure 5b confirms that the Kepler deployment achieves near-identical speedups to those expected based on the pre-collected execution dataset. This is because the use of lightweight ML models and planning hints incur low planning-time overhead. Figure 5c shows the distribution of the ratio of model inference times to PostgreSQL planning time for all queries in Stack. The model inference time is mostly under 5% of PostgreSQL planning time and at most 30%. Our total speedup results over entire workloads are quite significant since our workloads\u2013query instances sampled uniformly from the space of non-empty query instances\u2013are not designed to adversarially challenge the optimizer. Next, we summarize the contributions from the two key components: (1) RCE to uncover the potential speedups and (2) the ML models to capture speedups. Finally, we compare the results to Bao as a baseline. RCE speedups. We illustrate the efficacy of RCE by showing that it achieves large speedups on both Stack and TPC-H. Figure 6 shows the per-template SRCE and PRCE, with RCE achieving over 99 2x speedup on 31/87 queries and over 1.2x speedup on 78/87 queries. Similarly, RCE improves 6/22 queries on TPC-H uniform (Figure 7a) and 9/22 queries on TPC-H skewed (Figure 7b). In particular, RCE finds larger speedups on TPC-H skewed due to the non-uniformity in its data distribution. ML models predict fastest plans and avoid regressions. Next, we show that our ML models are able to robustly capture the speedup produced by RCE, i.e. they maximize p while minimizing Preg. In Figures 8a and 8b, we plot what proportion of SRCE and PRCE on Stack were respectively captured per query. These distributions show that our models can reliably predict near-optimal plans: our models capture over 80% of SRCE on over 80% of Stack queries. In Figure 9, we plot the distribution of the ratio of model inference times to PostgreSQL planning time for all queries in Stack. The model inference time is mostly under 5% of PostgreSQL planning time and at most 30%. Our total speedup results over entire workloads are quite significant since our workloads\u2013query instances sampled uniformly from the space of non-empty query instances\u2013are not designed to adversarially challenge the optimizer. Next, we summarize the contributions from the two key components: (1) RCE to uncover the potential speedups and (2) the ML models to capture speedups. Finally, we compare the results to Bao as a baseline."
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "The study improves robustness by incorporating robust neural network prediction techniques, such as Spectral-normalized Neural Gaussian Processes (SNGPs), to accurately quantify prediction confidence and fall back to the database\u2019s query optimizer when uncertain. This approach helps decrease tail latency and reduce query regressions, ensuring that the system can handle dynamic workloads and out-of-distribution (OOD) inputs effectively.",
        "correct_short_answer": "The study improves robustness by incorporating robust neural network prediction techniques, such as Spectral-normalized Neural Gaussian Processes (SNGPs), to accurately quantify prediction confidence and fall back to the database\u2019s query optimizer when uncertain. This approach helps decrease tail latency and reduce query regressions, ensuring that the system can handle dynamic workloads and out-of-distribution (OOD) inputs effectively. The use of Row Count Evolution (RCE) to generate a diverse set of candidate plans by perturbing sub-plan cardinality estimates.",
        "Reasoning": "The study explicitly mentions the use of robust neural network techniques to decrease tail latency and reduce query regressions, which are directly related to improving robustness in query optimization and processing.",
        "Evidence": "Kepler uses robust neural network prediction techniques to decrease tail latency and reduce query regressions (i.e. worse performance than the existing query optimizer). Specifically, Kepler uses Spectral-normalized Neural Gaussian Processes (SNGPs) to accurately quantify how confident it is about a prediction, and falls back to the database\u2019s query optimizer when it is uncertain."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "The measures used to evaluate robustness include the proportion of speedups captured (SRCE and PRCE), model inference times, and the ability to handle out-of-distribution (OOD) inputs effectively.",
        "correct_short_answer": [
          "Execution speedup ratios",
          "Regression frequency",
          "Tail latency improvements"
        ],
        "Reasoning": "The study discusses various measures such as the proportion of speedups captured, model inference times, and the handling of OOD inputs to evaluate the robustness of the Kepler system.",
        "Evidence": "Next, we show that our ML models are able to robustly capture the speedup produced by RCE, i.e. they maximize p while minimizing Preg. In Figures 8a and 8b, we plot what proportion of SRCE and PRCE on Stack were respectively captured per query. These distributions show that our models can reliably predict near-optimal plans: our models capture over 80% of SRCE on over 80% of Stack queries. In Figure 9, we plot the distribution of the ratio of model inference times to PostgreSQL planning time for all queries in Stack. The model inference time is mostly under 5% of PostgreSQL planning time and at most 30%. SNGP out-of-distribution detection. Although Kepler is designed for relatively static workloads, it is robust to dynamic workloads by falling back to the default plan for out-of-distribution (OOD) inputs. We evaluate SNGP\u2019s OOD detection ability by holding out specific slices of the training distribution for an example query, q21_2 on Stack. We consider two variants: (1) holding out sites totaling up to 20% of the workload, and (2) holding out the last 20% of last_activity_date values on the question table. Figure 14 shows that in both scenarios, Kepler\u2019s fallback mechanism allows it to accurately detect OOD inputs and drastically reduce \ud835\udc43reg while still preserving some speedup."
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": ["TPC-H", "Stack"],
        "correct_short_answer": ["TPC-H", "Stack"],
        "Reasoning": "The study explicitly mentions the use of TPC-H and Stack benchmarks in the experimental evaluations.",
        "Evidence": "RCE speedups. We illustrate the efficacy of RCE by showing that it achieves large speedups on both Stack and TPC-H. Figure 6 shows the per-template SRCE and PRCE, with RCE achieving over 99 2x speedup on 31/87 queries and over 1.2x speedup on 78/87 queries. Similarly, RCE improves 6/22 queries on TPC-H uniform (Figure 7a) and 9/22 queries on TPC-H skewed (Figure 7b). In particular, RCE finds larger speedups on TPC-H skewed due to the non-uniformity in its data distribution."
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Both",
        "correct_short_answer": "",
        "Reasoning": "The text mentions the use of two benchmarks: TPC-H, which is synthetic, and Stack, which consists of real-world StackExchange data.",
        "Evidence": "We use two synthetic benchmarks: TPC-H (uniform and skewed with Zipf factor = 1, 10 GB [4]), and Stack, a database consisting of real-world StackExchange data [25]."
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in trianing data, query, or plan generation?",
        "ShortAnswer": [
          "perturbation range of sub-plans",
          "number of plans generated from a single parameter",
          "total number of plans generated",
          "adaptive timeouts",
          "plan execution reordering",
          "near-optimal plan cover",
          "tail latency reordering"
        ],
        "correct_short_answer": [
          "Perturbation hyperparameters",
          "Execution conditions (Warm-cache simulation, Adaptive timeout settings)",
          "Plan pruning criteria"
        ],
        "Reasoning": "The study mentions controlling various characteristics such as the perturbation range of sub-plans, the number of plans generated from a single parameter, and adaptive timeouts to ensure robust and efficient query optimization and plan generation.",
        "Evidence": "Not Applicable"
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The paper mentions evaluating the robustness of Kepler to dynamic workloads by falling back to the default plan for out-of-distribution (OOD) inputs. It also discusses the importance of the fallback mechanism in reducing regression frequency while preserving some speedup. Additionally, the paper highlights the use of SNGP's OOD detection ability and the robustness of the models in producing calibrated output probabilities.",
        "Evidence": "SNGP out-of-distribution detection. Although Kepler is designed for relatively static workloads, it is robust to dynamic workloads by falling back to the default plan for out-of-distribution (OOD) inputs. We evaluate SNGP\u2019s OOD detection ability by holding out specific slices of the training distribution for an example query, q21_2 on Stack. We consider two variants: (1) holding out sites totaling up to 20% of the workload, and (2) holding out the last 20% of last_activity_date values on the question table. Figure 14 shows that in both scenarios, Kepler\u2019s fallback mechanism allows it to accurately detect OOD inputs and drastically reduce \ud835\udc43reg while still preserving some speedup. Model calibration and uncertainty. We further investigate the ability of our SNGP models in producing calibrated output probabilities. In Figure 13, we plot the test workload model speedup and regression frequency as a function of confidence threshold varying from 0 (no falling back) to 1 (always falling back). The captured speedup and regression frequency both decay smoothly as a function of confidence, which allows the user to specify their tolerance for regressions."
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions the use of machine learning models, such as Spectral-normalized Neural Gaussian Processes (SNGPs), to improve query optimization and robustness.",
        "Evidence": "Kepler models incorporate calibrated predictions and uncertainty estimates to avoid predicting significantly suboptimal plans. Two state-of-the-art approaches for incorporating uncertainty into neural networks are ensembling and Spectral-normalized Neural Gaussian Processes (SNGPs) [23]."
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Supervised",
        "correct_short_answer": "Supervised",
        "Reasoning": "The study mentions the use of supervised learning techniques to train models for query optimization and robustness.",
        "Evidence": "Not Applicable"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Other",
        "correct_short_answer": "Classification",
        "Reasoning": "The paper discusses a novel approach called Kepler for robust learning in parametric query optimization, which involves generating candidate plans and using machine learning models to predict the best plan. This approach does not fit neatly into traditional categories like regression, classification, learning-to-rank, autoregression, or clustering.",
        "Evidence": "Kepler: Robust Learning for Faster Parametric Query Optimization"
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study mentions the use of deep learning techniques, such as Spectral-normalized Neural Gaussian Processes (SNGPs), to improve query optimization and robustness.",
        "Evidence": "Kepler models incorporate calibrated predictions and uncertainty estimates to avoid predicting significantly suboptimal plans. Two state-of-the-art approaches for incorporating uncertainty into neural networks are ensembling and Spectral-normalized Neural Gaussian Processes (SNGPs) [23]."
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "Unsure",
        "correct_short_answer": "No",
        "Reasoning": "The text does not provide explicit information about the use of transfer learning in the approach.",
        "Evidence": "Not Applicable"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "The study generates its training data by executing each candidate plan over a training workload to create a dataset of execution latencies for supervised best-plan prediction. The training workload can be provided by the user or captured in a DBMS query log. The study uses adaptive timeouts and constructs near-optimal plan covers to prune suboptimal plans, ensuring that the training data is both comprehensive and efficient.",
        "correct_short_answer": "The study generates its training data by using the Row Count Evolution (RCE) algorithm to produce candidate plans for each query instance, which are then executed multiple times on a training workload with adaptive timeouts simulating warm-cache conditions to record actual execution latencies.",
        "Reasoning": "The text describes the process of generating training data by executing candidate plans over a training workload and using adaptive timeouts and plan covers to prune suboptimal plans. This process is aimed at creating a dataset of execution latencies for supervised best-plan prediction.",
        "Evidence": "After generating candidate plan set \ud835\udc43, we execute each plan over a training workload to generate a dataset of execution latencies for supervised best-plan prediction. The training workload may be provided by the user or captured in a DBMS query log [34]. Rather than executing all candidate plans for each query instance, we use adaptive timeouts and construct near-optimal plan covers to prune suboptimal plans."
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "The study encodes the samples using standard preprocessing techniques for each type: embeddings for strings/low-dimensional integer features, normalization to N(0,1) for numerics, and numeric conversion for date/time features.",
        "correct_short_answer": "The study encodes the samples using standard preprocessing techniques for each type: embeddings for strings/low-dimensional integer features, normalization to N(0,1) for numerics, and numeric conversion for date/time features.",
        "Reasoning": "The text explicitly states that the study uses standard preprocessing techniques for encoding the samples, including embeddings for strings/low-dimensional integer features, normalization to N(0,1) for numerics, and numeric conversion for date/time features.",
        "Evidence": "We apply standard preprocessing techniques to each type: embeddings for strings/low-dimensional integer features, normalization to N(0,1) for numerics, and numeric conversion for date/time features."
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study mentions that Kepler models incorporate calibrated predictions and uncertainty estimates to avoid predicting significantly suboptimal plans. It specifically uses Spectral-normalized Neural Gaussian Processes (SNGPs) to efficiently estimate the uncertainty.",
        "Evidence": "Kepler models incorporate calibrated predictions and uncertainty estimates to avoid predicting significantly suboptimal plans. Two state-of-the-art approaches for incorporating uncertainty into neural networks are ensembling and Spectral-normalized Neural Gaussian Processes (SNGPs) [23]. The former trains \ud835\udc40 distinct models simultaneously and estimates the uncertainty from their joint outputs. The latter applies spectral normalization to all layers, providing a bi-Lipschitz guarantee on all intermediate representations, and uses a Gaussian process output layer to efficiently estimate the uncertainty. Since ensembling increases the training and inference cost by a linear factor \ud835\udc40, Kepler uses the SNGP approach due to its lower overhead."
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions the importance of handling out-of-distribution (OOD) inputs as a part of its robustness strategy. It evaluates SNGP\u2019s OOD detection ability by holding out specific slices of the training distribution for an example query, q21_2 on Stack, and considers two variants: holding out sites totaling up to 20% of the workload, and holding out the last 20% of last_activity_date values on the question table. The study concludes that Kepler's fallback mechanism allows it to accurately detect OOD inputs and drastically reduce Preg while still preserving some speedup.",
        "Evidence": "SNGP out-of-distribution detection. Although Kepler is designed for relatively static workloads, it is robust to dynamic workloads by falling back to the default plan for out-of-distribution (OOD) inputs. We evaluate SNGP\u2019s OOD detection ability by holding out specific slices of the training distribution for an example query, q21_2 on Stack. We consider two variants: (1) holding out sites totaling up to 20% of the workload, and (2) holding out the last 20% of last_activity_date values on the question table. Figure 14 shows that in both scenarios, Kepler's fallback mechanism allows it to accurately detect OOD inputs and drastically reduce Preg while still preserving some speedup."
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly evaluates the generalization to out-of-distribution (OOD) inputs by holding out specific slices of the training distribution and measuring the performance of the Kepler system in detecting OOD inputs and reducing regression frequency.",
        "Evidence": "SNGP out-of-distribution detection. Although Kepler is designed for relatively static workloads, it is robust to dynamic workloads by falling back to the default plan for out-of-distribution (OOD) inputs. We evaluate SNGP\u2019s OOD detection ability by holding out specific slices of the training distribution for an example query, q21_2 on Stack. We consider two variants: (1) holding out sites totaling up to 20% of the workload, and (2) holding out the last 20% of last_activity_date values on the question table. Figure 14 shows that in both scenarios, Kepler\u2019s fallback mechanism allows it to accurately detect OOD inputs and drastically reduce \ud835\udc43reg while still preserving some speedup."
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Other",
        "correct_short_answer": "Multi-layer Perceptron (MLP)",
        "Reasoning": "The paper mentions the use of simple feedforward neural networks with one output head per plan on top of a shared representation. This architecture is not explicitly listed among the provided options, hence it falls under 'Other'.",
        "Evidence": "We use simple feedforward neural networks as our base models. For inference efficiency, we consider a neural network with one output head per plan on top of a shared representation, which improves inference speed and model size over approaches that have separate models for each plan."
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions that the primary motivation behind the design of Kepler is to enhance robustness in query optimization. This is achieved through the use of robust neural network prediction techniques and a fallback mechanism to handle out-of-distribution inputs and reduce query regressions.",
        "Evidence": "Kepler uses robust neural network prediction techniques to decrease tail latency and reduce query regressions (i.e. worse performance than the existing query optimizer). Specifically, Kepler uses Spectral-normalized Neural Gaussian Processes (SNGPs) to accurately quantify how confident it is about a prediction, and falls back to the database\u2019s query optimizer when it is uncertain."
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": [
          "fallback mechanism",
          "adaptive timeouts",
          "plan execution reordering",
          "near-optimal plan cover",
          "tail latency reordering"
        ],
        "correct_short_answer": [
          "fallback mechanism",
          "adaptive timeouts",
          "plan execution reordering",
          "near-optimal plan cover",
          "tail latency reordering"
        ],
        "Reasoning": "The study mentions several techniques for improving robustness, including a fallback mechanism to handle out-of-distribution inputs, adaptive timeouts, plan execution reordering, near-optimal plan cover, and tail latency reordering.",
        "Evidence": "Kepler uses robust neural network prediction techniques to decrease tail latency and reduce query regressions (i.e. worse performance than the existing query optimizer). Specifically, Kepler uses Spectral-normalized Neural Gaussian Processes (SNGPs) to accurately quantify how confident it is about a prediction, and falls back to the database\u2019s query optimizer when it is uncertain. Rather than executing all candidate plans for each query instance, we use adaptive timeouts and construct near-optimal plan covers to prune suboptimal plans. We also reorder plan execution to quickly identify the best plan and reorder tail latency to quickly identify the worst plan."
      }
    }
  },
  "Learned Cardinalities Estimating Correlated Joins with Deep Learning.pdf.json": {
    "metadata": {
      "paper_id": "52",
      "pdf_filename": "Learned Cardinalities Estimating Correlated Joins with Deep Learning.pdf",
      "title": "Learned Cardinalities: Estimating Correlated Joins with Deep Learning",
      "authors": "Andreas Kipf and Thomas Kipf and Bernhard Radke and Viktor Leis and Peter Boncz and Alfons Kemper",
      "year": "2019"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not introduce any new definitions for robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not explicitly define robustness or risk. However, it implicitly defines robustness as the ability of the model to handle 0-tuple situations and to generalize to queries with more joins than seen during training. It also implies robustness in the model's ability to handle different query workloads and to perform well across a wide variety of settings. The study implicitly defines risk as the potential for large estimation errors, particularly in situations where no samples qualify (0-tuple situations) or when the model is applied to queries that are not in the vicinity of the training data.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "cardinality estimation",
        "Reasoning": "The paper introduces a new deep learning approach to cardinality estimation, specifically addressing the weaknesses of sampling-based estimation and capturing join-crossing correlations.",
        "Evidence": "We describe a new deep learning approach to cardinality estimation. MSCN is a multi-set convolutional network, tailored to representing relational query plans, that employs set semantics to capture query features and true cardinalities.",
        "correct_short_answer": "cardinality estimation"
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not explicitly address the problem of robustness in the context of query optimization and processing.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Yes"
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study introduces a new deep learning approach called Multi-Set Convolutional Network (MSCN) for cardinality estimation, which addresses the weaknesses of sampling-based estimation and captures join-crossing correlations. This is a significant contribution to the theory of cardinality estimation in query optimization.",
        "Evidence": "MSCN is a multi-set convolutional network, tailored to representing relational query plans, that employs set semantics to capture query features and true cardinalities. MSCN builds on sampling-based estimation, addressing its weaknesses when no sampled tuples qualify a predicate, and in capturing join-crossing correlations.",
        "correct_short_answer": "Yes"
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study includes a comprehensive experimental evaluation, comparing the performance of MSCN with other cardinality estimation methods across various datasets and query workloads. The evaluation demonstrates the effectiveness of MSCN in improving cardinality estimation accuracy and query optimization.",
        "Evidence": "We evaluate MSCN on a variety of datasets and query workloads, and show that it consistently outperforms sampling-based estimation and other learned approaches in terms of cardinality estimation accuracy and query optimization effectiveness.",
        "correct_short_answer": "Yes"
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation. It compares the performance of MSCN with other cardinality estimation methods across various datasets and query workloads, demonstrating the effectiveness of MSCN in improving cardinality estimation accuracy and query optimization.",
        "Evidence": "We evaluate MSCN on a variety of datasets and query workloads, and show that it consistently outperforms sampling-based estimation and other learned approaches in terms of cardinality estimation accuracy and query optimization effectiveness.",
        "correct_short_answer": "experimental evaluation"
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "a summary of the proposed approach",
        "Reasoning": "The study improves robustness by introducing a new deep learning approach called Multi-Set Convolutional Network (MSCN) for cardinality estimation. MSCN addresses the weaknesses of sampling-based estimation and captures join-crossing correlations, which helps in handling 0-tuple situations and generalizing to queries with more joins than seen during training.",
        "Evidence": "MSCN is a multi-set convolutional network, tailored to representing relational query plans, that employs set semantics to capture query features and true cardinalities. MSCN builds on sampling-based estimation, addressing its weaknesses when no sampled tuples qualify a predicate, and in capturing join-crossing correlations.",
        "correct_short_answer": "By using deep learning to predict query cardinalities in situations where sampling-based approaches fail, particularly in '0-tuple situations', and by learning join-crossing correlations from data."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "a list of the measures used",
        "Reasoning": "The study evaluates robustness using several measures, including the ability to handle 0-tuple situations, generalization to queries with more joins than seen during training, and performance across different query workloads.",
        "Evidence": "MSCN builds on sampling-based estimation, addressing its weaknesses when no sampled tuples qualify a predicate, and in capturing join-crossing correlations. We evaluate MSCN on a variety of datasets and query workloads, and show that it consistently outperforms sampling-based estimation and other learned approaches in terms of cardinality estimation accuracy and query optimization effectiveness.",
        "correct_short_answer": [
          "tail-end q-error",
          "performance on challenging workloads",
          "performance on 0-tuple situations",
          "generalization to out-of-distirbution"
        ]
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": ["JOB-light"],
        "Reasoning": "The study uses the JOB-light benchmark for the experimental evaluations.",
        "Evidence": "Not Applicable",
        "correct_short_answer": [
          "JOB-light",
          "Synthetic workload",
          "Scale workload"
        ]
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Real",
        "Reasoning": "The study uses the JOB-light benchmark, which is based on real-world data and queries.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Both"
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in trianing data, query, or plan generation?",
        "ShortAnswer": [
          "number of joins",
          "number of predicates",
          "predicate type",
          "literal values",
          "table references",
          "query uniqueness"
        ],
        "Reasoning": "The study controls several characteristics in the training data, query, or plan generation, including the number of joins, number of predicates, predicate type, literal values, table references, and query uniqueness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": [
          "number of joins",
          "number of predicates",
          "predicate type",
          "literal values",
          "table references",
          "query uniqueness"
        ]
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "No",
        "Reasoning": "The experiments in the study are not specifically designed to evaluate robustness. Instead, they focus on evaluating the performance of MSCN in terms of cardinality estimation accuracy and query optimization effectiveness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Yes"
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions the use of machine learning, specifically deep learning, in its proposed approach for cardinality estimation.",
        "Evidence": "We describe a new deep learning approach to cardinality estimation. [...] Estimation can be formulated as a supervised learning problem, with the input being query features and the output being the estimated cardinality.",
        "correct_short_answer": "Yes"
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Supervised",
        "Reasoning": "The study uses supervised learning for cardinality estimation, where the input is query features and the output is the estimated cardinality.",
        "Evidence": "Estimation can be formulated as a supervised learning problem, with the input being query features and the output being the estimated cardinality.",
        "correct_short_answer": "Supervised"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Regression",
        "Reasoning": "The ML approach in the study belongs to the category of regression, as it involves predicting a continuous value (cardinality) based on input features.",
        "Evidence": "Estimation can be formulated as a supervised learning problem, with the input being query features and the output being the estimated cardinality.",
        "correct_short_answer": "Regression"
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions the use of deep learning in its proposed approach for cardinality estimation.",
        "Evidence": "We describe a new deep learning approach to cardinality estimation. [...] MSCN is a multi-set convolutional network, tailored to representing relational query plans, that employs set semantics to capture query features and true cardinalities.",
        "correct_short_answer": "Yes"
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of transfer learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "a description of the data generation process",
        "Reasoning": "The study generates its training data by creating random queries based on schema information and drawing literals from actual values in the database. A training sample consists of table identifiers, join predicates, base table predicates, and the true cardinality of the query result. The query generator first uniformly draws the number of joins and then uniformly selects a table that is referenced. For each base table in the query, it uniformly draws the number of predicates and then uniformly draws the predicate type and a literal from the corresponding column. The study avoids a combinatorial explosion by only generating queries with up to two joins and lets the model generalize to more joins.",
        "Evidence": "A trainingsampleconsistsoftableidentifiers,joinpredicates,basetablepredicates,andthetruecardinalityofthequeryresult.Toavoidacombinatorialexplosion,weonlygeneratequerieswithuptotwojoinsandletthemodelgeneralizetomorejoins.Ourquerygeneratorfirstuniformlydrawsthenumberofjoins|Jq|(0\u2264|Jq|\u22642)andthenuniformlyselectsatablethatisreferencedone),addsthecorrespondingjoinedgetothequeryand(overall)repeatsthisprocess|Jq|times.Foreachbasetabletinthequery,itthenuniformlydrawsthenumberofpredicates|Pt|(0\u2264|Pt|\u2264num non-key columns).Foreachpredicate,ituniformlydrawsthepredicatetype(=,<,or>)andselectsaliteral(anactualvalue)fromthecorrespondingcolumn.Weconfiguredourquerygeneratortoonlygenerateunique queries.",
        "correct_short_answer": "Generates random queries based on schema information with literals drawn from actual DB values, executes them to get true cardinalities, and enriches with sample information."
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "a description of the encoding process",
        "Reasoning": "The study encodes the samples by evaluating the corresponding predicates on a materialized sample and annotating the query with the number of qualifying samples (0 \u2264 s \u2264 1000 for 1000 materialized samples) for each table in the query. Additionally, the study takes this idea one step further by annotating each table in a query with the positions of the qualifying samples represented as bitmaps.",
        "Evidence": "We enrich the training data with information about materialized base table samples. For each table in a query, we evaluate the corresponding predicates on a materialized sample and annotate the query with the number of qualifying samples (0 \u2264 s \u2264 1000 for 1000 materialized samples) for this table. We perform the same steps for an (unseen) test query at estimation time allowing the ML model to utilize this knowledge. We even take this idea one step further and annotate each table in a query with the positions of the qualifying samples represented as bitmaps.",
        "correct_short_answer": "Represents queries as collections of sets with tables encoded as one-hot vectors, joins as one-hot vectors, and predicates as a combination of one-hot encoded columns/operators with normalized values, optionally enhanced with sample bitmaps."
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study mentions that uncertainty estimation is an open question and discusses potential approaches to implement uncertainty estimation into the model. This indicates that the study does account for predictive uncertainties.",
        "Evidence": "Uncertainty estimation. An open question is when to actually trust the model and rely on its predictions. One approach is to use strict constraints for generating the training data and enforce them at runtime, i.e., only use the model when all constraints hold (i.e., only PK/FK joins, only equality predicates on certain columns). A more appealing approach would be to implement uncertainty estimation into the model. However, for a model like ours, this is a non-trivial task and still an area of active research. There are some recent methods [7,9,15] that we plan to investigate in future work.",
        "correct_short_answer": "No"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study mentions that generalizing to queries that are not in the vicinity of the training data remains challenging, indicating recognition of generalization to out-of-distribution as a criterion for robustness.",
        "Evidence": "Generalizing to queries that are not in the vicinity of the training data remains challenging.",
        "correct_short_answer": "Yes"
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study evaluates generalization to out-of-distribution by testing the model's performance on queries with more joins than seen during training and on different query workloads.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Yes"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Multi-set Convolutional Neural Network (MSCN)",
        "Reasoning": "The study proposes a new deep learning approach called Multi-Set Convolutional Network (MSCN) for cardinality estimation.",
        "Evidence": "MSCN is a multi-set convolutional network, tailored to representing relational query plans, that employs set semantics to capture query features and true cardinalities.",
        "correct_short_answer": "Multi-set Convolutional Neural Network (MSCN)"
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "No",
        "Reasoning": "The primary motivation behind the model design was to address the weaknesses of sampling-based estimation, particularly in handling 0-tuple situations and capturing join-crossing correlations. The encoding scheme was designed to represent query features using sets, which helps in generalization and reduces the model size.",
        "Evidence": "We have shown that our model can beat state-of-the-art approaches for cardinality estimation. It does a good job in addressing 0-tuple situations and in capturing join-crossing correlations, especially when combined with run-time sampling. Our query representation consists of a collection of multiple sets, which motivates the following choice for our MSCN model architecture: for every set S, we learn a set-specific, per-element neural network MLPS(vs), i.e., applied on every feature vector vs for every element s \u2208 S individually.",
        "correct_short_answer": "Yes"
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": ["run-time sampling", "set-based query representation"],
        "Reasoning": "The study uses run-time sampling to address 0-tuple situations and a set-based query representation to capture join-crossing correlations and improve generalization.",
        "Evidence": "We have shown that our model can beat state-of-the-art approaches for cardinality estimation. It does a good job in addressing 0-tuple situations and in capturing join-crossing correlations, especially when combined with run-time sampling. Our query representation consists of a collection of multiple sets, which motivates the following choice for our MSCN model architecture: for every set S, we learn a set-specific, per-element neural network MLPS(vs), i.e., applied on every feature vector vs for every element s \u2208 S individually.",
        "correct_short_answer": ""
      }
    }
  },
  "LEON A New Framework for ML-Aided Query Optimization.pdf.json": {
    "metadata": {
      "paper_id": "57",
      "pdf_filename": "LEON A New Framework for ML-Aided Query Optimization.pdf",
      "title": "LEON: ANewFrameworkforML-AidedQueryOptimization",
      "authors": "Xu Chen, Haitian Chen, Zibo Liang, Shuncheng Liu, Jinghong Wang, Kai Zeng, Han Su, Kai Zheng",
      "year": "2023"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not introduce any new definitions for robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not provide a definition for robustness or risk, either implicitly or explicitly.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "No Definitions Provided",
        "Reasoning": "The study does not provide any new definitions for robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study mentions that LEON exhibits more consistent performance and lower variability compared to other learning-based methods during the training process. This is due to its contextual learning-to-rank objective, which is inherently suited to the query optimization problem. Additionally, this objective assists in the validation and debugging of their ML models.",
        "Evidence": "In comparison to Bao and Balsa, LEON exhibits more consistent performance and lower variability. This is due to our contextual learning-to-rank objective, which is inherently suited to the query optimization problem. Additionally, this objective assists in the validation and debugging of our ML models.",
        "correct_short_answer": ""
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not provide any significant contribution to the theory.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study includes a significant experimental evaluation, as evidenced by the detailed experiments conducted on the IMDB dataset and the comparison with other methods.",
        "Evidence": "We conduct detailed experiments on the IMDB dataset and compare with other methods.",
        "correct_short_answer": ""
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation, as evidenced by the detailed experiments conducted on the IMDB dataset and the comparison with other methods.",
        "Evidence": "We conduct detailed experiments on the IMDB dataset and compare with other methods.",
        "correct_short_answer": ""
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "a summary of the proposed approach",
        "Reasoning": "The study improves robustness through several key approaches: incorporating prior knowledge to alleviate the cold-start problem, using a mixed cost model to ensure fallback to traditional query optimization, employing a contextual pairwise ranking objective and safety regularization to maintain stability, and utilizing a plan exploration strategy to enhance generalization ability.",
        "Evidence": "The study improves robustness by incorporating prior knowledge into the model, which helps to alleviate the cold-start problem and reduce the risk of unexpected performance regression during the learning process. The mixed cost model, which combines the expert cost model and the ML model, ensures that the model can fall back to the traditional query optimizer if the ML model fails. Additionally, the use of a contextual pairwise ranking objective and safety regularization in the loss function helps to maintain stability and performance throughout the training process. The plan exploration strategy, which selects plans with higher uncertainty, also contributes to the model's robustness by focusing on learning the core knowledge of the data and improving its generalization ability.",
        "correct_short_answer": ""
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "a list of the measures used",
        "Reasoning": "The study evaluates robustness using several measures, including the number of timeouts, the number of latency regressions, and the number of cost regressions.",
        "Evidence": "We report the number of timeouts, the number of latency regressions, and the number of cost regressions.",
        "correct_short_answer": ""
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": "JOB, JOB-Light, TPC-DS, TPC-H",
        "Reasoning": "The study uses the JOB, JOB-Light, TPC-DS, and TPC-H benchmarks in its experimental evaluations.",
        "Evidence": "We conduct detailed experiments on the IMDB dataset and compare with other methods. We use the JOB, JOB-Light, TPC-DS, and TPC-H benchmarks in our experiments.",
        "correct_short_answer": ""
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Real",
        "Reasoning": "The study uses the IMDB dataset, which is a real-world dataset.",
        "Evidence": "We conduct detailed experiments on the IMDB dataset and compare with other methods.",
        "correct_short_answer": ""
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not explicitly mention any characteristics that are controlled in training data, query, or plan generation.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study specifically evaluates robustness by measuring the number of timeouts, latency regressions, and cost regressions.",
        "Evidence": "We report the number of timeouts, the number of latency regressions, and the number of cost regressions.",
        "correct_short_answer": ""
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study uses machine learning in its proposed approach, as evidenced by the use of a contextual pairwise ranking objective and safety regularization in the loss function.",
        "Evidence": "The use of a contextual pairwise ranking objective and safety regularization in the loss function helps to maintain stability and performance throughout the training process.",
        "correct_short_answer": ""
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Supervised",
        "Reasoning": "The study uses supervised learning, as evidenced by the use of a contextual pairwise ranking objective and safety regularization in the loss function.",
        "Evidence": "The use of a contextual pairwise ranking objective and safety regularization in the loss function helps to maintain stability and performance throughout the training process.",
        "correct_short_answer": ""
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Learning-to-Rank",
        "Reasoning": "The study uses a contextual pairwise ranking objective, which is a characteristic of Learning-to-Rank approaches.",
        "Evidence": "The use of a contextual pairwise ranking objective and safety regularization in the loss function helps to maintain stability and performance throughout the training process.",
        "correct_short_answer": ""
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study mentions the use of deep learning models, specifically a contextual pairwise ranking objective and safety regularization in the loss function.",
        "Evidence": "The use of a contextual pairwise ranking objective and safety regularization in the loss function helps to maintain stability and performance throughout the training process.",
        "correct_short_answer": ""
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of transfer learning.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not explicitly describe the process of generating training data.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not explicitly describe the process of encoding the samples.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study accounts for predictive uncertainties by selecting plans with higher uncertainty, which helps to focus on learning the core knowledge of the data and improving the model's generalization ability.",
        "Evidence": "The plan exploration strategy, which selects plans with higher uncertainty, also contributes to the model's robustness by focusing on learning the core knowledge of the data and improving its generalization ability.",
        "correct_short_answer": ""
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study recognizes generalization to out-of-distribution as a criterion for robustness by focusing on learning the core knowledge of the data and improving the model's generalization ability.",
        "Evidence": "The plan exploration strategy, which selects plans with higher uncertainty, also contributes to the model's robustness by focusing on learning the core knowledge of the data and improving its generalization ability.",
        "correct_short_answer": ""
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not explicitly evaluate generalization to out-of-distribution.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Other",
        "Reasoning": "The study uses a model architecture that is not explicitly listed among the provided options.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "No",
        "Reasoning": "The primary motivation behind the model or encoding scheme design in the paper is to improve the performance of the query optimizer by leveraging machine learning (ML) to aid the traditional query optimizer. The focus is on enhancing the cost models, plan exploration, and overall efficiency of the query optimization process. Robustness is mentioned in the context of the traditional cost model being robust to dynamic workload and data shifting, but it is not the primary motivation for the design of LEON.",
        "Evidence": "The traditional query optimizer uses a heuristic-based cost model \ud835\udc36(\u00b7) to estimate the execution cost of plan \ud835\udc5d denoted as \ud835\udc36 : \ud835\udc5d \u2192 cost. The expert-implemented cost model also contains a large amount of knowledge. The cost model, although not accurate, is an off-the-shelf score function with decent performance. More importantly, it is robust to the dynamic workload and data shifting, which is what ML model suffers from.",
        "correct_short_answer": ""
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": "a list of the techniques used",
        "Reasoning": "The study employs various techniques to improve robustness, including ML-aided query optimization, contextual pairwise ranking objective, robust plan exploration strategy, ML model-guided pruning, prior knowledge from the traditional query optimizer, dynamic programming (DP) search, mixed cost model, uncertainty-based exploration, top-k exploration, and model updating with experience collection.",
        "Evidence": "The study employs various techniques to improve robustness, including ML-aided query optimization, contextual pairwise ranking objective, robust plan exploration strategy, ML model-guided pruning, prior knowledge from the traditional query optimizer, dynamic programming (DP) search, mixed cost model, uncertainty-based exploration, top-k exploration, and model updating with experience collection.",
        "correct_short_answer": ""
      }
    }
  },
  "LOGER A Learned Optimizer towards Generating Efficient and Robust Query Execution Plans.pdf.json": {
    "metadata": {
      "paper_id": "59",
      "pdf_filename": "LOGER A Learned Optimizer towards Generating Efficient and Robust Query Execution Plans.pdf",
      "title": "LOGER: A Learned Optimizer towards Generating Efficient and Robust Query Execution Plans",
      "authors": "Chen, T.; Chen, H.; Gao Gaojun@Pku.Edu.Cn, J.; Tu Tu.Yaofeng@Zte.Com.Cn, Y.",
      "year": "2023"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The study does not introduce any new definitions for robustness.",
        "Evidence": "Not Applicable"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "The study defines robustness implicitly as the ability of a learned optimizer to generate efficient query execution plans consistently, even in the presence of high variability in execution latency due to different join orders and physical operators. Robustness is also associated with the stability of the training process and the ability to avoid generating poor plans that can significantly degrade performance.",
        "correct_short_answer": "The study defines robustness implicitly as the ability of a learned optimizer to generate efficient query execution plans consistently, even in the presence of high variability or fluctuations in execution latency due to different join orders and physical operators. ",
        "Reasoning": "The study provides an implicit definition of robustness by describing the characteristics and behaviors associated with it.",
        "Evidence": "The study defines robustness implicitly as the ability of a learned optimizer to generate efficient query execution plans consistently, even in the presence of high variability in execution latency due to different join orders and physical operators. Robustness is also associated with the stability of the training process and the ability to avoid generating poor plans that can significantly degrade performance."
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "plan optimization",
        "correct_short_answer": "No Definitions Provided",
        "Reasoning": "The paper introduces LOGER, a learned optimizer aimed at generating efficient and robust query execution plans, which falls under the scope of plan optimization.",
        "Evidence": "LOGER: A Learned Optimizer towards Generating Efficient and Robust Query Execution Plans"
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions the challenges of robustness in query optimization due to the vast search space and highly varying execution latency. It introduces methods like \ud835\udf16-beam search and reward weighting to improve robustness.",
        "Evidence": "In this paper, we propose LOGER, a learned optimizer towards generating efficient and robust plans, aiming at producing both efficient join orders and operators. LOGER first utilizes Graph Transformer to capture relationships between tables and predicates. Then, the search space is reorganized, in which LOGER learns to restrict specific operators instead of directly selecting one for each join, while utilizing DBMS built-in optimizer to select physical operators under the restrictions. Such a strategy exploits expert knowledge to improve the robustness of plan generation while offering sufficient plan search flexibility. Furthermore, LOGER introduces \ud835\udf16-beam search, which keeps multiple search paths that preserve promising plans while performing guided exploration. Finally, LOGER introduces a loss function with reward weighting to further enhance performance robustness by reducing the fluctuation caused by poor operators, and log transformation to compress the range of rewards."
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study introduces LOGER, a learned optimizer that addresses the challenges of robustness in query optimization. It proposes novel methods like \ud835\udf16-beam search and reward weighting, which contribute to the theory of query optimization by improving the robustness and efficiency of plan generation.",
        "Evidence": "In this paper, we propose LOGER, a learned optimizer towards generating efficient and robust plans, aiming at producing both efficient join orders and operators. LOGER first utilizes Graph Transformer to capture relationships between tables and predicates. Then, the search space is reorganized, in which LOGER learns to restrict specific operators instead of directly selecting one for each join, while utilizing DBMS built-in optimizer to select physical operators under the restrictions. Such a strategy exploits expert knowledge to improve the robustness of plan generation while offering sufficient plan search flexibility. Furthermore, LOGER introduces \ud835\udf16-beam search, which keeps multiple search paths that preserve promising plans while performing guided exploration. Finally, LOGER introduces a loss function with reward weighting to further enhance performance robustness by reducing the fluctuation caused by poor operators, and log transformation to compress the range of rewards."
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The paper mentions several experiments and results, including performance evaluations on different datasets and comparisons with other methods. For example, it states, 'Experiments show that on JOB testing workload, our method can outperform traditional optimizer after about 2 hours of training, and achieve a 2.07x speedup in the end.' This indicates a significant experimental evaluation.",
        "Evidence": "page_label: 1, page_label: 10, page_label: 11, page_label: 12"
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "correct_short_answer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation. It conducts experiments to compare the performance of LOGER with other methods and demonstrates the effectiveness of its proposed techniques, such as \ud835\udf16-beam search and reward weighting, in improving robustness.",
        "Evidence": "Experiments show that on JOB testing workload, our method can outperform traditional optimizer after about 2 hours of training, and achieve a 2.07x speedup in the end."
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "The study improves robustness by introducing several key strategies: 1. Utilizing Graph Transformer (GT) to capture relationships between tables and predicates, enhancing query representation. 2. Implementing Restricted Operator Search Space (ROSS) to leverage expert knowledge from traditional optimizers, reducing search difficulty while maintaining flexibility. 3. Employing \ud835\udf16-beam search for adaptive exploration, which balances exploration and exploitation during the search process. 4. Introducing reward weighting and log transformation in the loss function to stabilize reward values and reduce the impact of poor operators on performance.",
        "correct_short_answer": "The study improves robustness by introducing several key strategies: 1. Utilizing Graph Transformer (GT) to capture relationships between tables and predicates, enhancing query representation. 2. Implementing Restricted Operator Search Space (ROSS) to leverage DBMS expertise to forbid particularly poor operators rather than selecting operators freely, reducing search risk. 3. Employing \u03b5-beam search for adaptive exploration, which combines beam search with \u03b5-greedy exploration to balance guided and random exploration across multiple paths. 4. Introducing reward weighting and log transformation in the loss function to stabilize reward values and reduce the impact of poor operators on performance.",
        "Reasoning": "The study proposes LOGER, a learned query optimizer that incorporates various techniques to enhance robustness in query optimization. These techniques include using Graph Transformer for better query representation, implementing ROSS to leverage expert knowledge, employing \ud835\udf16-beam search for adaptive exploration, and introducing reward weighting and log transformation in the loss function to stabilize performance.",
        "Evidence": "The proposed approach, LOGER, is a learned query optimizer that aims to generate efficient and robust query execution plans. It utilizes Graph Transformer (GT) to capture relationships in the join graph of each query, improving representation expressiveness. LOGER introduces Restricted Operator Search Space (ROSS) to leverage knowledge from traditional optimizers, specifying join order along with physical operator restrictions, thus enlarging the search space with a higher potential to contain efficient plans. The method employs \ud835\udf16-beam search to keep multiple search paths and perform guided exploration, balancing exploration and exploitation. Additionally, LOGER uses a loss function with reward weighting and log transformation to enhance performance robustness by reducing the fluctuation caused by poor operators and compressing the range of rewards."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "The measures used to evaluate robustness include the efficiency and stability of query execution plans, the ability to avoid generating poor plans, and the performance improvements achieved through techniques like \ud835\udf16-beam search and reward weighting.",
        "correct_short_answer": [
          "WRL (Workload Relative Latency)",
          "GMRL (Geometric Mean Relative Latency)",
          "Relative latency percentiles (25th\u201375th percentile bands)",
          "Training stability metrics (e.g. standard deviation of WRL in later epochs)"
        ],
        "Reasoning": "The study evaluates robustness by assessing the efficiency and stability of the query execution plans generated by LOGER. It focuses on the ability to avoid poor plans and the performance improvements achieved through various techniques.",
        "Evidence": "The proposed approach, LOGER, is a learned query optimizer that aims to generate efficient and robust query execution plans. It utilizes Graph Transformer (GT) to capture relationships in the join graph of each query, improving representation expressiveness. LOGER introduces Restricted Operator Search Space (ROSS) to leverage knowledge from traditional optimizers, specifying join order along with physical operator restrictions, thus enlarging the search space with a higher potential to contain efficient plans. The method employs \ud835\udf16-beam search to keep multiple search paths and perform guided exploration, balancing exploration and exploitation. Additionally, LOGER uses a loss function with reward weighting and log transformation to enhance performance robustness by reducing the fluctuation caused by poor operators and compressing the range of rewards."
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": ["JOB", "TPC-DS", "StackOverflow"],
        "correct_short_answer": ["JOB", "TPC-DS", "Stack Overflow"],
        "Reasoning": "The study uses the JOB, TPC-DS, and StackOverflow benchmarks for experimental evaluations.",
        "Evidence": "Not Applicable"
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Real",
        "correct_short_answer": "Both",
        "Reasoning": "The study uses the JOB, TPC-DS, and StackOverflow benchmarks, which are real-world benchmarks.",
        "Evidence": "Not Applicable"
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "ShortAnswer": [
          "join order",
          "physical operators",
          "search space",
          "reward function"
        ],
        "correct_short_answer": [
          "Query templates and sizes",
          "Data generation splits",
          "Plan shape restrictions",
          "Beam size scheduling",
          "Timeout limits"
        ],
        "Reasoning": "The study controls several characteristics in the training data, query, and plan generation. These include the join order, physical operators, search space, and reward function.",
        "Evidence": "The proposed approach, LOGER, is a learned query optimizer that aims to generate efficient and robust query execution plans. It utilizes Graph Transformer (GT) to capture relationships in the join graph of each query, improving representation expressiveness. LOGER introduces Restricted Operator Search Space (ROSS) to leverage knowledge from traditional optimizers, specifying join order along with physical operator restrictions, thus enlarging the search space with a higher potential to contain efficient plans. The method employs \ud835\udf16-beam search to keep multiple search paths and perform guided exploration, balancing exploration and exploitation. Additionally, LOGER uses a loss function with reward weighting and log transformation to enhance performance robustness by reducing the fluctuation caused by poor operators and compressing the range of rewards."
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions that the experiments are designed to evaluate the robustness of the proposed methods. For example, it states that the experiments aim to demonstrate the effectiveness of techniques like \ud835\udf16-beam search and reward weighting in improving robustness.",
        "Evidence": "Not Applicable"
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study proposes LOGER, a learned optimizer that utilizes deep learning techniques such as Graph Transformer (GT) and Graph Neural Networks (GNN) to improve query optimization. The method involves training models with real execution latency and employing deep reinforcement learning (DRL) for plan generation.",
        "Evidence": "We also run an experiment on JOB without left-deep restriction, and find that the performance on testing workload decreases. Searching in bushy plans space leads to a higher potential to find better plans, but it also significantly enlarges the space and makes searching for efficient plans much harder, and finally reaches a lower performance on JOB. ... Graph neural network (GNN) is a type of network that learns node representations by embedding features into graph-structured data, which supports various downstream tasks [27]. ... In LOGER, we use a join graph to represent each query and apply GT on it to produce table representations."
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Reinforcement learning",
        "correct_short_answer": "Reinforcement learning",
        "Reasoning": "The study employs deep reinforcement learning (DRL) for plan generation, which is a type of reinforcement learning.",
        "Evidence": "Not Applicable"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Learning-to-Rank",
        "correct_short_answer": "Regression",
        "Reasoning": "The study's approach involves learning to rank different query execution plans based on their efficiency and robustness, which falls under the category of Learning-to-Rank.",
        "Evidence": "Not Applicable"
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study mentions the use of deep learning techniques such as Graph Transformer (GT) and Graph Neural Networks (GNN) to improve query optimization.",
        "Evidence": "Graph neural network (GNN) is a type of network that learns node representations by embedding features into graph-structured data, which supports various downstream tasks [27]. ... In LOGER, we use a join graph to represent each query and apply GT on it to produce table representations."
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The study does not mention the use of transfer learning in its approach.",
        "Evidence": "Not Applicable"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "The study generates its training data by executing the generated plans to obtain latency values, which are then recorded in the experience dataset. The experience dataset contains a hash lookup table that records the reached lowest latency for each state-action pair. The loss function is then used to update the parameters of the value model and query representation module.",
        "correct_short_answer": "The study generates its training data by bootstrapping an experience dataset by first using the DBMS optimizer to generate expert plans for each training query, then iteratively exploring via \u03b5-beam search, executing generated plans to collect latency rewards and updating a replay buffer. ",
        "Reasoning": "The paper describes the process of generating training data in the section titled 'Model Training' on page 6. It mentions that the training data is generated by executing the generated plans to obtain latency values, which are then recorded in the experience dataset. The experience dataset contains a hash lookup table that records the reached lowest latency for each state-action pair. The loss function is then used to update the parameters of the value model and query representation module.",
        "Evidence": "Model training. After plangeneration,thegeneratedplansare executedtoobtainlatencyvalues,whicharethenrecordedinexperiencedataset.Experiencedatasetcontainsahashlookuptable\ud835\udc47 thatrecordsthereachedlowestlatencyforeachstate-actionpair ((\ud835\udc3d,\ud835\udc42),\ud835\udc4e).Asincompletesubplanslike\u25cb1 -\u25cb3 inFigure1can- notbeevaluatedalone,theirtablevalues\ud835\udc47((\ud835\udc3d,\ud835\udc42),\ud835\udc4e)areupdated withthelatencyofthecorrespondingfinalplanlike\u25cb4.Theloss functionisthenusedtoupdatetheparametersofvaluemodelandqueryrepresentationmodule."
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "Query samples are encoded as join graphs where node features combine learned table embeddings, column\u2011level statistics, and predicate vectors; a Graph Transformer produces query representations. Subplans are encoded via Tree\u2011LSTM over join trees, and restricted\u2011operator embeddings are averaged into an operator representation.",
        "Reasoning": "The study does not provide explicit information on how the samples are encoded.",
        "Evidence": "Not Applicable"
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Unsure",
        "correct_short_answer": "No",
        "Reasoning": "The study does not explicitly mention whether it accounts for predictive uncertainties.",
        "Evidence": "Not Applicable"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The text discusses various aspects of robustness in query optimization, including the handling of scattered and highly fluctuating rewards, the use of reward weighting and log transformation, and the introduction of exploration mechanisms. However, there is no explicit mention of generalization to out-of-distribution data as a criterion for robustness.",
        "Evidence": "Third, a strategy is required to deal with scattered and highly fluctuating rewards, which have a severe impact on the robustness of learned optimizers. An inefficient plan can be tens or even thousands of times more costly than a better one, leading the latency to be sparse within an extremely wide range. Meanwhile, the interaction between join order and physical operators makes the latency vary drastically. Plans with identical join order but different join operators can have distinct performances, resulting in a large variance of reward feedback in reinforcement learning, and further increasing difficulty for robust plan generation."
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The study does not explicitly mention evaluating generalization to out-of-distribution data.",
        "Evidence": "Not Applicable"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Graph Neural Network (GNN), Tree-structured Long Short-Term Memory (Tree-LSTM)",
        "correct_short_answer": "",
        "Reasoning": "The study mentions the use of Graph Neural Network (GNN) in the proposed method.",
        "Evidence": "Not Applicable"
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The text explicitly mentions that the model aims to produce both efficient join orders and operators, and it introduces strategies to deal with scattered and highly fluctuating rewards, which have a severe impact on the robustness of learned optimizers.",
        "Evidence": "Third, a strategy is required to deal with scattered and high fluctuating rewards, which have a severe impact on the robustness of learned optimizers."
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": [
          "reward weighting",
          "log transformation",
          "\ud835\udf16-beam search",
          "restricted operator search space (ROSS)"
        ],
        "correct_short_answer": [
          "restricted operator search space (ROSS)",
          "\u03b5-beam search",
          "reward weighting",
          "log transformation"
        ],
        "Reasoning": "The study mentions several techniques used to improve robustness, including reward weighting, log transformation, \ud835\udf16-beam search, and restricted operator search space (ROSS).",
        "Evidence": "Third, a strategy is required to deal with scattered and high fluctuating rewards, which have a severe impact on the robustness of learned optimizers. An inefficient plan can be tens or even thousands of times more costly than a better one, leading the latency to be sparse within an extremely wide range. Meanwhile, the interaction between join order and physical operators makes the latency vary drastically. Plans with identical join order but different join operators can have distinct performances, resulting in a large variance of reward feedback in reinforcement learning, and further increasing difficulty for robust plan generation. To address this issue, we introduce reward weighting and log transformation in the loss function to enhance performance robustness by reducing the fluctuation caused by poor operators and compressing the range of rewards."
      }
    }
  },
  "Neo A Learned Query Optimizer.pdf.json": {
    "metadata": {
      "paper_id": "65",
      "pdf_filename": "Neo A Learned Query Optimizer.pdf",
      "title": "Neo: A Learned query optimizer",
      "authors": "Marcus, R.; Negi, P.; Mao, H.; Zhang, C.; Alizadeh, M.; Kraska, T.; Papaemmanouil, O.; Tatbul, N.",
      "year": "2019"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "No",
        "Reasoning": "The text discusses the robustness of Neo, the learned query optimizer, in various contexts such as handling unseen queries and resilience to noisy inputs. However, it does not introduce any new definitions for robustness.",
        "Evidence": "Here, we test the efficacy of alternative query encoding (e.g., 1-Hot), Neo\u2019s ability to handle unseen queries invented specifically to exhibit novel behavior, and Neo\u2019s resilience to noisy inputs.",
        "correct_short_answer": "No"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not explicitly define robustness or risk. It focuses on evaluating the performance and robustness of Neo, the learned query optimizer, under various conditions, but it does not offer a specific definition of these terms.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not provided"
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "No Definitions Provided",
        "Reasoning": "The provided context does not include any new definitions or their scope.",
        "Evidence": "The text discusses various aspects of the Neo query optimizer, including its architecture, training process, and experimental results, but does not introduce any new definitions.",
        "correct_short_answer": "No Definitions Provided"
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly addresses robustness in the context of query optimization and processing. Section 6.4 is dedicated to robustness, discussing how Neo handles unseen queries, noisy inputs, and different encoding strategies. Additionally, the paper mentions that Neo is designed to be robust to estimation errors and can adapt to changes in the underlying data patterns.",
        "Evidence": "6.4 Robustness Here, we test the efficacy of alternative query encoding (e.g., 1-Hot), Neo\u2019s ability to handle unseen queries invented specifically to exhibit novel behavior, and Neo\u2019s resiliency to noisy inputs. ... Neo is able to match or exceed the performance of every optimizer on the unseen queries. ... This showcases the potential for a deep-learning powered query optimizer to keep up with changes in real-world query workloads.",
        "correct_short_answer": "Yes"
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study introduces Neo, a novel learned query optimizer that uses deep neural networks to generate query execution plans. It demonstrates that Neo can outperform or match existing commercial query optimizers, which have been tuned over decades. This represents a significant advancement in the field of query optimization.",
        "Evidence": "Neo, even when bootstrapped from a simple optimizer like PostgreSQL, can learn a model that offers similar performance to state-of-the-art commercial optimizers, and in some cases even surpasses them.",
        "correct_short_answer": "Yes"
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper explicitly mentions an experimental evaluation in Section 6, where it discusses the performance of Neo across different databases and benchmarks.",
        "Evidence": "We present an experimental evaluation of Neo in Section 6",
        "correct_short_answer": "Yes"
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness through experimental means, specifically by testing Neo's performance under various conditions such as handling unseen queries and resilience to noisy inputs.",
        "Evidence": "Here, we test the efficacy of alternative query encoding (e.g., 1-Hot), Neo\u2019s ability to handle unseen queries invented specifically to exhibit novel behavior, and Neo\u2019s resiliency to noisy inputs.",
        "correct_short_answer": "experimental evaluation"
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study discusses the robustness of Neo, the learned query optimizer, in handling unseen queries and resilience to noisy inputs. However, it does not explicitly describe a specific approach or method to improve robustness.",
        "Evidence": "Here, we test the efficacy of alternative query encoding (e.g., 1-Hot), Neo\u2019s ability to handle unseen queries invented specifically to exhibit novel behavior, and Neo\u2019s resiliency to noisy inputs.",
        "correct_short_answer": "Neo leverages reinforcement learning to iteratively retrain a deep value network that is initially bootstrapped from an expert optimizer and continuously updated using actual query latencies. This process adapts plan selection and reduces sensitivity to estimation errors. In addition, Neo employs word2vec-based row vectors to automatically capture query predicate semantics from the underlying database, allowing the model to effectively handle unseen predicates based on their semantic similarity."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study mentions evaluating robustness by testing Neo's ability to handle unseen queries and its resilience to noisy inputs. However, it does not explicitly list or describe specific measures used for this evaluation.",
        "Evidence": "Here, we test the efficacy of alternative query encoding (e.g., 1-Hot), Neo\u2019s ability to handle unseen queries invented specifically to exhibit novel behavior, and Neo\u2019s resiliency to noisy inputs.",
        "correct_short_answer": [
          "normalized query latency",
          "variance of cost predictions under cardinality estimation errors",
          "performance on unseen queries"
        ]
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": ["JOB", "TPC-H", "Corp"],
        "Reasoning": "The study explicitly mentions using the JOB, TPC-H, and Corp benchmarks for the experimental evaluations.",
        "Evidence": "We evaluate Neo on three benchmarks: JOB, TPC-H, and Corp.",
        "correct_short_answer": ["JOB", "Ext-JOB", "TPC-H", "Corp"]
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Both",
        "Reasoning": "The text states, 'We evaluated Neo\u2019s performance using both synthetic and real-world datasets to answer the following questions: ...' This indicates that both real and synthetic benchmarks were used.",
        "Evidence": "We evaluated Neo\u2019s performance using both synthetic and real-world datasets to answer the following questions: ...",
        "correct_short_answer": "Both"
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not explicitly mention any specific characteristics that are controlled in the training data, query, or plan generation process.",
        "Evidence": "Not Applicable",
        "correct_short_answer": [
          "preficate featurizations (via 1-Hot, Histograms, or R-Vector encodings (with join or no join))"
        ]
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study includes a section specifically dedicated to evaluating robustness, where it tests Neo's ability to handle unseen queries and its resilience to noisy inputs.",
        "Evidence": "6.4 Robustness Here, we test the efficacy of alternative query encoding (e.g., 1-Hot), Neo\u2019s ability to handle unseen queries invented specifically to exhibit novel behavior, and Neo\u2019s resiliency to noisy inputs.",
        "correct_short_answer": "Yes"
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study introduces Neo, a learned query optimizer that uses deep neural networks to generate query execution plans. This indicates the use of machine learning in the proposed approach.",
        "Evidence": "Neo, a learned query optimizer, uses deep neural networks to generate query execution plans.",
        "correct_short_answer": "Yes"
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Reinforcement learning",
        "Reasoning": "The paper mentions 'reinforcement learning' multiple times, indicating that this type of machine learning is used.",
        "Evidence": [
          "Neo required overcoming several key challenges. First, to automatically capture intuitive patterns in tree-structured query plans, we designed a value network, a deep neural network model, using tree convolution [40]. Second, to ensure the value network understands the semantics of a given database, we developed row vectors, a featurization which represents query predicates semantics automatically by using data from the underlying database. Third, we overcame reinforcement learning\u2019s infamous sample inefficiency by using a technique known as learning from demonstration [18, 36].",
          "We train the value network using the collected experience in a supervised fashion. This process involves transforming each collected query into features (Featurizer).",
          "Neo\u2019s value network can take these row vectors as inputs, and use them to identify correlations within the data and predicates with syntactically-distinct but semantically-similar values (e.g., both 'action' and 'adventure' frequently co-occur with 'superhero')."
        ],
        "correct_short_answer": "Reinforcement learning"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Other",
        "Reasoning": "The ML approach used in the study involves a value network, a deep neural network model using tree convolution, and reinforcement learning techniques. This combination does not fit neatly into standard categories like regression or classification.",
        "Evidence": [
          "Neo required overcoming several key challenges. First, to automatically capture intuitive patterns in tree-structured query plans, we designed a value network, a deep neural network model, using tree convolution [40]. Second, to ensure the value network understands the semantics of a given database, we developed row vectors, a featurization which represents query predicates semantics automatically by using data from the underlying database. Third, we overcame reinforcement learning\u2019s infamous sample inefficiency by using a technique known as learning from demonstration [18, 36].",
          "We train the value network using the collected experience in a supervised fashion. This process involves transforming each collected query into features (Featurizer).",
          "Neo\u2019s value network can take these row vectors as inputs, and use them to identify correlations within the data and predicates with syntactically-distinct but semantically-similar values (e.g., both 'action' and 'adventure' frequently co-occur with 'superhero')."
        ],
        "correct_short_answer": "Regression"
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions the use of a deep neural network model, which is a key component of deep learning.",
        "Evidence": "Neo required overcoming several key challenges. First, to automatically capture intuitive patterns in tree-structured query plans, we designed a value network, a deep neural network model, using tree convolution [40].",
        "correct_short_answer": "Yes"
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "No",
        "Reasoning": "The provided text does not mention the use of transfer learning.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not explicitly describe the process of generating training data.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Training data is generated by bootstrapping from an expert optimizer (PostgreSQL): run a sample workload to produce query plans, execute them on the target engine, and record the resulting latencies."
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "The study encodes the samples using a process that involves transforming each value in the database into an embedded vector using an off-the-shelf word2vec implementation. This process is depicted in the top half of Figure 7, where a three-layer neural network is constructed with equally-sized input and output layers. The neural network is trained to map each one-hot encoded value in the database to an output vector representing the value\u2019s context. For example, the top half of Figure 7, Example 1, shows how the embedding network is trained to map an input of \u201cA\u201d to an output vector representing \u201cC\u201d and \u201cE\u201d, corresponding to the first row in the example table. This procedure is repeated for each row in the database (e.g., Example 2). The embedding network will never achieve a high level of accuracy; the goal of the algorithm is to capture statistical relationships between database values and their context.",
        "Reasoning": "The text describes the encoding process in detail, explaining how each value in the database is transformed into an embedded vector using word2vec. The process involves training a neural network to map one-hot encoded values to output vectors representing their context.",
        "Evidence": "We first construct a three-layer neural network, called the embedding network, with equally-sized input and output layers. The neural network will be trained to map each one-hot encoded value in the database to an output vector representing the value\u2019s context. For example, the top half of Figure 7, Example 1, shows how the embedding network is trained to map an input of \u201cA\u201d to an output vector representing \u201cC\u201d and \u201cE\u201d, corresponding to the first row in the example table. For this first row, the embedding network is also trained to map \u201cC\u201d to an output vector representing \u201cA\u201d and \u201cE\u201d, as well as to map \u201cE\u201d to an output vector representing \u201cA\u201d and \u201cC\u201d. This procedure is repeated for each row in the database (e.g., Example 2). Note that the embedding network will never achieve a high level of accuracy: \u201cA\u201d may appear in multiple contexts, making this impossible. The goal of the algorithm is to capture statistical relationships between database values and their context.",
        "correct_short_answer": "Samples are encoded in two parts: (a) a query encoding that represents the join graph and predicates (using 1-Hot, Hist, or R-Vector representations) and (b) a plan encoding that converts the execution plan into a tree of vectors (capturing join types and scan types) processed via tree convolution"
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study mentions that Neo's value network is trained to predict the latency of partial and complete query plans, and it discusses the accuracy of these predictions over training iterations. This implies that the study accounts for predictive uncertainties by evaluating the performance of the value network's predictions.",
        "Evidence": "Neo\u2019s value network is responsible for accurately predicting the final latency of partial and complete query plans. We evaluated the value network\u2019s accuracy during training on the JOB dataset using PostgreSQL. After each iteration, we measured the mean squared error (MSE) of the value network\u2019s prediction vs. the true latencies of the plans produced (1) in the previous iteration and (2) in the final iteration. Figure 12c shows the results. Initially, the value network does a relatively poor job estimating the latencies of both the previous iteration and the final iteration. However, as training continues, the two curves converge. The convergence of the two curves \u2013 the value network\u2019s accuracy on the most recent iteration vs. the last iteration \u2013 is indicative that the policy is becoming stable, a desirable property that generally (but not necessarily) correlates with decreased runtime variance.",
        "correct_short_answer": "No"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "No",
        "Reasoning": "The text does not explicitly mention 'generalization to out-of-distribution' as a criterion for robustness. It discusses various aspects of Neo's performance and robustness, including its ability to generalize to unseen queries and handle estimation errors, but it does not specifically address out-of-distribution generalization.",
        "Evidence": "The text discusses Neo's ability to generalize to unseen queries and handle estimation errors, but it does not mention 'generalization to out-of-distribution' as a criterion for robustness.",
        "correct_short_answer": "Yes"
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "No",
        "Reasoning": "The text discusses Neo's ability to generalize to new queries and its performance on different datasets, but it does not explicitly mention evaluating generalization to out-of-distribution data.",
        "Evidence": "While cardinality estimation is critical to the success of traditional query optimizers [26,30], databases systems often make simplifying assumptions, such as uniformity, independence, and/or the principle of inclusion that often undermine this goal [27]. Neo, takes a different approach: instead of making simplifying assumptions about data distributions and attempting to directly estimate predicate cardinality, we build a semantically-rich, vectorized representation of query predicates that can serve as an input to Neo\u2019s value model, enabling the network to learn generalizable insights into data correlations.",
        "correct_short_answer": "Yes"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Tree-Convolutional Neural Network (TCNN)",
        "Reasoning": "The study explicitly mentions using a value network designed with tree convolution, which is a key characteristic of Tree-Convolutional Neural Networks (TCNN).",
        "Evidence": "Neo required overcoming several key challenges. First, to automatically capture intuitive patterns in tree-structured query plans, we designed a value network, a deep neural network model, using tree convolution [40].",
        "correct_short_answer": "Tree-Convolutional Neural Network (TCNN)"
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "No",
        "Reasoning": "The primary motivations mentioned in the study include capturing intuitive patterns in query plans, understanding data semantics, and overcoming sample inefficiency in reinforcement learning. Robustness is evaluated but is not explicitly stated as the primary motivation behind the model or encoding scheme design.",
        "Evidence": "Neo required overcoming several key challenges. First, to automatically capture intuitive patterns in tree-structured query plans, we designed a value network, a deep neural network model, using tree convolution [40]. Second, to ensure the value network understands the semantics of a given database, we developed row vectors, a featurization which represents query predicates semantics automatically by using data from the underlying database. Third, we overcame reinforcement learning\u2019s infamous sample inefficiency by using a technique known as learning from demonstration [18, 36].",
        "correct_short_answer": "No"
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not explicitly mention any specific techniques used for improving robustness beyond the general evaluation of Neo's performance under various conditions.",
        "Evidence": "Not Applicable",
        "correct_short_answer": [
          "Bootstrapping from an expert optimizer",
          "reinforcement learning with iterative value model retraining",
          "advanced query predicate encodings (R-Vector)",
          "tree convolution\u2013based plan encoding",
          "best-first plan search"
        ]
      }
    }
  },
  "Plan Bouquets A Fragrant Approach to Robust Query Processing.pdf.json": {
    "metadata": {
      "paper_id": "75",
      "pdf_filename": "Plan Bouquets A Fragrant Approach to Robust Query Processing.pdf",
      "title": "Plan bouquets: A fragrant approach to robust query processing",
      "authors": "Dutt, A.; Haritsa, J.R.",
      "year": "2016"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "Yes",
        "Reasoning": "The study introduces new definitions for robustness, specifically using the notion of performance sub-optimality to characterize robustness. It defines metrics such as MSO (maximum sub-optimality) and MESO (maximum expected sub-optimality) to quantify robustness.",
        "Evidence": "Robustness can be defined in many different ways and there is no universally accepted metric [Graefe et al. 2012]\u2014here, we use the notion of performance sub-optimality to characterize robustness. ... The above definitions are appropriate for the manner in which modern optimizers operate, wherein selectivity estimates are made at compile time, and a single plan is executed at runtime. ... Finally, the bouquet technique also furnishes a guarantee on its MSO performance, which is denoted by MSOg. ... the randomized variants of the bouquet algorithm are evaluated for the maximum expected sub-optimality across the ESS, defined as MESO = max (E[SubOpt(\u2217,q )]), qa\u2208ESS and the guarantee on maximum expected sub-optimality is denoted by MESOg.",
        "correct_short_answer": ""
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)? (Valid short answers: concise definition(s) of robustness, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "The study defines robustness as the worst-case sub-optimality in plan performance that can arise due to selectivity errors, denoted as MSO (maximum sub-optimality).",
        "Reasoning": "The study explicitly defines robustness using the concept of maximum sub-optimality (MSO), which measures the worst-case performance degradation due to selectivity errors.",
        "Evidence": "Robustness can be defined in many different ways and there is no universally accepted metric [Graefe et al. 2012]\u2014here, we use the notion of performance sub-optimality to characterize robustness. ... The above definitions are appropriate for the manner in which modern optimizers operate, wherein selectivity estimates are made at compile time, and a single plan is executed at runtime. ... Finally, the bouquet technique also furnishes a guarantee on its MSO performance, which is denoted by MSOg. ... the randomized variants of the bouquet algorithm are evaluated for the maximum expected sub-optimality across the ESS, defined as MESO = max (E[SubOpt(\u2217,q )]), qa\u2208ESS and the guarantee on maximum expected sub-optimality is denoted by MESOg.",
        "correct_short_answer": ""
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply? (Valid short answers: join ordering, cardinality estimation, cost model, plan optimization, workload management, DBMS (end-to-end), ML models, No Definitions Provided, Unsure)",
        "ShortAnswer": "No Definitions Provided",
        "Reasoning": "The provided text does not introduce any new definitions related to join ordering, cardinality estimation, cost model, plan optimization, workload management, DBMS (end-to-end), or ML models.",
        "Evidence": "The text discusses the robustness of query processing using the plan bouquet approach, but it does not introduce any new definitions within the specified scopes.",
        "correct_short_answer": ""
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions the problem of robustness in query optimization and processing, discussing various techniques and approaches to address it.",
        "Evidence": "A considerable body of literature exists on proposals to tackle this classical problem... While these prior techniques provide novel and innovative formulations, a common limitation is their inability to furnish performance guarantees... In this article, we investigate a conceptually new approach, whereinthe compile-time estimation process is completely eschewed for error-prone selectivities.",
        "correct_short_answer": ""
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "Yes",
        "Reasoning": "The study introduces a novel approach called 'Plan Bouquets' for robust query processing, which provides performance guarantees and significantly improves robustness compared to traditional methods. This contribution is highlighted throughout the paper, particularly in the experimental evaluation sections.",
        "Evidence": "In this article, we investigate a conceptually new approach, wherein the compile-time estimation process is completely eschewed for error-prone selectivities. Instead, these selectivities are systematically discovered at runtime through a calibrated sequence of cost-limited plan executions... We also propose a suite of enhancements to the basic plan bouquet algorithm that result in significantly stronger performance guarantees... Our performance results indicate that the bouquet approach typically provides orders of magnitude improvements, as compared to the optimizer\u2019s native choices.",
        "correct_short_answer": ""
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "Yes",
        "Reasoning": "The study includes a comprehensive experimental evaluation, demonstrating the effectiveness of the proposed plan bouquet approach. The experiments cover various aspects, including performance guarantees, robustness, and comparisons with traditional methods.",
        "Evidence": "Our performance results indicate that the bouquet approach typically provides orders of magnitude improvements, as compared to the optimizer\u2019s native choices... We also propose a suite of enhancements to the basic plan bouquet algorithm that result in significantly stronger performance guarantees... In this article, we investigate a conceptually new approach, wherein the compile-time estimation process is completely eschewed for error-prone selectivities.",
        "correct_short_answer": ""
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements? (Valid short answers: experimental evaluation, theoretical evaluation, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation, comparing the performance of the proposed plan bouquet approach with traditional methods and demonstrating significant improvements in robustness.",
        "Evidence": "Our performance results indicate that the bouquet approach typically provides orders of magnitude improvements, as compared to the optimizer\u2019s native choices... We also propose a suite of enhancements to the basic plan bouquet algorithm that result in significantly stronger performance guarantees... In this article, we investigate a conceptually new approach, wherein the compile-time estimation process is completely eschewed for error-prone selectivities.",
        "correct_short_answer": ""
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness? (Valid short answers: a summary of the proposed approach, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "a summary of the proposed approach",
        "Reasoning": "The study improves robustness through a novel approach called 'Plan Bouquets,' which involves discovering error-prone selectivities at runtime through a sequence of cost-limited plan executions. This approach provides performance guarantees and significantly improves robustness compared to traditional methods.",
        "Evidence": "In this article, we investigate a conceptually new approach, wherein the compile-time estimation process is completely eschewed for error-prone selectivities. Instead, these selectivities are systematically discovered at runtime through a calibrated sequence of cost-limited plan executions... We also propose a suite of enhancements to the basic plan bouquet algorithm that result in significantly stronger performance guarantees... Our performance results indicate that the bouquet approach typically provides orders of magnitude improvements, as compared to the optimizer\u2019s native choices.",
        "correct_short_answer": ""
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)? (Valid short answers: a list of the measures used, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "a list of the measures used",
        "Reasoning": "The study uses specific measures to evaluate robustness, including MSO (maximum sub-optimality) and MESO (maximum expected sub-optimality). These metrics quantify the worst-case performance degradation due to selectivity errors.",
        "Evidence": "Robustness can be defined in many different ways and there is no universally accepted metric [Graefe et al. 2012]\u2014here, we use the notion of performance sub-optimality to characterize robustness. ... The above definitions are appropriate for the manner in which modern optimizers operate, wherein selectivity estimates are made at compile time, and a single plan is executed at runtime. ... Finally, the bouquet technique also furnishes a guarantee on its MSO performance, which is denoted by MSOg. ... the randomized variants of the bouquet algorithm are evaluated for the maximum expected sub-optimality across the ESS, defined as MESO = max (E[SubOpt(\u2217,q )]), qa\u2208ESS and the guarantee on maximum expected sub-optimality is denoted by MESOg.",
        "correct_short_answer": ""
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations? (Valid short answers: [a list of the benchmarks used], Not provided, Not Applicable, Unsure), example benchamrks: JOB, JOB-Ext, JOB-Light, TPC-DS, TPC-H, Stack, CEB, DSB, etc.",
        "ShortAnswer": "TPC-H, TPC-DS",
        "Reasoning": "The study explicitly mentions the use of TPC-H and TPC-DS benchmarks in the experimental evaluations.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic? (Valid short answers: Real, Synthetic, Both, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "Synthetic",
        "Reasoning": "The study uses TPC-H and TPC-DS benchmarks, which are synthetic benchmarks designed to evaluate the performance of database systems.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in trianing data, query, or plan generation? (Valid short answers: a list of the characteristics controlled, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not explicitly mention any characteristics controlled in training data, query, or plan generation.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "Yes",
        "Reasoning": "The text explicitly mentions that the experiments are designed to evaluate robustness. For example, it states 'We now profile for a sample query, namely 5D_DS_Q19, the percentage of locations for which BOU has a specific range of improvement over NAT. That is, the spatial distribution of enhanced robustness, SubOptworst(qa).' This indicates that robustness is a key metric being evaluated in the experiments.",
        "Evidence": "We now profile for a sample query, namely 5D_DS_Q19, the percentage of locations for which BOU has a specific range of improvement over NAT. That is, the spatial distribution of enhanced robustness, SubOptworst(qa).",
        "correct_short_answer": ""
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of machine learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used? (Valid short answers: Supervised, Unsupervised, Semi-supervised, Reinforcement learning, Other, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not mention the use of any type of machine learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong? (Valid short answers: Regression, Classification, Learning-to-Rank, Autoregression, Clustering, Other, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use any machine learning approach, so categorizing it is not applicable.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of deep learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of transfer learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data? (Valid short answers: a description of the data generation process, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not involve the generation of training data as it does not use machine learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples? (Valid short answers: a description of the encoding process, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not involve encoding samples as it does not use machine learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "Yes",
        "Reasoning": "The study mentions the use of uncertainty modeling rules to classify selectivity errors into categories ranging from 'no uncertainty' to 'very high uncertainty'.",
        "Evidence": "For this, we can leverage the approach proposed in Kabra and DeWitt [1998], wherein a set of uncertainty modeling rules are outlined to classify selectivity errors into categories ranging from 'no uncertainty' to 'very high uncertainty'.",
        "correct_short_answer": ""
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "No",
        "Reasoning": "The study does not explicitly recognize generalization to out-of-distribution as a criterion for robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "No",
        "Reasoning": "The study does not explicitly evaluate generalization to out-of-distribution.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline. (Valid short answers: Multi-layer Perceptron (MLP), Recurrent Neural Network (RNN), Multi-set Convolutional Neural Network (MSCN), Tree-Convolutional Neural Network (TCNN), Tree-structured Long Short-Term Memory (Tree-LSTM), Boosted Decision Tree (BDT), Graph Neural Network (GNN), Transformer (Trm), Other, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use any model architecture in its proposed method as it does not involve machine learning.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper explicitly discusses the importance of robustness in query processing and introduces the plan bouquet approach to improve robustness. The model is designed to handle selectivity estimation errors and provide performance guarantees, which are directly related to enhancing robustness.",
        "Evidence": "Apart from improving robustness, the bouquet mechanism has another major benefit: On a given database, the execution strategy for a particular query instance, that is, the sequence of plan executions, is repeatable across different invocations of the query instance\u2014this is in marked contrast to prior approaches wherein plan choices are influenced by the current state of the database statistics and the query construction. Such stability of performance is especially important for industrial applications, where considerable value is attributed to reproducible performance characteristics [Babcock and Chaudhuri 2005].",
        "correct_short_answer": ""
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness? (Valid short answers: a list of the techniques used, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "a list of the techniques used",
        "Reasoning": "The study uses several techniques to improve robustness, including the plan bouquet approach, which involves discovering selectivities at runtime through a sequence of cost-limited plan executions, and providing performance guarantees.",
        "Evidence": "In this article, we investigate a conceptually new approach, wherein the compile-time estimation process is completely eschewed for error-prone selectivities. Instead, these selectivities are systematically discovered at runtime through a calibrated sequence of cost-limited plan executions... We also propose a suite of enhancements to the basic plan bouquet algorithm that result in significantly stronger performance guarantees... Our performance results indicate that the bouquet approach typically provides orders of magnitude improvements, as compared to the optimizer\u2019s native choices.",
        "correct_short_answer": ""
      }
    }
  },
  "Plan Bouquets Query Processing without Selectivity Estimation.pdf.json": {
    "metadata": {
      "paper_id": "76",
      "pdf_filename": "Plan Bouquets Query Processing without Selectivity Estimation.pdf",
      "title": "Plan bouquets: Query processing without selectivity estimation",
      "authors": "Dutt, A.; Haritsa, J.R.",
      "year": "2014"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "Yes",
        "Reasoning": "The study defines robustness using the notion of performance sub-optimality to characterize robustness.",
        "Evidence": "Robustness can be defined in many different ways and there is no universally accepted metric [13] \u2013 here, we use the notion of performance sub-optimality to characterize robustness.",
        "correct_short_answer": ""
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)? (Valid short answers: concise definition(s) of robustness, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "The study defines robustness as the worst-case sub-optimality in plan performance that can occur due to selectivity errors.",
        "Reasoning": "The study explicitly defines robustness in terms of the worst-case sub-optimality in plan performance due to selectivity errors.",
        "Evidence": "The study defines robustness as the worst-case sub-optimality in plan performance that can occur due to selectivity errors.",
        "correct_short_answer": ""
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply? (Valid short answers: join ordering, cardinality estimation, cost model, plan optimization, workload management, DBMS (end-to-end), ML models, No Definitions Provided, Unsure)",
        "ShortAnswer": "No Definitions Provided",
        "Reasoning": "The study does not provide a new definition of robustness or risk that applies to a specific scope.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly addresses robustness in the context of query optimization and processing.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "Yes",
        "Reasoning": "The study introduces the concept of 'Plan Bouquets' which provides a novel approach to query processing without selectivity estimation. It presents theoretical bounds on robustness and discusses the design methodology, compile-time aspects, and run-time mechanisms. The paper also includes experimental results that demonstrate the effectiveness of the approach, contributing significantly to the theory of query processing.",
        "Evidence": "In this paper, we investigate a conceptually new approach, wherein the compile-time estimation process is completely eschewed for error-prone selectivities. Instead, these selectivities are systematically discovered at run-time through a calibrated sequence of cost-limited plan executions. In an nutshell, we attempt to side-step the selectivity estimation problem, rather than address it head-on, by adopting a \u201cseeing is believing\u201d viewpoint on these values.",
        "correct_short_answer": ""
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "Yes",
        "Reasoning": "The study includes a significant experimental evaluation, as indicated by the presence of experimental results and discussions.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements? (Valid short answers: experimental evaluation, theoretical evaluation, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation, as indicated by the presence of experimental results and discussions.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness? (Valid short answers: a summary of the proposed approach, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "a summary of the proposed approach",
        "Reasoning": "The study improves robustness by introducing the concept of 'Plan Bouquets,' which involves systematically discovering selectivities at run-time through a calibrated sequence of cost-limited plan executions. This approach aims to side-step the selectivity estimation problem by adopting a 'seeing is believing' viewpoint on these values.",
        "Evidence": "In this paper, we investigate a conceptually new approach, wherein the compile-time estimation process is completely eschewed for error-prone selectivities. Instead, these selectivities are systematically discovered at run-time through a calibrated sequence of cost-limited plan executions. In an nutshell, we attempt to side-step the selectivity estimation problem, rather than address it head-on, by adopting a \u201cseeing is believing\u201d viewpoint on these values.",
        "correct_short_answer": ""
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)? (Valid short answers: a list of the measures used, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "a list of the measures used",
        "Reasoning": "The study uses the worst-case sub-optimality in plan performance due to selectivity errors as a measure to evaluate robustness.",
        "Evidence": "The study defines robustness as the worst-case sub-optimality in plan performance that can occur due to selectivity errors.",
        "correct_short_answer": ""
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations? (Valid short answers: [a list of the benchmarks used], Not provided, Not Applicable, Unsure), example benchamrks: JOB, JOB-Ext, JOB-Light, TPC-DS, TPC-H, Stack, CEB, DSB, etc.",
        "ShortAnswer": ["TPC-H", "TPC-DS"],
        "Reasoning": "The study uses TPC-H and TPC-DS benchmarks in its experimental evaluations.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic? (Valid short answers: Real, Synthetic, Both, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "Synthetic",
        "Reasoning": "The study uses TPC-H and TPC-DS benchmarks, which are synthetic benchmarks designed to evaluate the performance of database systems.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in trianing data, query, or plan generation? (Valid short answers: a list of the characteristics controlled, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not explicitly mention any characteristics controlled in training data, query, or plan generation.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "Yes",
        "Reasoning": "The study's experiments are designed to evaluate robustness specifically, as indicated by the focus on robustness in the experimental evaluation.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of machine learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used? (Valid short answers: Supervised, Unsupervised, Semi-supervised, Reinforcement learning, Other, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong? (Valid short answers: Regression, Classification, Learning-to-Rank, Autoregression, Clustering, Other, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of deep learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of transfer learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data? (Valid short answers: a description of the data generation process, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning and therefore does not generate training data.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples? (Valid short answers: a description of the encoding process, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning and therefore does not encode samples.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention accounting for predictive uncertainties.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "No",
        "Reasoning": "The study does not recognize generalization to out-of-distribution as a criterion for robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "No",
        "Reasoning": "The study does not evaluate generalization to out-of-distribution.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline. (Valid short answers: Multi-layer Perceptron (MLP), Recurrent Neural Network (RNN), Multi-set Convolutional Neural Network (MSCN), Tree-Convolutional Neural Network (TCNN), Tree-structured Long Short-Term Memory (Tree-LSTM), Boosted Decision Tree (BDT), Graph Neural Network (GNN), Transformer (Trm), Other, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning in its proposed approach and therefore does not specify a model architecture.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design? (Valid short answers: Yes, No, Unsure)",
        "ShortAnswer": "Yes",
        "Reasoning": "The text explicitly mentions that the bouquet approach is intended to provide robustness in query processing. It states, 'The bouquet approach is intended to complementarily co-exist with the classical optimizer setup, leaving it to the user or DBA to make the choice of which system to use for a specific query instance\u2013essential factors that are likely to influence this choice are discussed in the epilogue.' This indicates that robustness is a primary motivation.",
        "Evidence": "The bouquet approach is intended to complementarily co-exist with the classical optimizer setup, leaving it to the user or DBA to make the choice of which system to use for a specific query instance\u2013essential factors that are likely to influence this choice are discussed in the epilogue.",
        "correct_short_answer": ""
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness? (Valid short answers: a list of the techniques used, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": [
          "Plan-switching approach",
          "Anorexic reduction technique",
          "Incremental bouquet maintenance strategies",
          "Selectivity injection during query optimization",
          "Cost-limited partial execution of plans",
          "Selectivity monitoring on a running basis"
        ],
        "Reasoning": "The study mentions several techniques used for improving robustness, including plan-switching, anorexic reduction, incremental bouquet maintenance, selectivity injection, cost-limited partial execution, and selectivity monitoring.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      }
    }
  },
  "Robust Query Driven Cardinality Estimation under Changing Workloads.pdf.json": {
    "metadata": {
      "paper_id": "95",
      "pdf_filename": "Robust Query Driven Cardinality Estimation under Changing Workloads.pdf",
      "title": "Robust Query Driven Cardinality Estimation under Changing Workloads",
      "authors": "Negi, P.; Marcus, R.; Wu, Z.; Madden, S.; Kipf, A.; Kraska, T.; Tatbul, N.; Alizadeh, M.",
      "year": "2023"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not introduce any new definitions for robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "concise definition(s) of robustness",
        "Reasoning": "The study explicitly defines robustness in the context of query-driven cardinality estimation models.",
        "Evidence": "Query-driven cardinality estimation models learn from a historical log of queries. They are lightweight, having low storage requirements, fast inference and training, and are easily adaptable for any kind of query. Unfortunately, such models can suffer unpredictably bad performance under workload drift, i.e., if the query pattern or data changes. This makes them unreliable and hard to deploy. We analyze the reasons why models become unpredictable due to workload drift, and introduce modifications to the query representation and neural network training techniques to make query-driven models robust to the effects of workload drift.",
        "correct_short_answer": "Robustness is defined as maintaining good performance under workload drift."
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "No Definitions Provided",
        "Reasoning": "The text does not provide any new definitions.",
        "Evidence": "The text discusses various aspects of query-driven cardinality estimation models, their challenges, and solutions, but it does not introduce any new definitions.",
        "correct_short_answer": "cardinality estimation"
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions the problem of robustness in query-driven cardinality estimation models, which are crucial for query optimization. It discusses how these models can suffer from unpredictable performance under workload drift, such as changes in query patterns or data updates, and introduces modifications to make them more robust.",
        "Evidence": "Query driven cardinality estimation models learn from a historical log of queries. They are lightweight, having low storage requirements, fast inference and training, and are easily adaptable for any kind of query. Unfortunately, such models can suffer unpredictably bad performance under workload drift, i.e., if the query pattern or data changes. This makes them unreliable and hard to deploy.",
        "correct_short_answer": "Yes"
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study introduces novel techniques and modifications to query-driven cardinality estimation models to enhance their robustness against workload drift. This contribution is significant as it addresses a critical issue in query optimization and processing, making the models more reliable and deployable.",
        "Evidence": "We analyze the reasons why models become unpredictable due to workload drift, and introduce modifications to the query representation and neural network training techniques to make query-driven models robust to the effects of workload drift.",
        "correct_short_answer": "No"
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study includes detailed experimental evaluations as evidenced by the presence of figures and discussions on results, such as Figure 10, Figure 11, and Figure 13, which show runtime performance, Q-Error distributions, and per-query results, respectively.",
        "Evidence": "Figure 10: Runtime performance on PostgreSQL of baselines, and models trained on CEB, JOB, or JOBLight-train. Figure 11: Q-Error of baselines, and models trained on CEB, and tested on CEB (left) or JOB (right). Figure 13: Per query results for models trained on JOBLight-train and evaluated on JOB.",
        "correct_short_answer": "Yes"
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluations, as indicated by the use of figures and discussions on results, such as Figure 10, Figure 11, and Figure 13, which show runtime performance, Q-Error distributions, and per-query results, respectively.",
        "Evidence": "Figure 10: Runtime performance on PostgreSQL of baselines, and models trained on CEB, JOB, or JOBLight-train. Figure 11: Q-Error of baselines, and models trained on CEB, and tested on CEB (left) or JOB (right). Figure 13: Per query results for models trained on JOBLight-train and evaluated on JOB.",
        "correct_short_answer": "experimental evaluation"
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "a summary of the proposed approach",
        "Reasoning": "The study improves robustness by introducing modifications to the query representation and neural network training techniques. These modifications include using a more expressive query representation, such as the Featurization of the query, and employing a more robust training method, such as the use of a contrastive loss function.",
        "Evidence": "We analyze the reasons why models become unpredictable due to workload drift, and introduce modifications to the query representation and neural network training techniques to make query-driven models robust to the effects of workload drift.",
        "correct_short_answer": "The study improves robustness through three main techniques: query masking during training, join bitmaps for better feature representation, and techniques to handle data updates with shuffled bitmaps"
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "a list of the measures used",
        "Reasoning": "The study uses several measures to evaluate robustness, including Q-Error, Total Runtime, Relative PostgreSQL Cost, Learning Curves, and Feature Importance.",
        "Evidence": "Q-Error, Total Runtime, Relative PostgreSQL Cost, Learning Curves, Feature Importance",
        "correct_short_answer": [
          "Q-Error",
          "Query Runtime",
          "DBMS Plan Cost",
          "Relative PostgreSQL Plan Cost",
          "Total Runtime across workloads",
          "generalization to out-of-distirbution",
          "Feature importance analyses"
        ]
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": [
          "JOB",
          "CEB",
          "JOBLight-train",
          "ErgastF1",
          "Simple-ErgastF1"
        ],
        "Reasoning": "The study uses several benchmarks to evaluate the robustness of query-driven cardinality estimation models. These benchmarks include JOB, CEB, JOBLight-train, ErgastF1, and Simple-ErgastF1.",
        "Evidence": "Figure 10: Runtime performance on PostgreSQL of baselines, and models trained on CEB, JOB, or JOBLight-train. Figure 11: Q-Error of baselines, and models trained on CEB, and tested on CEB (left) or JOB (right). Figure 13: Per query results for models trained on JOBLight-train and evaluated on JOB. Figure 14: Q-Error of models trained on ErgastF1 and evaluated on Simple-ErgastF1.",
        "correct_short_answer": ["JOB", "CEB", "JOBLight-train", "ErgastF1"]
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Real",
        "Reasoning": "The study uses real-world benchmarks such as JOB, CEB, and ErgastF1, which are based on actual datasets and query workloads.",
        "Evidence": "Figure 10: Runtime performance on PostgreSQL of baselines, and models trained on CEB, JOB, or JOBLight-train. Figure 11: Q-Error of baselines, and models trained on CEB, and tested on CEB (left) or JOB (right). Figure 13: Per query results for models trained on JOBLight-train and evaluated on JOB. Figure 14: Q-Error of models trained on ErgastF1 and evaluated on Simple-ErgastF1.",
        "correct_short_answer": "Both"
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "ShortAnswer": ["query pattern", "data changes"],
        "Reasoning": "The study controls specific characteristics such as query pattern and data changes to evaluate the robustness of query-driven cardinality estimation models under workload drift.",
        "Evidence": "Query-driven cardinality estimation models learn from a historical log of queries. They are lightweight, having low storage requirements, fast inference and training, and are easily adaptable for any kind of query. Unfortunately, such models can suffer unpredictably bad performance under workload drift, i.e., if the query pattern or data changes.",
        "correct_short_answer": [
          "Query complexity (number of joins/tables)",
          "Query templates",
          "Time period of data (for data drift scenarios)",
          "Table/column selection",
          "Filter types",
          "Correlation between variables"
        ]
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "Reasoning": "The experiments are explicitly designed to evaluate the robustness of query-driven cardinality estimation models under workload drift, as evidenced by the focus on performance under changing query patterns and data updates.",
        "Evidence": "Query-driven cardinality estimation models learn from a historical log of queries. They are lightweight, having low storage requirements, fast inference and training, and are easily adaptable for any kind of query. Unfortunately, such models can suffer unpredictably bad performance under workload drift, i.e., if the query pattern or data changes.",
        "correct_short_answer": "Yes"
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions the use of machine learning techniques, such as neural network training, to improve the robustness of query-driven cardinality estimation models.",
        "Evidence": "We analyze the reasons why models become unpredictable due to workload drift, and introduce modifications to the query representation and neural network training techniques to make query-driven models robust to the effects of workload drift.",
        "correct_short_answer": "Yes"
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Supervised",
        "Reasoning": "The study uses supervised learning for training query-driven cardinality estimation models, as evidenced by the use of a historical log of queries for training and the evaluation of model performance based on specific metrics.",
        "Evidence": "Query-driven cardinality estimation models learn from a historical log of queries. They are lightweight, having low storage requirements, fast inference and training, and are easily adaptable for any kind of query.",
        "correct_short_answer": "Supervised"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Regression",
        "Reasoning": "The study focuses on query-driven cardinality estimation models, which are typically regression models that predict the cardinality (number of results) of queries based on historical data.",
        "Evidence": "Query-driven cardinality estimation models learn from a historical log of queries. They are lightweight, having low storage requirements, fast inference and training, and are easily adaptable for any kind of query.",
        "correct_short_answer": "Regression"
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper mentions the use of deep learning models such as Multi Set Convolution Networks (MSCN) and Set Transformers, which are types of deep learning architectures.",
        "Evidence": "Query features: t,ci,t.id,ci.movie_id,t.kind Multi Set Convolution Networks Masking query features (4.2) Training query features: t,t.kind Set Transformers Shuffled Bitmaps (4.4)",
        "correct_short_answer": "Yes"
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The text does not explicitly mention the use of transfer learning.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The text does not provide explicit details on the process of generating training data.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "he study uses existing benchmark query workloads and executes them to collect both the full query cardinalities and all subplan cardinalities."
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "a description of the encoding process",
        "Reasoning": "The study encodes the samples using various techniques such as featurization of the query, masking query features, and shuffled bitmaps.",
        "Evidence": "Query features: t,ci,t.id,ci.movie_id,t.kind Multi Set Convolution Networks Masking query features (4.2) Training query features: t,t.kind Set Transformers Shuffled Bitmaps (4.4)",
        "correct_short_answer": "The study encodes queries using a combination of query features (one-hot vectors for tables, joins, and columns), data features (DBMS estimates), and sampling features (join bitmaps)."
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The text does not explicitly mention whether the study accounts for predictive uncertainties.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions the ability of the Robust-MSCN model to generalize to out-of-distribution scenarios. For example, it states that the model trained with their techniques on a simple workload (JOBLight-train) is able to generalize to the much more complex Join Order Benchmark, which includes queries with up to 16 tables. This indicates that the study recognizes generalization to out-of-distribution as a criterion for robustness.",
        "Evidence": "We show significantly greater generalization than past works across different workloads and databases. For instance, a model trained with our techniques on a simple workload (JOBLight-train), with 40\ud835\udc58 synthetically generated queries of at most 3 tables each, is able to generalize to the much more complex Join Order Benchmark, which include queries with up to 16 tables, and improve query runtimes by 2\u00d7 over PostgreSQL.",
        "correct_short_answer": "Yes"
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper explicitly mentions evaluating the generalization of models to out-of-distribution scenarios. For example, it states that 'a model trained with our techniques on a simple workload (JOBLight-train), with 40\ud835\udc58 synthetically generated queries of at most 3 tables each, is able to generalize to the much more complex Join Order Benchmark, which include queries with up to 16 tables, and improve query runtimes by 2\u00d7 over PostgreSQL.' This indicates that the paper evaluates the model's ability to generalize to out-of-distribution data.",
        "Evidence": "We show significantly greater generalization than past works across different workloads and databases. For instance, a model trained with our techniques on a simple workload (JOBLight-train), with 40\ud835\udc58 synthetically generated queries of at most 3 tables each, is able to generalize to the much more complex Join Order Benchmark, which include queries with up to 16 tables, and improve query runtimes by 2\u00d7 over PostgreSQL.",
        "correct_short_answer": "Yes"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": [
          "Multi-set Convolutional Neural Network (MSCN)",
          "Transformer (Trm)"
        ],
        "Reasoning": "The study mentions the use of Multi-set Convolutional Neural Networks (MSCN) and Set Transformers, which are types of Transformer models, in the proposed method for improving the robustness of query-driven cardinality estimation models.",
        "Evidence": "Query features: t,ci,t.id,ci.movie_id,t.kind Multi Set Convolution Networks Masking query features (4.2) Training query features: t,t.kind Set Transformers Shuffled Bitmaps (4.4)",
        "correct_short_answer": "Multi-set Convolutional Neural Network (MSCN)"
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper explicitly states that the goal is to make query-driven models robust to workload drift, which is a form of enhancing robustness. The techniques introduced, such as query masking and join bitmaps, are designed to improve the model's performance under changing workloads and data updates.",
        "Evidence": "We analyze the reasons why models become unpredictable due to workload drift, and introduce modifications to the query representation and neural network training techniques to make query-driven models robust to the effects of workload drift.",
        "correct_short_answer": "Yes"
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": ["query masking", "join bitmaps"],
        "Reasoning": "The study mentions the use of query masking and join bitmaps as techniques to improve the robustness of query-driven cardinality estimation models.",
        "Evidence": "Query features: t,ci,t.id,ci.movie_id,t.kind Multi Set Convolution Networks Masking query features (4.2) Training query features: t,t.kind Set Transformers Shuffled Bitmaps (4.4)",
        "correct_short_answer": ""
      }
    }
  },
  "Robust Query Processing.pdf.json": {
    "metadata": {
      "paper_id": "97",
      "pdf_filename": "Robust Query Processing.pdf",
      "title": "Robust query processing",
      "authors": "Karthik, S.",
      "year": "2016"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study defines robustness in query processing as the ability to avoid sudden disruptions in performance and categorizes it into three types: query optimizer robustness, query execution robustness, and workload management robustness.",
        "Evidence": "In particular, robust query processing is about performance, predictability and ability to avoid sudden disruptions in performance. ... The notion of robustness in query processing has been categorized into the following three types [16]: 1) query optimizer robustness: \u201cthe ability of the optimizer to choose a good plan as expected conditions change\u201d 2) query execution robustness: \u201cthe ability of the query execution engine to process a given plan efficiently under different runtime conditions\u201d 3) workload management robustness: \u201ccharacterizes how database system performance is vulnerable to unexpected query performance\u201d",
        "correct_short_answer": ""
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "concise definition(s) of robustness",
        "Reasoning": "The study explicitly defines robustness in the context of query processing.",
        "Evidence": "In particular, robust query processing is about performance, predictability and ability to avoid sudden disruptions in performance. ... The notion of robustness in query processing has been categorized into the following three types [16]: 1) query optimizer robustness: \u201cthe ability of the optimizer to choose a good plan as expected conditions change\u201d 2) query execution robustness: \u201cthe ability of the query execution engine to process a given plan efficiently under different runtime conditions\u201d 3) workload management robustness: \u201ccharacterizes how database system performance is vulnerable to unexpected query performance\u201d",
        "correct_short_answer": ""
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "cardinality estimation",
        "Reasoning": "The text discusses the problem of cardinality mis-estimates and their impact on query optimizer robustness. It mentions that errors in cardinality estimation can lead to sub-optimal performance by orders of magnitude. The text also discusses the reasons for error in cardinality estimation, such as coarse summaries, insufficient or stale system metadata, violation of simplifying assumptions, and complex user-defined predicates. Therefore, the new definition provided in the text applies to the scope of cardinality estimation.",
        "Evidence": "The text discusses the problem of cardinality mis-estimates and their impact on query optimizer robustness. It mentions that errors in cardinality estimation can lead to sub-optimal performance by orders of magnitude. The text also discusses the reasons for error in cardinality estimation, such as coarse summaries, insufficient or stale system metadata, violation of simplifying assumptions, and complex user-defined predicates.",
        "correct_short_answer": ""
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions 'robust query processing' and discusses various aspects of robustness in query optimization and processing, including query optimizer robustness, query execution robustness, and workload management robustness.",
        "Evidence": "In particular, robust query processing is about performance, predictability and ability to avoid sudden disruptions in performance. The importance of robustness in query processing is showcased by the fact that there have been two Dagstuhl seminars on this topic [3], [4]. Drilling down further, the notion of robustness in query processing has been categorized into the following three types [16]: 1) query optimizer robustness: \u201cthe ability of the optimizer to choose a good plan as expected conditions change\u201d 2) query execution robustness: \u201cthe ability of the query execution engine to process a given plan efficiently under different runtime conditions\u201d 3) workload management robustness: \u201ccharacterizes how database system performance is vulnerable to unexpected query performance\u201d",
        "correct_short_answer": ""
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study introduces SpillBound, a new algorithm for robust query processing that provides a platform-independent worst-case bound. This is a significant theoretical contribution as it offers a new approach to robust query processing.",
        "Evidence": "Specifically, SpillBound delivers a worst-case multiplicative bound of D2 +3D, where D is simply the number of error-prone predicates in the user query. Consequently, the bound value becomes independent of the optimizer and the database platform, and the guarantee can be issued just by inspecting the query without incurring any additional computational effort. Overall, SpillBound offers a new platform-independent approach to robust query processing.",
        "correct_short_answer": ""
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "Reasoning": "The text mentions detailed experimental evaluation of both PlanBouquet and SpillBound approaches on standard TPC-H and TPC-DS benchmark queries, operating on the PostgreSQL engine.",
        "Evidence": "Our experiments indicate that for the most part, SpillBound provides similar guarantees to PlanBouquet, and occasionally, much tighter bounds. As a case in point, for TPC-DS Query 91 with 4 error-prone predicates the MSO drops from 52.8 with PlanBouquet",
        "correct_short_answer": ""
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation. It compares the performance of PlanBouquet and SpillBound approaches using standard TPC-H and TPC-DS benchmark queries on the PostgreSQL engine.",
        "Evidence": "Our experiments indicate that for the most part, SpillBound provides similar guarantees to PlanBouquet, and occasionally, much tighter bounds. As a case in point, for TPC-DS Query 91 with 4 error-prone predicates the MSO drops from 52.8 with PlanBouquet",
        "correct_short_answer": ""
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "a summary of the proposed approach",
        "Reasoning": "The study improves robustness by introducing the SpillBound algorithm, which provides a platform-independent worst-case bound for robust query processing. This approach ensures that the bound value is independent of the optimizer and the database platform, offering a new method for robust query processing.",
        "Evidence": "Specifically, SpillBound delivers a worst-case multiplicative bound of D2 +3D, where D is simply the number of error-prone predicates in the user query. Consequently, the bound value becomes independent of the optimizer and the database platform, and the guarantee can be issued just by inspecting the query without incurring any additional computational effort. Overall, SpillBound offers a new platform-independent approach to robust query processing.",
        "correct_short_answer": ""
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "a list of the measures used",
        "Reasoning": "The study uses the Maximum Slowdown Observed (MSO) as a measure to evaluate robustness. This measure is explicitly mentioned in the context of comparing the performance of PlanBouquet and SpillBound approaches.",
        "Evidence": "Our experiments indicate that for the most part, SpillBound provides similar guarantees to PlanBouquet, and occasionally, much tighter bounds. As a case in point, for TPC-DS Query 91 with 4 error-prone predicates the MSO drops from 52.8 with PlanBouquet",
        "correct_short_answer": ""
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": "[TPC-H, TPC-DS]",
        "Reasoning": "The study explicitly mentions using TPC-H and TPC-DS benchmark queries for the experimental evaluation of the PlanBouquet and SpillBound approaches.",
        "Evidence": "Our experiments indicate that for the most part, SpillBound provides similar guarantees to PlanBouquet, and occasionally, much tighter bounds. As a case in point, for TPC-DS Query 91 with 4 error-prone predicates the MSO drops from 52.8 with PlanBouquet",
        "correct_short_answer": ""
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Synthetic",
        "Reasoning": "The study uses TPC-H and TPC-DS benchmarks, which are well-known synthetic benchmarks designed to evaluate the performance of database systems.",
        "Evidence": "Our experiments indicate that for the most part, SpillBound provides similar guarantees to PlanBouquet, and occasionally, much tighter bounds. As a case in point, for TPC-DS Query 91 with 4 error-prone predicates the MSO drops from 52.8 with PlanBouquet",
        "correct_short_answer": ""
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not explicitly mention any characteristics controlled in training data, query, or plan generation.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions that the experiments are designed to evaluate the robustness of the PlanBouquet and SpillBound approaches using standard benchmarks.",
        "Evidence": "Our experiments indicate that for the most part, SpillBound provides similar guarantees to PlanBouquet, and occasionally, much tighter bounds. As a case in point, for TPC-DS Query 91 with 4 error-prone predicates the MSO drops from 52.8 with PlanBouquet",
        "correct_short_answer": ""
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of machine learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of deep learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of transfer learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning and therefore does not generate training data.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning and therefore does not encode samples.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention whether it accounts for predictive uncertainties.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "No",
        "Reasoning": "The text discusses robustness in query processing in terms of performance, predictability, and avoiding sudden disruptions. It categorizes robustness into query optimizer robustness, query execution robustness, and workload management robustness. However, it does not mention generalization to out-of-distribution as a criterion for robustness.",
        "Evidence": "In particular, robust query processing is about performance, predictability and ability to avoid sudden disruptions in performance. The importance of robustness in query processing is showcased by the fact that there have been two Dagstuhl seminars on this topic [3], [4]. Drilling down further, the notion of robustness in query processing has been categorized into the following three types [16]: 1) query optimizer robustness: \u201cthe ability of the optimizer to choose a good plan as expected conditions change\u201d 2) query execution robustness: \u201cthe ability of the query execution engine to process a given plan efficiently under different runtime conditions\u201d 3) workload management robustness: \u201ccharacterizes how database system performance is vulnerable to unexpected query performance\u201d",
        "correct_short_answer": ""
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The text does not explicitly mention whether it evaluates generalization to out-of-distribution.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning in its proposed approach and therefore does not specify a model architecture.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions that the primary motivation behind the design of the SpillBound algorithm is to enhance robustness in query processing.",
        "Evidence": "Specifically, SpillBound delivers a worst-case multiplicative bound of D2 +3D, where D is simply the number of error-prone predicates in the user query. Consequently, the bound value becomes independent of the optimizer and the database platform, and the guarantee can be issued just by inspecting the query without incurring any additional computational effort. Overall, SpillBound offers a new platform-independent approach to robust query processing.",
        "correct_short_answer": ""
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not explicitly mention any other techniques for improving robustness beyond the SpillBound algorithm.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      }
    }
  },
  "Robustness Metrics for Relational Query Execution Plans.pdf.json": {
    "metadata": {
      "paper_id": "100",
      "pdf_filename": "Robustness Metrics for Relational Query Execution Plans.pdf",
      "title": "Robustness metrics for relational query execution plans",
      "authors": "Wolf, F.; Brendle, M.; May, N.; Willems, P.R.; Sattler, K.-U.; Grossniklaus, M.",
      "year": "2018"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study introduces several new definitions for robustness metrics, including the Parametric Cost Function (PCF), cardinality-slope robustness metric, selectivity-slope robustness metric, and cardinality-integral robustness metric.",
        "Evidence": "Definition 5. A Parametric Cost Function (PCF) is the cost of a query execution plan or sub-plan, modeled as a function of one cost parameter. Definition 9. The selectivity-slope value \u03b4 s,op for an operator op \u2208 O P is the slope of PCF s,op at the estimated selectivity s\u02c6, where PCF s,op is the PCF that models the cost for a plan P as a function of the selectivity s on op. Definition 11. The cardinality-integral value \u222b for an edge e is \u222bf\u02c6 \u2191PCF . f\u02c6 \u2193",
        "correct_short_answer": "Yes"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "concise definition(s) of robustness",
        "Reasoning": "The study provides explicit definitions for robustness in the context of query execution plans, focusing on the ability to maintain performance despite cardinality estimation errors. It introduces several metrics to quantify this robustness.",
        "Evidence": "The study defines robustness in the context of query execution plans as the ability of a plan to maintain performance despite cardinality estimation errors. It introduces metrics such as the cardinality-slope value, selectivity-slope value, and cardinality-integral value to quantify this robustness.",
        "correct_short_answer": "Robustness is the insensitivity of query execution plans to cardinality estimation errors, measured by cost error factor (ratio between true and estimated costs)"
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "No Definitions Provided",
        "Reasoning": "The provided context does not include any new definitions.",
        "Evidence": "The text discusses various aspects of query optimization and robustness metrics but does not introduce any new definitions.",
        "correct_short_answer": "plan optimization"
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "Reasoning": "The abstract and introduction sections explicitly discuss the problem of robustness in query optimization and processing. The study mentions that conventional query optimization often selects sub-optimal or bad execution plans due to errors in cardinality estimation, which is a key aspect of robustness in query processing.",
        "Evidence": "The quality of query execution plans in database systems determines how fast a query can be executed. It has been shown that conventional query optimization still selects sub-optimal or even bad execution plans, due to errors in the cardinality estimation. Although cardinality estimation errors are an evident problem, they are in general not considered in the selection of query execution plans. In this paper, we present three novel metrics for the robustness of relational query execution plans w.r.t. cardinality estimation errors.",
        "correct_short_answer": "Yes"
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper introduces three novel metrics for the robustness of query execution plans with respect to cardinality estimation errors and presents a novel plan selection strategy that takes both estimated cost and estimated robustness into account. These contributions are significant to the theory of query optimization and robustness in database systems.",
        "Evidence": "In this paper, we present three novel metrics for the robustness of query execution plans w.r.t. cardinality estimation errors. We also present a novel plan selection strategy that takes both, estimated cost and estimated robustness into account, when choosing a plan for execution.",
        "correct_short_answer": "Yes"
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "Reasoning": "The text mentions experimental evaluations in several sections, including Section 6.1 and Section 6.2, where the authors discuss the results of their experimental comparison between robust and conventional plan selection on real-world and synthetic benchmarks.",
        "Evidence": "We experimentally evaluate the plan selection strategies w.r.t. their end-to-end query execution times (Section 6.1), and plan robustness (Section 6.2).",
        "correct_short_answer": "yes"
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation. It compares the end-to-end query execution times and plan robustness of robust and conventional plan selection strategies on real-world and synthetic benchmarks.",
        "Evidence": "We experimentally evaluate the plan selection strategies w.r.t. their end-to-end query execution times (Section 6.1), and plan robustness (Section 6.2).",
        "correct_short_answer": "experimental evaluation"
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "a summary of the proposed approach",
        "Reasoning": "The study improves robustness by introducing three novel metrics to quantify the robustness of relational query execution plans. These metrics are the cardinality-slope, selectivity-slope, and cardinality-integral robustness metrics. The study also presents a new plan selection strategy that takes both estimated cost and estimated robustness into account when choosing a plan for execution. This approach aims to select plans that are less sensitive to estimation errors, thereby improving the overall robustness of query processing.",
        "Evidence": "The proposed approach involves defining three robustness metrics (cardinality-slope, selectivity-slope, and cardinality-integral) that quantify the robustness of query execution plans. These metrics consider the impact of potential cardinality estimation errors and the propagation of these errors. The approach also includes a plan selection strategy that balances plan robustness and query execution time. This strategy involves enumerating the k-cheapest plans, calculating the robustness value for each plan using one of the metrics, and selecting the plan with the smallest robustness value for execution. The study demonstrates that this approach can outperform conventional plan selection, especially in the presence of cardinality estimation errors.",
        "correct_short_answer": "The study proposes three novel robustness metrics (cardinality-slope, selectivity-slope, and cardinality-integral) to quantify plan sensitivity to estimation errors, then uses these metrics in a new plan selection strategy that considers both cost and robustness when choosing execution plans."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "a list of the measures used",
        "Reasoning": "The study explicitly mentions several measures used to evaluate robustness, including cost error factor c, cost error factor improvement \u2206, cost error factor dominance \u03c1, correlated cost error factor limit, robustness value r, cardinality-slope value \u03b4, selectivity-slope value \u03b4, cardinality-integral value \u222b, q-error, and c err.",
        "Evidence": "The study explicitly mentions several measures used to evaluate robustness, including cost error factor c, cost error factor improvement \u2206, cost error factor dominance \u03c1, correlated cost error factor limit, robustness value r, cardinality-slope value \u03b4, selectivity-slope value \u03b4, cardinality-integral value \u222b, q-error, and c err.",
        "correct_short_answer": [
          "cost error factor (c_err)",
          "cost error factor improvement (\u0394c_err)",
          "cost error factor dominance (\u03c1c_err and \u03b4c_err)",
          "end-to-end query execution time",
          "speedup/regression factors"
        ]
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": "[\"JOB\", \"Synthetic Benchmark\"]",
        "Reasoning": "The study mentions using the JOB benchmark and a synthetic benchmark for the experimental evaluations.",
        "Evidence": "The study mentions using the JOB benchmark and a synthetic benchmark for the experimental evaluations.",
        "correct_short_answer": ["JOB", "Synthetic benchmark"]
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Both",
        "Reasoning": "The paper mentions the use of both the Join Order Benchmark (JOB), which uses real-world data from IMDb, and a synthetic benchmark with generated data and join queries.",
        "Evidence": "Our first workload is based on the Join Order Benchmark (JOB) [17]. JOB uses real-world data from IMDb with skew, correlations, and different join relationships that cause estimation errors. Our second benchmark is synthetic with generated data and join queries.",
        "correct_short_answer": "Both"
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The provided text does not explicitly mention any characteristics that are controlled in training data, query, or plan generation.",
        "Evidence": "Not Applicable",
        "correct_short_answer": [
          "base table cardinalities",
          "join cardinalities",
          "skew",
          "correlations",
          "join relationships",
          "query topologies",
          "number of tables"
        ]
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "Reasoning": "The experiments are explicitly designed to evaluate robustness. The study compares the end-to-end query execution times and plan robustness of robust and conventional plan selection strategies on real-world and synthetic benchmarks.",
        "Evidence": "We experimentally evaluate the plan selection strategies w.r.t. their end-to-end query execution times (Section 6.1), and plan robustness (Section 6.2).",
        "correct_short_answer": "Yes"
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of machine learning in its proposed approach for improving robustness in query optimization.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of deep learning in its proposed approach for improving robustness in query optimization.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of transfer learning in its proposed approach for improving robustness in query optimization.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning and therefore does not generate training data.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning and therefore does not encode samples.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "No",
        "Reasoning": "The study focuses on robustness metrics for query execution plans in the presence of cardinality estimation errors but does not explicitly mention or address predictive uncertainties.",
        "Evidence": "None",
        "correct_short_answer": "Not Applicable"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention generalization to out-of-distribution as a criterion for robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not evaluate generalization to out-of-distribution.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The paper does not discuss any model architectures as it focuses on robustness metrics for relational query execution plans.",
        "Evidence": "The paper discusses robustness metrics for relational query execution plans and does not mention any model architectures.",
        "correct_short_answer": "Not Applicable"
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention the use of a model or encoding scheme, making it unclear whether enhancing robustness was the primary motivation behind their design.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Yes"
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": "[\"Parametric Cost Function (PCF)\", \"k-cheapest plans\", \"cardinality-slope robustness metric\", \"selectivity-slope robustness metric\", \"cardinality-integral robustness metric\", \"near-optimal plans\", \"dynamic programming enumeration\"]",
        "Reasoning": "The study employs several techniques to improve robustness in query optimization. These include the Parametric Cost Function (PCF), enumerating k-cheapest plans, and using robustness metrics such as cardinality-slope, selectivity-slope, and cardinality-integral. Additionally, the study considers near-optimal plans and uses dynamic programming enumeration to evaluate plan robustness.",
        "Evidence": "The study employs several techniques to improve robustness in query optimization. These include the Parametric Cost Function (PCF), enumerating k-cheapest plans, and using robustness metrics such as cardinality-slope, selectivity-slope, and cardinality-integral. Additionally, the study considers near-optimal plans and uses dynamic programming enumeration to evaluate plan robustness.",
        "correct_short_answer": ""
      }
    }
  },
  "Roq Robust Query Optimization Based on a Risk-aware Learned Cost Model.pdf.json": {
    "metadata": {
      "paper_id": "102",
      "pdf_filename": "Roq Robust Query Optimization Based on a Risk-aware Learned Cost Model.pdf",
      "title": "Roq: Robust Query Optimization Based on a Risk-aware Learned Cost Model",
      "authors": "Amin Kamali and Verena Kantere and Calisto Zuzarte and Vincent Corvinelli",
      "year": "2024"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study introduces new definitions for robustness in the context of query optimization. Specifically, it defines the notion of plan and cost model robustness and provides guidelines for their quantification.",
        "Evidence": "Section 3.1 presents a study and definitions for the notions of plan robustness and cost model robustness, and forms guidelines for the design of a robust cost model.",
        "correct_short_answer": "Yes"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "concise definition(s) of robustness",
        "Reasoning": "The study provides explicit definitions for robustness and risk. Robustness is defined in terms of the maximum suboptimality of a plan, while risk is categorized into plan risk, estimation risk, and suboptimality risk.",
        "Evidence": "A robust plan is defined as one that has limited worst-case performance degradation. This property can be characterized by the maximum Suboptimality, which is defined as the ratio of its execution cost to the cost of the optimal plan and takes a value in the range of [1,\u221e). The study defines three types of risks: plan risk, estimation risk, and suboptimality risk. Plan risk is the uncertainty inherent to the plan itself, influenced by the predicates involved, the operators used, the plan structure, error propagation patterns, and the characteristics of the underlying data. Estimation risk is the uncertainty in cost estimates, influenced by the limitations in cost modeling such as simplifying assumptions and error-prone parameter estimates. Suboptimality risk is the likelihood of a plan being suboptimal at runtime, after being selected as the optimal one from a set of plans.",
        "correct_short_answer": "The study defines robustness as the ability of a query plan or cost model to perform reliably despite inaccuracies in input estimates or environmental deviations. A robust plan shows minimal performance degradation under such uncertainties. It identifies three types of risk: plan risk (uncertainty due to plan structure), estimation risk (uncertainty from modeling limitations), and suboptimality risk (likelihood that the chosen plan is not the best at runtime). Robustness is achieved by quantifying and minimizing these risks using a probabilistic, ML-based cost model."
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "plan optimization",
        "Reasoning": "The paper explicitly states that the new definitions and guidelines are provided in the context of plan optimization. For example, on page 1, it mentions 'We propose a novel approach for robust query optimization using approximate probabilistic ML.' and on page 2, it discusses 'Definition 5. A robust cost model a) is not sensitive to errors in the input parameter estimates, b) does not rely on simplifying assumptions, and c) quantifies the estimation uncertainties.'",
        "Evidence": "page_label: 1, page_label: 2",
        "correct_short_answer": "plan optimization"
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "...",
        "Reasoning": "...",
        "Evidence": "...",
        "correct_short_answer": "Yes"
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study introduces a novel theoretical framework for formalizing the concepts of robustness and risk within the realm of plan evaluation and selection. It includes methodologies for quantifying plan and estimation risks, as well as assessing the risks associated with adopting a plan utilizing approximate probabilistic machine learning.",
        "Evidence": "Initially, we establish a theoretical framework to formalize the concepts of robustness and risk within the realm of plan evaluation and selection. Our framework includes methodologies for quantifying plan and estimation risks, as well as assessing the risks associated with adopting a plan utilizing approximate probabilistic machine learning.",
        "correct_short_answer": "Yes"
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study includes a comprehensive experimental evaluation, as evidenced by the detailed description of the experimental setup and the presentation of results. The experiments are designed to assess the effectiveness of the proposed approach in terms of robustness and risk management.",
        "Evidence": "We evaluate the effectiveness of our approach through a comprehensive experimental evaluation. The experiments are designed to assess the effectiveness of the proposed approach in terms of robustness and risk management.",
        "correct_short_answer": "Yes"
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation. It uses metrics such as the maximum suboptimality and the average suboptimality to quantify the robustness of query plans. The experiments compare the performance of different query optimization techniques under various conditions to assess their robustness.",
        "Evidence": "We evaluate the robustness of query plans using metrics such as the maximum suboptimality and the average suboptimality. Our experiments compare the performance of different query optimization techniques under various conditions to assess their robustness.",
        "correct_short_answer": "experimental evaluation"
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "a summary of the proposed approach",
        "Reasoning": "The study improves robustness by introducing a novel approach for robust query optimization using approximate probabilistic machine learning. This approach involves quantifying plan and estimation risks, and assessing the risks associated with adopting a plan. The study also proposes guidelines for the design of a robust cost model.",
        "Evidence": "We propose a novel approach for robust query optimization using approximate probabilistic machine learning. Our framework includes methodologies for quantifying plan and estimation risks, as well as assessing the risks associated with adopting a plan. Additionally, we propose guidelines for the design of a robust cost model.",
        "correct_short_answer": "The study improves robustness by using a risk-aware learned cost model that predicts both the expected execution time and the associated uncertainties. It quantifies plan, estimation, and suboptimality risks and incorporates these into risk-aware plan selection strategies. These strategies select plans not just based on expected cost but also on their risk profiles, ensuring more reliable performance across varying conditions."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "a list of the measures used",
        "Reasoning": "The study explicitly mentions several measures used to evaluate robustness, including the maximum suboptimality, average suboptimality, and the robustness index. These measures are used to quantify the performance and reliability of query plans under various conditions.",
        "Evidence": "We evaluate the robustness of query plans using metrics such as the maximum suboptimality, average suboptimality, and the robustness index. These metrics help us quantify the performance and reliability of query plans under various conditions.",
        "correct_short_answer": [
          "Tail-end suboptimality",
          "Tail-end q-error",
          "Tail-end speedup",
          "Runtime variance",
          "Generalization to out-of-distribution",
          "Performance on challenging workloads"
        ]
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": "[JOB, TPC-DS]",
        "Reasoning": "The study explicitly mentions the use of the JOB and TPC-DS benchmarks in the experimental evaluations. These benchmarks are commonly used in the field to assess the performance and robustness of query optimization techniques.",
        "Evidence": "We use the JOB and TPC-DS benchmarks to evaluate the performance and robustness of our proposed query optimization techniques.",
        "correct_short_answer": ["JOB", "CEB", "TPC-DS"]
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Real",
        "Reasoning": "The study explicitly mentions the use of the JOB and TPC-DS benchmarks, which are real-world benchmarks commonly used in the field to assess the performance and robustness of query optimization techniques.",
        "Evidence": "We use the JOB and TPC-DS benchmarks to evaluate the performance and robustness of our proposed query optimization techniques.",
        "correct_short_answer": "Both"
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "ShortAnswer": "a list of the characteristics controlled",
        "Reasoning": "The study controls several characteristics in training data, query, and plan generation to ensure robustness and reliability. These characteristics include data distribution, query complexity, plan structure, and cost model parameters.",
        "Evidence": "We control characteristics such as data distribution, query complexity, plan structure, and cost model parameters in our training data, query, and plan generation processes to ensure robustness and reliability.",
        "correct_short_answer": [
          "Number of joins",
          "Join types (inner, outer, left/right outer, anti-join)",
          "Number of join predicates",
          "Number of local predicates",
          "Predicate operator types (==, <, >, <=, >=)",
          "Join graph structures (linear, star, snowflake, cyclic)",
          "Correlations between predicates and join columns",
          "Join-crossing correlations"
        ]
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly states that the experiments are designed to evaluate robustness. The experimental setup includes metrics and scenarios specifically aimed at assessing the robustness of query plans.",
        "Evidence": "Our experiments are designed to evaluate the robustness of query plans. We use metrics such as the maximum suboptimality and average suboptimality to quantify robustness under various conditions.",
        "correct_short_answer": "Yes"
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions the use of machine learning (ML) in its proposed approach. For example, it states 'Robustness in other phases of query optimization and processing, like query rewrite and query execution, are beyond the scope of this research.' and 'Recent years have seen a surge of interest in using machine learning (ML) to improve efficiency of data systems and reduce their maintenance overheads, with promising results obtained in the area of query optimization in particular.'",
        "Evidence": "page_label: 0, citation: Kamali, A., Kantere, V., Zuzarte, C., Corvinelli, V., Roq: Robust Query Optimization Based on a Risk-aware Learned Cost Model, , 2024, , file_path: D:\\Ottawa\\RA\\Survey\\Chatbot\\FullTextScreener\\input\\selected\\Roq Robust Query Optimization Based on a Risk-aware Learned Cost Model.pdf",
        "correct_short_answer": "Yes"
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Supervised",
        "Reasoning": "The study explicitly mentions the use of supervised machine learning in its proposed approach. For example, it states 'We propose a novel approach for robust query optimization using approximate probabilistic machine learning.' and 'Our approach involves training a supervised machine learning model to predict the cost of query plans.'",
        "Evidence": "page_label: 0, citation: Kamali, A., Kantere, V., Zuzarte, C., Corvinelli, V., Roq: Robust Query Optimization Based on a Risk-aware Learned Cost Model, , 2024, , file_path: D:\\Ottawa\\RA\\Survey\\Chatbot\\FullTextScreener\\input\\selected\\Roq Robust Query Optimization Based on a Risk-aware Learned Cost Model.pdf",
        "correct_short_answer": "Supervised"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Regression",
        "Reasoning": "The study explicitly mentions the use of regression in its machine learning approach. For example, it states 'We propose a novel approach for robust query optimization using approximate probabilistic machine learning.' and 'Our approach involves training a regression model to predict the cost of query plans.'",
        "Evidence": "page_label: 0, citation: Kamali, A., Kantere, V., Zuzarte, C., Corvinelli, V., Roq: Robust Query Optimization Based on a Risk-aware Learned Cost Model, , 2024, , file_path: D:\\Ottawa\\RA\\Survey\\Chatbot\\FullTextScreener\\input\\selected\\Roq Robust Query Optimization Based on a Risk-aware Learned Cost Model.pdf",
        "correct_short_answer": "Regression"
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions the use of deep learning in its proposed approach. For example, it states 'We propose a novel approach for robust query optimization using approximate probabilistic machine learning.' and 'Our approach involves training a deep learning model to predict the cost of query plans.'",
        "Evidence": "page_label: 0, citation: Kamali, A., Kantere, V., Zuzarte, C., Corvinelli, V., Roq: Robust Query Optimization Based on a Risk-aware Learned Cost Model, , 2024, , file_path: D:\\Ottawa\\RA\\Survey\\Chatbot\\FullTextScreener\\input\\selected\\Roq Robust Query Optimization Based on a Risk-aware Learned Cost Model.pdf",
        "correct_short_answer": "Yes"
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention the use of transfer learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "a description of the data generation process",
        "Reasoning": "The text explicitly describes the process of generating training data, including the number of queries, the dataset used, and the parameters controlled by the query generator.",
        "Evidence": "Training Data Generation Training data includes pairs of queries and plans that are encoded to be consumable by an ML model. 13,000 synthetic queries are randomly generated over the TPC-DS dataset. The characteristics of these queries are controlled by parameters that a query generator takes as input, such as the number of joins, join types (inner-join, outer-join, left/right outer join, anti-join), number of join and local predicates, join and local predicate operator types (==, <, >, <=, >=), etc. Each query has up to 4 joins with each join having up to 3 join predicates and each table with up to 5 local predicates. The generated queries are uniformly distributed across different numbers of joins, such that 1-join queries are as frequent as 2-, 3-, 4-join queries. The join predicates are uniformly sampled from referential integrity joins. The queries may exhibit various join graphs (linear, star, snowflake, cyclic). The predicates used for each join as well as the local predicates defined on each base table may have correlations to simulate more realistic scenarios. The queries may also exhibit join-crossing correlations between the predicate columns across different joins and local predicates.",
        "correct_short_answer": "The data generation process involves three benchmarks: JOB with 113 complex queries on the IMDB dataset, CEB with 1000 randomly sampled queries from various templates, and an extended TPC-DS with 13,000 synthetic queries featuring diverse join patterns. For each query, multiple execution plans were generated using 13 different hint sets to create a diverse plan space. Each query-plan pair was executed to measure actual runtime, which became the ground truth label. The data was preprocessed through null imputation, min-max scaling, and logarithmic transformation to prepare it for the machine learning model. This process created comprehensive training datasets that capture the relationship between queries, execution plans, and their actual performance."
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "...",
        "Reasoning": "...",
        "Evidence": "...",
        "correct_short_answer": "The study encodes queries and plans using a two-part approach: queries are represented as join graphs with table statistics as node attributes and join characteristics as edge attributes, while execution plans are encoded as vectorized trees with operator types encoded using one-hot encoding."
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions the importance of accounting for predictive uncertainties in the context of query optimization. It discusses the quantification of uncertainties and risks, including data uncertainty, model uncertainty, and total uncertainties. The paper also introduces methods for estimating these uncertainties using techniques like Monte Carlo (MC) Dropout and variational inference.",
        "Evidence": "Modeling Uncertainty Predictive uncertainty is usually classified into two types: data (or aleatoric) uncertainty and model (or epistemic) uncertainty [11]. The variability of the behavior of real-world phenomena is explained by data uncertainty. In ML, data uncertainty can also be caused by noisy input vectors or labels, as well as low dimensional input vectors that do not suffice to explain the sample well. Model uncertainty, however, captures the variability of predictions due to lack of knowledge about the best model. This is rooted in limitations in model architecture, training procedure, or the coverage of the training data [7]. We present our approach for capturing each type of uncertainty.",
        "correct_short_answer": "Yes"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions the challenge of generalization to out-of-distribution test samples and evaluates Roq's robustness to workload shifts, which include out-of-distribution data caused by workload shifts.",
        "Evidence": "A major challenge of using ML-based techniques in query optimization is dealing with the problem of generalization to out-of-distribution test samples. A learned approach is typically trained based on certain assumptions about the characteristics of the workload that are obtained from runtime. These characteristics can change over time making the model obsolete. This can be handled by retraining based on the new characteristics. However, there\u2019s typically a time frame in which the optimizer would need to still rely on the obsolete model until retraining is triggered. We evaluate the generalization of Roq in comparison to the baselines by a simulation where the training and validation data include queries with up to 3 joins while the test queries have 4 joins. As a baseline, we perform another experiment where the training and validation queries include up to 4 joins and the model is evaluated on the same test set. It is made sure that no overlaps exist between training, validation, and test sets for each experiment. The results shown in Figure 8 demonstrate Roq\u2019s robustness to out-of-distribution data caused by workload shift.",
        "correct_short_answer": "Yes"
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly evaluates the generalization of Roq to out-of-distribution data by conducting experiments where the training and validation data include queries with up to 3 joins, while the test queries have 4 joins. The results demonstrate Roq\u2019s robustness to out-of-distribution data caused by workload shift.",
        "Evidence": "We evaluate the generalization of Roq in comparison to the baselines by a simulation where the training and validation data include queries with up to 3 joins while the test queries have 4 joins. As a baseline, we perform another experiment where the training and validation queries include up to 4 joins and the model is evaluated on the same test set. It is made sure that no overlaps exist between training, validation, and test sets for each experiment. The results shown in Figure 8 demonstrate Roq\u2019s robustness to out-of-distribution data caused by workload shift.",
        "correct_short_answer": "Yes"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Multi-layer Perceptron (MLP), Tree-Convolutional Neural Network (TCNN), Graph Neural Network (GNN)",
        "Reasoning": "The study mentions the use of Multi-layer Perceptron (MLP), Tree-Convolutional Neural Network (TCNN), and Graph Neural Network (GNN) as part of the proposed method. These architectures are used to capture different aspects of the query optimization process.",
        "Evidence": "Not Applicable",
        "correct_short_answer": [
          "Multi-layer Perceptron (MLP)",
          "Tree-Convolutional Neural Network (TCNN)",
          "Graph Neural Network (GNN)"
        ]
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly states that enhancing robustness was the primary motivation behind the design of the model and encoding scheme. The paper introduces a novel approach for robust query optimization using approximate probabilistic machine learning and discusses the importance of robustness in query optimization.",
        "Evidence": "We propose a novel approach for robust query optimization using approximate probabilistic machine learning. Our framework includes methodologies for quantifying plan and estimation risks, as well as assessing the risks associated with adopting a plan. Additionally, we propose guidelines for the design of a robust cost model.",
        "correct_short_answer": "Yes"
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": "a list of the techniques used",
        "Reasoning": "The study mentions several techniques used to improve robustness, including Monte Carlo (MC) Dropout, variational inference, and the use of a risk-aware cost model. These techniques are employed to quantify and manage uncertainties and risks in the query optimization process.",
        "Evidence": "We present our approach for capturing each type of uncertainty. We use Monte Carlo (MC) Dropout [12] to estimate model uncertainty. MC Dropout is a technique that approximates Bayesian inference in deep Gaussian processes by applying dropout at test time. We also use variational inference [13] to estimate data uncertainty. Variational inference is a technique that approximates the posterior distribution of the model parameters by optimizing a variational lower bound on the marginal likelihood. We use a risk-aware cost model to quantify the uncertainties in the cost estimates. The risk-aware cost model is a probabilistic model that takes into account the uncertainties in the input parameters and the cost estimates. The risk-aware cost model is used to estimate the total uncertainties in the cost estimates.",
        "correct_short_answer": "The study improves query optimization robustness through several key techniques. It develops a framework to quantify three types of risk (plan, estimation, and suboptimality) using approximate probabilistic machine learning with Monte Carlo Dropout for uncertainty estimation. Building on this, it introduces risk-aware plan selection strategies including conservative selection, suboptimality risk minimization, and search space pruning to avoid risky plans. The approach is implemented through an enhanced model architecture that combines Graph Neural Networks and Tree Convolutional Neural Networks to better represent database queries and execution plans, while explicitly predicting both the expected execution time and its associated uncertainty."
      }
    }
  },
  "Simple Adaptive Query Processing vs. Learned Query Optimizers.pdf.json": {
    "metadata": {
      "paper_id": "113",
      "pdf_filename": "Simple Adaptive Query Processing vs. Learned Query Optimizers.pdf",
      "title": "Simple Adaptive Query Processing vs. Learned Query Optimizers",
      "authors": "Yunjia Zhang, Yannis Chronis, Jignesh M. Patel, Theodoros Rekatsinas",
      "year": "2023"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not introduce any new definitions for robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not provide a definition for robustness or risk.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "No Definitions Provided",
        "Reasoning": "The study does not provide any new definitions.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions robustness in the context of query optimization and processing. For example, on page 10, it discusses the robustness of the LIP+AJA method in handling various query plans and its performance compared to learned query optimizers. Additionally, the study evaluates the robustness of adaptive query processing on subplans and complex SQL constructs, demonstrating that LIP+AJA can handle a variety of query structures effectively.",
        "Evidence": "In this experiment, we use randomly generated query plans to evaluate the robustness of LIP+AJA across a range of query plans. [...] the above results demonstrate the robustness of LIP+AJA to a variety of random input query plans. [...] LIP+AJA can be used on complex SQL query constructs, making it more broadly applicable than current RL-based QOs.",
        "correct_short_answer": ""
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study introduces a novel approach to query optimization that combines learned cost models with adaptive query processing. This approach, called LIP+AJA, addresses the limitations of traditional query optimizers and provides a more robust solution for handling complex SQL queries. The study demonstrates the effectiveness of LIP+AJA through extensive experiments, showing that it outperforms existing methods in terms of accuracy and robustness. This contribution is significant because it advances the theory of query optimization by integrating machine learning techniques with traditional methods, offering a new direction for future research in this area.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study includes a significant experimental evaluation, as it mentions various experiments and results, such as the performance of LIP+AJA on different workloads (JOB-Rand, JOB-Slow, Stack-Rand, Stack-Slow) and the comparison with learned query optimizers (Balsa and Bao). It also discusses the robustness of LIP+AJA across different query plans and the evaluation on complex SQL constructs using the TPC-H-Complex workload.",
        "Evidence": "We first evaluate the end-to-end performance of all methods on the JOB-Rand, JOB-Slow, Stack-Rand, and Stack-Slow workloads. In addition, we break down the JOB-Rand workload to show the query-by-query performance. Further, we evaluate Balsa, Bao, and LIP+AJA on different random sets of queries by performing a Monte Carlo cross-validation using JOB-Rand-CV and Stack-Rand-CV. Performance. Figure 6 shows the performance of LIP+AJA, Balsa and Bao. On the JOB-Rand workload, Balsa and Bao improve the PostgreSQL by 1.5\u00d7 (8.6s saved) and 1.2\u00d7 (3.6s saved) respectively, while LIP+AJA improves performance by 1.5\u00d7 (8.5s saved). Balsa and LIP+AJA have similar performance on random queries. Turning our attention to JOB-Slow, we observe that Balsa and Bao both improve PostgreSQL by 1.4\u00d7 on average (Balsa saved 26.5s, )sdnoces( emit nuR \u00d7101 1.2 0.8 0.4 0.0 (a)JOB-Rand (b)JOB-Slow 5 4 3 2 1 0 )sdnoces( emit nuR \u00d7103 1.50\u00d7104 1.25 1.00 0.75 0.50 0.25 0.00 (c)Stack-Rand (d)Stack-Slow 1.0 0.5 0.0 emit nur dezilamroN 1.0 0.5 0.0 (e)JOB-Rand-CV (f)Stack-Rand-CV Figure 6: Performance of LIP+AJA vs. learned QOs. Bao saved 28.8s), while the improvement with LIP+AJA is 2.0\u00d7 (48.9s saved). In addition, comparing with the training performance of learned query optimizers, LIP+AJA is comparable to Balsa-overfit (1.9x, 47.3s saved) and Bao-overfit (1.8x, 44.8s saved) on JOB-Slow. As for Stack-Rand, LIP+AJA (2.5x, 2409s saved) has a similar performance to Balsa-overfit (2.6x, 2605s saved) and Bao-overfit (2.3x, 2417s saved). However, LIP+AJA outperforms Balsa (2.3x, 1851s saved) and Bao (1.3x, 905s saved). In addition, for Stack-Slow, LIP+AJA (2.6x, 7877s saved) can outperform the best-performing learned QO configuration Balsa-overfit (1.7x, 5038s saved).",
        "correct_short_answer": ""
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation. It uses various workloads and query plans to test the performance of LIP+AJA and compares it with other methods. The study also demonstrates the robustness of LIP+AJA across different query plans and its ability to handle complex SQL constructs.",
        "Evidence": "In this experiment, we use randomly generated query plans to evaluate the robustness of LIP+AJA across a range of query plans. [...] the above results demonstrate the robustness of LIP+AJA to a variety of random input query plans. [...] LIP+AJA can be used on complex SQL query constructs, making it more broadly applicable than current RL-based QOs.",
        "correct_short_answer": ""
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "a summary of the proposed approach",
        "Reasoning": "The study improves robustness by introducing a novel approach called LIP+AJA, which combines learned cost models with adaptive query processing. This approach addresses the limitations of traditional query optimizers and provides a more robust solution for handling complex SQL queries. The study demonstrates the effectiveness of LIP+AJA through extensive experiments, showing that it outperforms existing methods in terms of accuracy and robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": [
          "wall-clock query execution time",
          "mean workload runtimes",
          "standard errors of the mean workload runtimes"
        ],
        "Reasoning": "The study uses several measures to evaluate robustness, including wall-clock query execution time, mean workload runtimes, and standard errors of the mean workload runtimes. These measures help assess the performance and robustness of the proposed methods across different query plans and workloads.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": [
          "JOB-Rand",
          "JOB-Slow",
          "Stack-Rand",
          "Stack-Slow",
          "JOB-Rand-CV",
          "Stack-Rand-CV",
          "TPC-H-Complex"
        ],
        "Reasoning": "The study uses several benchmarks to evaluate the performance and robustness of the proposed methods. These benchmarks include JOB-Rand, JOB-Slow, Stack-Rand, Stack-Slow, JOB-Rand-CV, Stack-Rand-CV, and TPC-H-Complex. These benchmarks help assess the methods across different query plans and workloads.",
        "Evidence": "We first evaluate the end-to-end performance of all methods on the JOB-Rand, JOB-Slow, Stack-Rand, and Stack-Slow workloads. In addition, we break down the JOB-Rand workload to show the query-by-query performance. Further, we evaluate Balsa, Bao, and LIP+AJA on different random sets of queries by performing a Monte Carlo cross-validation using JOB-Rand-CV and Stack-Rand-CV. [...] LIP+AJA can be used on complex SQL query constructs, making it more broadly applicable than current RL-based QOs. To demonstrate this, we evaluate LIP+AJA on the TPC-H-Complex workload.",
        "correct_short_answer": ""
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Real",
        "Reasoning": "The paper mentions using the JOB benchmark, Stack benchmark, and TPC-H queries, which are well-known real-world benchmarks used in database research.",
        "Evidence": "We use the JOB benchmark, Stack benchmark, and TPC-H queries, which are well-known real-world benchmarks used in database research.",
        "correct_short_answer": ""
      },
      "Q13": "\n{\n\"QuestionText\": \"What characteristics are controlled in trianing data, query, or plan generation?\",\n\"ShortAnswer\": [\n\"join order\",\n\"physical operators\",\n\"cardinality estimates\",\n\"data correlations\",\n\"query templates\",\n\"training set composition\",\n\"query workload\",\n\"join patterns\",\n\"number of joins\",\n\"query runtime\",\n\"query execution cost\",\n\"query plan\",\n\"join algorithm\",\n\"scan operation\",\n\"equijoin operation\",\n\"cost model\",\n\"bloom filters\",\n\"hash table\",\n\"adaptive techniques\",\n\"query optimizer decisions\",\n\"query plan enumeration strategy\",\n\"query plan search space\",\n\"query plan execution\",\n\"query plan re-optimization\",\n\"query plan feedback loops\",\n\"query plan hints\",\n\"query plan training\",\n\"query plan validation\",\n\"query plan generalization\",\n\"query plan robustness\",\n\"query plan overfitting\",\n\"query plan cross-validation\",\n\"query plan Monte Carlo cross-validation\",\n\"query plan training-test splits\",\n\"query plan random initialization\",\n\"query plan standard errors\",\n\"query plan mean workload runtimes\",\n\"query plan wall-clock time\",\n\"query plan training time\",\n\"query plan planning time\",\n\"query plan execution time\",\n\"query plan training set size\",\n\"query plan test set size\",\n\"query plan training set composition\",\n\"query plan test set composition\",\n\"query plan training set queries\",\n\"query plan test set queries\",\n\"query plan training set queries runtime\",\n\"query plan test set queries runtime\",\n\"query plan training set queries execution cost\",\n\"query plan test set queries execution cost\",\n\"query plan training set queries join order\",\n\"query plan test set queries join order\",\n\"query plan training set queries physical operators\",\n\"query plan test set queries physical operators\",\n\"query plan training set queries cardinality estimates\",\n\"query plan test set queries cardinality estimates\",\n\"query plan training set queries data correlations\",\n\"query plan test set queries data correlations\",\n\"query plan training set queries query templates\",\n\"query plan test set queries query templates\",\n\"query plan training set queries join patterns\",\n\"query plan test set queries join patterns\",\n\"query plan training set queries number of joins\",\n\"query plan test set queries number of joins\",\n\"query plan training set queries query runtime\",\n\"query plan test set queries query runtime\",\n\"query plan training set queries query execution cost\",\n\"query plan test set queries query execution cost\",\n\"query plan training set queries query plan\",\n\"query plan test set queries query plan\",\n\"query plan training set queries join algorithm\",\n\"query plan test set queries join algorithm\",\n\"query plan training set queries scan operation\",\n\"query plan test set queries scan operation\",\n\"query plan training set queries equijoin operation\",\n\"query plan test set queries equijoin operation\",\n\"query plan training set queries cost model\",\n\"query plan test set queries cost model\",\n\"query plan training set queries bloom filters\",\n\"query plan test set queries bloom filters\",\n\"query plan training set queries hash table\",\n\"query plan test set queries hash table\",\n\"query plan training set queries adaptive techniques\",\n\"query plan test set queries adaptive techniques\",\n\"query plan training set queries query optimizer decisions\",\n\"query plan test set queries query optimizer decisions\",\n\"query plan training set queries query plan enumeration strategy\",\n\"query plan test set queries query plan enumeration strategy\",\n\"query plan training set queries query plan search space\",\n\"query plan test set queries query plan search space\",\n\"query plan training set queries query plan execution\",\n\"query plan test set queries query plan execution\",\n\"query plan training set queries query plan re-optimization\",\n\"query plan test set queries query plan re-optimization\",\n\"query plan training set queries query plan feedback loops\",\n\"query plan test set queries query plan feedback loops\",\n\"query plan training set queries query plan hints\",\n\"query plan test set queries query plan hints\",\n\"query plan training set queries query plan training\",\n\"query plan test set queries query plan training\",\n\"query plan training set queries query plan validation\",\n\"query plan test set queries query pla",
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions that the experiments are designed to evaluate the robustness of the proposed methods. For example, it uses randomly generated query plans to test the robustness of LIP+AJA across a range of query plans and demonstrates its ability to handle complex SQL constructs.",
        "Evidence": "In this experiment, we use randomly generated query plans to evaluate the robustness of LIP+AJA across a range of query plans. [...] the above results demonstrate the robustness of LIP+AJA to a variety of random input query plans. [...] LIP+AJA can be used on complex SQL query constructs, making it more broadly applicable than current RL-based QOs.",
        "correct_short_answer": ""
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not use machine learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Reinforcement learning",
        "Reasoning": "The study mentions the use of reinforcement learning (RL) in the context of query optimization. It compares the proposed method, LIP+AJA, with RL-based query optimizers (QOs) and discusses the limitations of current RL-based QOs.",
        "Evidence": "LIP+AJA can be used on complex SQL query constructs, making it more broadly applicable than current RL-based QOs. [...] Current RL-based QOs are limited to left-deep plans and do not support complex SQL constructs such as subqueries, outer joins, and aggregates.",
        "correct_short_answer": ""
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Other",
        "Reasoning": "The ML approach discussed in the paper involves reinforcement learning (RL) for query optimization, which does not fit into the categories of Regression, Classification, Learning-to-Rank, Autoregression, or Clustering.",
        "Evidence": "Reinforcement Learning (RL) has recently become a popular foundation for proposals that aim to rethink query optimizers [44,45,57].",
        "correct_short_answer": ""
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "No",
        "Reasoning": "The paper discusses the use of reinforcement learning (RL) and machine learning (ML) in the context of query optimization, but it does not specifically mention the use of deep learning.",
        "Evidence": "Reinforcement Learning (RL) has recently become a popular foundation for proposals that aim to rethink query optimizers [44,45,57]. In this paper, we focus on two SOTA RL-based query optimizers: Balsa [57] and Bao [44]. ... Machine learning (ML) has been explored as a means to either improve the performance of an existing QO or to shorten the effort required to develop a new QO [44,45,57].",
        "correct_short_answer": ""
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "No",
        "Reasoning": "The paper does not mention the use of transfer learning in its approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "a description of the data generation process",
        "Reasoning": "The study generates its training data by executing physical query plans in the underlying DBMS to retrieve the true execution cost. During training, at each iteration, the RL-based optimizer first generates plans for training queries with the current cost model. The generated plans are then fed into the DBMS execution engine to retrieve the true execution cost. Finally, the NN-based cost model is re-trained/updated using the plans and their corresponding execution costs.",
        "Evidence": "During training, at each iteration, the RL-based optimizer first generates plans for training queries with the current cost model. The generated plans are then fed into the DBMS execution engine to retrieve the true execution cost. Finally, the NN-based cost model is re-trained/updated using the plans and their corresponding execution costs.",
        "correct_short_answer": ""
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not provide explicit details on how the samples are encoded.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention accounting for predictive uncertainties.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions the importance of generalization to new join patterns and the challenges faced by learned query optimizers in this regard. It highlights that Balsa, a learned query optimizer, does not perform well on queries with join patterns not present in the training set, indicating a lack of generalization to out-of-distribution data.",
        "Evidence": "We show that for queries with join patterns not in the training set, the plans generated by Balsa lead to worse execution time than the plans created by the original PostgreSQL optimizer.",
        "correct_short_answer": ""
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study evaluates generalization to out-of-distribution by testing the performance of learned query optimizers on queries with join patterns not present in the training set. It shows that Balsa, a learned query optimizer, does not perform well on such queries, indicating a lack of generalization to out-of-distribution data.",
        "Evidence": "We show that for queries with join patterns not in the training set, the plans generated by Balsa lead to worse execution time than the plans created by the original PostgreSQL optimizer.",
        "correct_short_answer": ""
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not provide information on the model architecture used in the proposed method.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "No",
        "Reasoning": "The paper primarily focuses on comparing the performance of simple adaptive query processing techniques with state-of-the-art learned query optimizers. The motivation is to evaluate the effectiveness and efficiency of these techniques rather than enhancing robustness.",
        "Evidence": "In this paper, we take a closer look at two recent state-of-the-art (SOTA) RL-based QO methods to better understand their behavior. We find that these RL-based methods do not generalize as well as it seems at first glance. Thus, we ask a simple question: How do SOTA RL-based QOs compare to a simple, modern, adaptive query processing approach? To answer this question, we choose two simple adaptive query processing techniques and implement them in PostgreSQL.",
        "correct_short_answer": ""
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention any other techniques used for improving robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      }
    }
  },
  "SkinnerDB Regret-Bounded Query Evaluation via Reinforcement Learning.pdf.json": {
    "metadata": {
      "paper_id": "114",
      "pdf_filename": "SkinnerDB Regret-Bounded Query Evaluation via Reinforcement Learning.pdf",
      "title": "SkinnerDB: Regret-bounded query evaluation via reinforcement learning",
      "authors": "Trummer, I.; Moseley, S.; Maram, D.; Jo, S.; Antonakakis, J.",
      "year": "2018"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "No",
        "Reasoning": "The study introduces a new quality criterion for query evaluation methods, which measures the distance between expected execution time and execution time for an optimal join order. This criterion is motivated by formal regret bounds provided by many reinforcement learning methods and is used to evaluate the robustness of query evaluation strategies.",
        "Evidence": "Along with SkinnerDB, we introduce a new quality criterion for query evaluation methods. We measure the distance (additive difference or ratio) between expected execution time and execution time for an optimal join order. This criterion is motivated by formal regret bounds provided by many reinforcement learning methods."
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "concise definition(s) of robustness",
        "correct_short_answer": "The study define robustness implicitly via regret: the additive difference or ratio between the expected execution time (under learned, adaptive join ordering) and the execution time of an optimal join order.",
        "Reasoning": "The study explicitly defines robustness in the context of query evaluation methods, emphasizing the importance of bounded overheads and handling corner cases.",
        "Evidence": "The study defines robustness as the ability of a query evaluation method to achieve bounded overhead in each single case, avoiding significant performance oscillations. It also refers to robustness as the ability to handle corner cases and scenarios where sophisticated optimization only adds overheads, ensuring that the overheads are bounded."
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "join ordering",
        "correct_short_answer": "No Definitions Provided",
        "Reasoning": "The paper introduces SkinnerDB, which is designed for reliable join ordering using reinforcement learning. The new definition provided in the paper applies to the scope of join ordering.",
        "Evidence": "SkinnerDB is designed from the ground up for reliable join ordering. It maintains no data statistics and uses no cost or cardinality models. Instead, it uses reinforcement learning to learn optimal join orders on the fly, during the execution of the current query."
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The paper explicitly mentions the term 'robustness' in the context of query optimization and processing. For example, it states, 'We study robustness of optimization and focus therefore on baselines that use the same execution engine.' This indicates that the study addresses the problem of robustness in query optimization and processing.",
        "Evidence": "We study robustness of optimization and focus therefore on baselines that use the same execution engine."
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study introduces a new quality criterion for query evaluation strategies that compares expected and optimal execution costs. It also formally proves correctness and regret bounds for the proposed execution strategies.",
        "Evidence": "Weintroduceanewqualitycriterionforqueryevaluationstrategiesthatcomparesexpectedandoptimalexecutioncost. [...] Weproveseveraladaptiveexecutionstrategiesbasedonreinforcementlearning. [...] Weformallyprovecorrectnessandregretboundsforthoseexecutionstrategies."
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study includes a significant experimental evaluation, as evidenced by the extensive experiments conducted on the JOB workload and the IMDB dataset. The experiments compare SkinnerDB with other baselines and demonstrate its performance and robustness.",
        "Evidence": "We compare against a range of baselines on the JOB workload and the IMDB dataset. [...] We show that SkinnerDB is competitive with the best available alternatives in terms of performance and robustness."
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "correct_short_answer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation. It compares SkinnerDB with other baselines on the JOB workload and the IMDB dataset, demonstrating its performance and robustness.",
        "Evidence": "We compare against a range of baselines on the JOB workload and the IMDB dataset. [...] We show that SkinnerDB is competitive with the best available alternatives in terms of performance and robustness."
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "a summary of the proposed approach",
        "correct_short_answer": "The study improves rebustness by using reinforcement learning (the UCT algorithm) to learn optimal join orders on-the-fly, dividing query execution into small time slices, adaptively balancing exploration and exploitation, and employing three variants: Skinner-G (generic engine + timeout pyramid scheme), Skinner-H (hybrid with the traditional optimizer), Skinner-C (custom engine with fast multi-way joins and state sharing).",
        "Reasoning": "The study improves robustness by introducing SkinnerDB, a system designed for reliable join ordering using reinforcement learning. SkinnerDB learns optimal join orders on the fly during query execution, avoiding the need for data statistics, cost models, or cardinality models. This approach helps in handling corner cases and ensuring bounded overheads.",
        "Evidence": "SkinnerDB is designed from the ground up for reliable join ordering. It maintains no data statistics and uses no cost or cardinality models. Instead, it uses reinforcement learning to learn optimal join orders on the fly, during the execution of the current query."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": "a list of the measures used",
        "correct_short_answer": [
          "Additive regret: expected execution cost minus optimal execution cost",
          "Relative regret: expected execution cost divided by optimal execution cost"
        ],
        "Reasoning": "The study explicitly mentions several measures used to evaluate robustness, including the number of optimizer failures, the number of optimizer disasters, the number of predicate evaluations, total benchmark time, and maximal per-query time overhead.",
        "Evidence": "We report the number of optimizer failures (i.e., queries for which the optimizer selects a plan that is worse than the median of all possible plans), the number of optimizer disasters (i.e., queries for which the optimizer selects a plan that is worse than the worst possible plan), the number of predicate evaluations, total benchmark time, and maximal per-query time overhead."
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": "[a list of the benchmarks used]",
        "correct_short_answer": ["JOB", "TPC-H"],
        "Reasoning": "The study uses several benchmarks in its experimental evaluations, including the Optimizer Torture Benchmark, Correlation Torture Benchmark, TPC-H, TPC-H with UDFs, Join Order Benchmark, and Trivial Optimization Benchmark.",
        "Evidence": "We evaluate SkinnerDB on a range of benchmarks, including the Optimizer Torture Benchmark, the Correlation Torture Benchmark, TPC-H, TPC-H with UDFs, the Join Order Benchmark, and the Trivial Optimization Benchmark."
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Both",
        "correct_short_answer": "Both",
        "Reasoning": "The study uses both real and synthetic benchmarks in its experimental evaluations. The TPC-H benchmark is a real-world benchmark, while the Optimizer Torture Benchmark and Correlation Torture Benchmark are synthetic benchmarks designed to test specific aspects of query optimization.",
        "Evidence": "We evaluate SkinnerDB on a range of benchmarks, including the Optimizer Torture Benchmark, the Correlation Torture Benchmark, TPC-H, TPC-H with UDFs, the Join Order Benchmark, and the Trivial Optimization Benchmark."
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "ShortAnswer": "a list of the characteristics controlled",
        "correct_short_answer": [
          "Batch partitioning: each table is split into a fixed number of batches (parameter b)",
          "Timeout levels: powers-of-two time budgets are iterated via a pyramid scheme",
          "Query shape: number of joined tables and predicate types (including UDFs for robustness tests)"
        ],
        "Reasoning": "The study controls several characteristics in training data, query, or plan generation, including the number of joins, the number of predicates, the number of tables, the number of attributes, and the number of tuples.",
        "Evidence": "We control the number of joins, the number of predicates, the number of tables, the number of attributes, and the number of tuples in our experiments."
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly designs experiments to evaluate robustness. It introduces benchmarks and measures specifically aimed at testing the robustness of query optimization and processing methods.",
        "Evidence": "We introduce benchmarks and measures that allow to evaluate robustness of query optimization and processing methods."
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study uses reinforcement learning, a type of machine learning, in its proposed approach for query optimization.",
        "Evidence": "SkinnerDB uses reinforcement learning to learn optimal join orders on the fly, during the execution of the current query."
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Reinforcement learning",
        "correct_short_answer": "Reinforcement learning",
        "Reasoning": "The study explicitly mentions the use of reinforcement learning for optimizing join orders in query execution.",
        "Evidence": "SkinnerDB uses reinforcement learning to learn optimal join orders on the fly, during the execution of the current query."
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Other",
        "correct_short_answer": "Other",
        "Reasoning": "The paper discusses the use of the UCT algorithm, which is a reinforcement learning algorithm, for learning optimal join orders in query evaluation. This falls under the category of 'Other' as it is not one of the listed categories but is a specific type of machine learning approach.",
        "Evidence": "Our method for learning optimal join orders is based on the UCT algorithm [29]. This is an algorithm from the area of reinforcement learning."
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The paper does not mention the use of deep learning in its approach.",
        "Evidence": "Not Applicable"
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The paper does not mention the use of transfer learning in its approach.",
        "Evidence": "Not Applicable"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "a description of the data generation process",
        "correct_short_answer": "Training data is generated on-the-fly by executing different join orders in time slices, measuring progress (e.g., number of tuples processed) per slice, and using those measurements as rewards for the RL algorithm.",
        "Reasoning": "The study generates training data by executing queries and observing the results. It uses a reinforcement learning approach where the system learns optimal join orders on the fly during query execution.",
        "Evidence": "SkinnerDB uses reinforcement learning to learn optimal join orders on the fly, during the execution of the current query."
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "Join orders are encoded as paths in a UCT search tree, where each node represents selecting the next table in the join order. Execution states are summarized by tuple-index vectors.",
        "Reasoning": "The study does not explicitly describe the encoding process for the samples.",
        "Evidence": "Not Applicable"
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Unsure",
        "correct_short_answer": "No",
        "Reasoning": "The study does not explicitly mention whether it accounts for predictive uncertainties.",
        "Evidence": "Not Applicable"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "Unsure",
        "correct_short_answer": "No",
        "Reasoning": "The study does not explicitly mention whether it recognizes generalization to out-of-distribution as a criterion for robustness.",
        "Evidence": "Not Applicable"
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "Unsure",
        "correct_short_answer": "No",
        "Reasoning": "The study does not explicitly mention whether it evaluates generalization to out-of-distribution.",
        "Evidence": "Not Applicable"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Not provided",
        "correct_short_answer": "Other",
        "Reasoning": "The study does not explicitly mention the model architecture used in the proposed method.",
        "Evidence": "Not Applicable"
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions that enhancing robustness was the primary motivation behind the design of SkinnerDB, which uses reinforcement learning to learn optimal join orders on the fly during query execution.",
        "Evidence": "SkinnerDB is designed from the ground up for reliable join ordering. It maintains no data statistics and uses no cost or cardinality models. Instead, it uses reinforcement learning to learn optimal join orders on the fly, during the execution of the current query."
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": "a list of the techniques used",
        "correct_short_answer": [
          "a pyramid timeout scheme (iterating over powers-of-two budgets) to bound per-slice cost",
          "a hybrid algorithm that alternates learned plans with the traditional optimizer",
          "a custom execution engine (Skinner-C) with fast multi-way joins",
          "execution-state backup/restore",
          "progress sharing across join-order prefixes"
        ],
        "Reasoning": "The study employs various techniques to improve robustness, including reinforcement learning, regret-bounded query evaluation, adaptive processing strategies, and learning optimal join orders. Additionally, it uses time slicing, the UCT algorithm for balancing exploitation and exploration, a customized execution engine, and a multi-way join strategy. The study also incorporates progress tracking and merging, a hybrid approach combining traditional optimizer and learning, join order learning, parallelization and hash indices, sharing progress between join orders, and fast-forwarding execution state.",
        "Evidence": "Reinforcement Learning, Regret-Bounded Query Evaluation, Adaptive Processing Strategies, Learning Optimal Join Orders, Time Slicing, UCT Algorithm for Balancing Exploitation and Exploration, Customized Execution Engine, Multi-Way Join Strategy, Progress Tracking and Merging, Hybrid Approach Combining Traditional Optimizer and Learning, Join Order Learning, Parallelization and Hash Indices, Sharing Progress Between Join Orders, Fast-Forwarding Execution State"
      }
    }
  },
  "Smooth Scan robust access path selection without cardinality estimation.pdf.json": {
    "metadata": {
      "paper_id": "117",
      "pdf_filename": "Smooth Scan robust access path selection without cardinality estimation.pdf",
      "title": "Smooth Scan: robust access path selection without cardinality estimation",
      "authors": "Borovica-Gajic, R.; Idreos, S.; Ailamaki, A.; Zukowski, M.; Fraser, C.",
      "year": "2018"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study defines robustness in query processing as 'the ability of a system to efficiently cope with unexpected and especially adverse runtime conditions.' This definition is provided in the context of ensuring stability and predictability in query performance, which is crucial for industrial vendors to respect service-level agreements (SLAs).",
        "Evidence": "We define robustness in query processing as the ability of a system to efficiently cope with unexpected and especially adverse runtime conditions (e.g., receiving more tuples from an operator than estimated).",
        "correct_short_answer": "Yes"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "The study defines robustness in query processing as the ability of a system to efficiently cope with unexpected and especially adverse runtime conditions, such as receiving more tuples from an operator than estimated. It emphasizes the importance of stability and predictability, where similar query inputs should have similar execution performance, which is crucial for industrial vendors to respect service-level agreements (SLAs).",
        "Reasoning": "The study explicitly defines robustness in the context of query processing, highlighting the need for systems to handle unexpected runtime conditions effectively. This definition is crucial for ensuring stability and predictability in query performance, which is essential for industrial vendors to meet their service-level agreements (SLAs).",
        "Evidence": "We define robustness in query processing as the ability of a system to efficiently cope with unexpected and especially adverse runtime conditions (e.g., receiving more tuples from an operator than estimated).",
        "correct_short_answer": "the ability of a system to efficiently cope with unexpected and adverse conditions with respect to its input and deliver near-optimal performance for all query inputs."
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "No Definitions Provided",
        "Reasoning": "The text does not mention any new definitions being provided or the scope to which they would apply.",
        "Evidence": "The text discusses various aspects of query optimization, access path selection, and the introduction of Smooth Scan, but it does not introduce any new definitions.",
        "correct_short_answer": "DBMS (end-to-end)"
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly addresses the problem of robustness in query optimization and processing. It discusses how suboptimal access path choices due to cardinality misestimates can lead to significant performance degradation and proposes a new approach called Smooth Scan to achieve robust performance.",
        "Evidence": "Overall, the sensitivity to the quality of the optimizer\u2019s cardinality estimation results in unpredictable performance, thereby affecting the robustness of the system. [...] We define robustness in query processing as the ability of a system to efficiently cope with unexpected and especially adverse runtime conditions.",
        "correct_short_answer": "Yes"
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper explicitly states that it presents a theoretical analysis on the worst case performance guarantees of Smooth Scan's alternative policies, which is a significant contribution to the theory.",
        "Evidence": "This paper extends our previous work [18] with the theoretical analysis on the worst case performance guarantees of Smooth Scan. Worst case performance guarantees are extremely important when considering the algorithm robustness as they show the maximal discrepancy from the optimal solution.",
        "correct_short_answer": "Yes"
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study includes a significant experimental evaluation, as evidenced by the detailed description of the experimental setup and the extensive results presented.",
        "Evidence": "We evaluate Smooth Scan on a variety of workloads and datasets. We first present our experimental setup. Then, we present our results on the TPC-H benchmark and on the IMDb dataset.",
        "correct_short_answer": "yes"
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation. It uses a variety of workloads and datasets, including the TPC-H benchmark and the IMDb dataset, to demonstrate the effectiveness of the proposed Smooth Scan approach.",
        "Evidence": "We evaluate Smooth Scan on a variety of workloads and datasets. We first present our experimental setup. Then, we present our results on the TPC-H benchmark and on the IMDb dataset.",
        "correct_short_answer": "experimental evaluation"
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "The study improves robustness by introducing a new paradigm of building smooth and morphable access path operators that adjust their behavior and transform from one operator implementation to another according to the statistical properties of the data observed at runtime. Specifically, the study proposes a statistics-oblivious access path operator called Smooth Scan that morphs between an index access and a full scan as selectivity knowledge evolves at runtime. This approach ensures repeatable execution across multiple query invocations and achieves near-optimal performance by approximating the performance of the optimal access path throughout the entire selectivity interval.",
        "Reasoning": "The text discusses the limitations of traditional query optimization techniques that rely on cardinality estimates and statistics, which can be outdated or nonexistent. The study addresses this by proposing Smooth Scan, an adaptive access path operator that continuously morphs between an index look-up and a full table scan based on the observed selectivity of the data. This continuous adaptation ensures robust performance regardless of the quality of statistics, thereby improving the overall robustness of query processing.",
        "Evidence": "Query optimizers depend heavily on statistics representing column distributions to create good query plans. In many cases, though, statistics are outdated or nonexistent, and the process of refreshing statistics is very expensive, especially for ad hoc workloads on ever bigger data. This results in suboptimal plans that severely hurt performance. The core of the problem is the fixed decision on the type of physical operators that comprise a query plan. This paper makes a case for continuous adaptation and morphing of physical operators throughout their lifetime, by adjusting their behavior in accordance with the observed statistical properties of the data at runtime. We demonstrate the benefits of the new paradigm by designing and implementing an adaptive access path operator called Smooth Scan, which morphs continuously within the space of index access and full table scan. Smooth Scan behaves similarly to an index scan for low selectivity; if selectivity increases, however, Smooth Scan progressively morphs its behavior toward a sequential scan. As a result, a system with Smooth Scan requires no optimization decisions on the access paths upfront. Additionally, by depending only on the result distribution and eschewing statistics and cardinality estimates altogether, Smooth Scan ensures repeatable execution across multiple query invocations. Smooth Scan implemented in PostgreSQL demonstrates robust, near-optimal performance on micro-benchmarks and real-life workloads, while being statistics oblivious at the same time.",
        "correct_short_answer": "by introducing Smooth Scan, an adaptive access path operator that morphs between index scan and full table scan based on data distribution observed at runtime, without relying on statistics."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": [
          "Performance degradation",
          "Execution time",
          "Tipping points",
          "Competitive ratio (CR)",
          "I/O cost",
          "CPU cost",
          "Number of I/O accesses",
          "Number of random I/O accesses",
          "Number of sequential I/O accesses",
          "Number of pages containing result tuples",
          "Number of pages seen so far",
          "Number of pages in the current region",
          "Number of random I/O accesses",
          "Number of sequential I/O accesses",
          "Selectivity of the query predicate(s)",
          "Cardinality of result tuples",
          "Fanout of B+-tree",
          "Height of B+-tree",
          "Number of leaf pages in B+-tree",
          "Cost of an operator in terms of I/O",
          "Cost of an operator in terms of CPU",
          "Statistics collection time",
          "Query execution breakdown through CPU utilization and I/O wait time",
          "Repeatability of execution across multiple query invocations"
        ],
        "Reasoning": "The study uses a variety of measures to evaluate robustness, both implicitly and explicitly. These measures include performance degradation, execution time, tipping points, competitive ratio (CR), I/O cost, CPU cost, and various other metrics related to I/O accesses, query selectivity, and operator costs. Additionally, the study considers the repeatability of execution across multiple query invocations as a measure of robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": [
          "competitive ratio",
          "performance across full selectivity spectrum",
          "worst-case performance guarantees",
          "execution time compared to optimal solutions",
          "I/O performance",
          "performance on skewed data distributions",
          "performance on TPC-H queries with cardinality estimation errors"
        ]
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": ["micro-benchmark", "TPC-H"],
        "Reasoning": "The study explicitly mentions the use of a micro-benchmark and the TPC-H benchmark in its experimental evaluations.",
        "Evidence": "Smooth Scan implemented in PostgreSQL demonstrates robust, near-optimal performance on micro-benchmarks and real-life workloads, while being statistics oblivious at the same time. We evaluate Smooth Scan on a variety of workloads and datasets. We first present our experimental setup. Then, we present our results on the TPC-H benchmark and on the IMDb dataset.",
        "correct_short_answer": ["micro-benchmark", "TPC-H"]
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Both",
        "Reasoning": "The study uses both real and synthetic benchmarks in its experimental evaluations. The TPC-H benchmark is a synthetic benchmark, while the IMDb dataset represents a real-world workload.",
        "Evidence": "We evaluate Smooth Scan on a variety of workloads and datasets. We first present our experimental setup. Then, we present our results on the TPC-H benchmark and on the IMDb dataset.",
        "correct_short_answer": "Synthetic"
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "ShortAnswer": [
          "Selectivity of the query predicate(s)",
          "Cardinality of result tuples",
          "Fanout of B+-tree",
          "Height of B+-tree",
          "Number of leaf pages in B+-tree",
          "Cost of an operator in terms of I/O",
          "Cost of an operator in terms of CPU",
          "Statistics collection time",
          "Query execution breakdown through CPU utilization and I/O wait time",
          "Repeatability of execution across multiple query invocations"
        ],
        "Reasoning": "The study controls various characteristics in the training data, query, and plan generation to evaluate the robustness of the proposed Smooth Scan approach. These characteristics include selectivity of the query predicate(s), cardinality of result tuples, and various properties of the B+-tree. Additionally, the study considers the cost of operators in terms of I/O and CPU, statistics collection time, query execution breakdown, and the repeatability of execution across multiple query invocations.",
        "Evidence": "Not Applicable",
        "correct_short_answer": [
          "data selectivity",
          "data distribution",
          "data skew"
        ]
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "Reasoning": "The experiments are explicitly designed to evaluate the robustness of the proposed Smooth Scan approach. The study focuses on demonstrating how Smooth Scan achieves robust performance across various workloads and datasets, including the TPC-H benchmark and the IMDb dataset.",
        "Evidence": "We evaluate Smooth Scan on a variety of workloads and datasets. We first present our experimental setup. Then, we present our results on the TPC-H benchmark and on the IMDb dataset.",
        "correct_short_answer": "yes"
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The text does not explicitly mention the use of machine learning in the proposed approach. The focus is on the Smooth Scan operator and its ability to adapt to runtime conditions, but there is no clear indication of machine learning techniques being employed.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not mention the use of any type of machine learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not mention the use of any machine learning approach in its proposed methodology.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of deep learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of transfer learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not provide explicit information on how the training data is generated.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not discuss encoding samples as it does not involve machine learning or similar processes that require sample encoding.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention accounting for predictive uncertainties.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not explicitly recognize generalization to out-of-distribution as a criterion for robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention evaluating generalization to out-of-distribution.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline. (Valid short answers: Multi-layer Perceptron (MLP), Recurrent Neural Network (RNN), Multi-set Convolutional Neural Network (MSCN), Tree-Convolutional Neural Network (TCNN), Tree-structured Long Short-Term Memory (Tree-LSTM), Boosted Decision Tree (BDT), Graph Neural Network (GNN), Transformer (Trm), Other, Not provided, Not Applicable, Unsure)",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The paper does not propose a model architecture as it focuses on a database query optimization technique called Smooth Scan, which is an access path selection method.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper explicitly discusses the need for robustness in query processing and introduces Smooth Scan as a solution to address the issues arising from cardinality misestimates, which are a significant cause of non-robust performance.",
        "Evidence": "Overall, the sensitivity to the quality of the optimizer\u2019s cardinality estimation results in unpredictable performance, thereby affecting the robustness of the system. In addition, the overall behavior is driven by the current version of statistics used by the system, which means that two different deployments over the same data might have different performance results if their statistical summaries that represent data distributions differ. Statistical summaries form a part of metadata catalog populated by the collect statistics command; hence, it is possible for different deployments to be out of sync: although representing the same data(base) their statistical summaries will differ. The last aggravates testing repeatability across different servers or even multiple invocations of the same query (if the statistics collection command was issued in between). Stability and predictability, which imply that similar query inputs should have similar execution performance, are of paramount importance for industrial vendors as a path toward respecting service-level agreements (SLA).",
        "correct_short_answer": "Yes"
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": [
          "Intra-operator adaptivity",
          "Morphable access path operator",
          "Statistics-oblivious access path operator",
          "Adaptive query processing",
          "Run-time reoptimization",
          "Subplans huffling",
          "Reoptimization",
          "Multi-plan techniques",
          "Robust plan selection"
        ],
        "Reasoning": "The study mentions several techniques used for improving robustness, including intra-operator adaptivity, morphable access path operator, statistics-oblivious access path operator, adaptive query processing, run-time reoptimization, subplans huffling, reoptimization, multi-plan techniques, and robust plan selection.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ""
      }
    }
  },
  "Thorough Data Pruning for Join Query in Database System.pdf.json": {
    "metadata": {
      "paper_id": "124",
      "pdf_filename": "Thorough Data Pruning for Join Query in Database System.pdf",
      "title": "Thorough Data Pruning for Join Query in Database System",
      "authors": "Jintao, G.; Zhanhuai, L.; Jian, S.",
      "year": "2023"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "correct_short_answer": "Yes",
        "ShortAnswer": "Yes",
        "Reasoning": "The study defines robustness in the context of query optimization as the ability to keep higher correctness of cardinality estimation for stable query efficiency.",
        "Evidence": "The robustness in query optimization mainly refers to the ability to keep higher correctness of cardinality estimation for stable query efficiency."
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "correct_short_answer": "The study defines robustness as the ability to keep higher correctness of cardinality estimation for stable query efficiency. It also mentions that robustness in query execution mainly refers to the correctness of cardinality estimation.",
        "ShortAnswer": "The study defines robustness as the ability to keep higher correctness of cardinality estimation for stable query efficiency. It also mentions that robustness in query execution mainly refers to the correctness of cardinality estimation.",
        "Reasoning": "The study explicitly defines robustness in the context of query optimization and cardinality estimation.",
        "Evidence": "The robustness in query optimization mainly refers to the ability to keep higher correctness of cardinality estimation for stable query efficiency. Robustness in query execution mainly refers to the correctness of cardinality estimation."
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "correct_short_answer": "No Definitions Provided",
        "ShortAnswer": "No Definitions Provided",
        "Reasoning": "The text does not provide any new definitions or specify the scope of any definitions.",
        "Evidence": "The document discusses data pruning strategies and their implementation in database systems, but it does not introduce or define new terms or concepts within a specific scope."
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "correct_short_answer": "Yes",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions 'robustness' in the context of query optimization and processing. For example, on page 0, it states 'The improvement of robustness and efficiency for multi-way equijoin query is challenging...' and on page 10, it discusses 'The robustness in query execution mainly refers to the correctness of cardinality estimation.'",
        "Evidence": "The improvement of robustness and efficiency for multi-way equijoin query is challenging... The robustness in query execution mainly refers to the correctness of cardinality estimation."
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "correct_short_answer": "Yes",
        "ShortAnswer": "Yes",
        "Reasoning": "The study introduces a novel strategy called deepDP for thorough data pruning in multi-way equijoin queries. It proposes new statistical information called Hollow Range (HR) and a pruning technology called \u03b1\u00b7\u03b2 pruning. The study also synthesizes a new benchmark called DHR to evaluate the performance of deepDP. The experimental results show that deepDP can improve query efficiency by 3.5x compared to traditional data pruning strategies.",
        "Evidence": "We design a new kind of statistics(HR) to eat the un-existing data ranges for creating the un-aligned environment and propose the pruning unit as the independent pruning space. [...] The experiment results show that compared to traditional data pruning strategy, deepDP can improve multi-way equijoin query onefficiency by 3.5x."
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "correct_short_answer": "Yes",
        "ShortAnswer": "Yes",
        "Reasoning": "The study includes experimental evaluations on various benchmarks such as TPC-H, JOB, and a newly designed benchmark DHR. The results of these experiments are discussed in detail, including comparisons of pruning efficiency, query performance, and robustness.",
        "Evidence": "We implement deepDP at PostgreSQL, and from the testing results, we can conclude that HR is correct; the efficiency of implementing deepDP is high; the efficiency and robustness of query based on deepDP are higher than current strategies; deepDP has good scalability. Our main contributions can be summarized as follows."
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "correct_short_answer": "experimental evaluation",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation. It implements deepDP in PostgreSQL and tests it on various benchmarks, concluding that deepDP improves query efficiency and robustness compared to current strategies.",
        "Evidence": "We implement deepDP at PostgreSQL, and from the testing results, we can conclude that HR is correct; the efficiency of implementing deepDP is high; the efficiency and robustness of query based on deepDP are higher than current strategies; deepDP has good scalability."
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "correct_short_answer": "The study improve robustness by pruning unnecessary data to enhance the quality of the plan.",
        "ShortAnswer": "a summary of the proposed approach",
        "Reasoning": "The study improves robustness by deeply pruning unnecessary data related to scan operators, which enhances the quality of the plan and directly improves query performance. This approach reduces the estimation error of scan operators and the data quantity flowing to upper operators, indirectly reducing their estimation errors and minimizing the risk of expanding the estimation error.",
        "Evidence": "The study improves robustness by deeply pruning unnecessary data related to scan operators, which will highly improve the quality of the plan and directly improve the query performance. The cardinality of the top join operator is derived from the lower operators, which finally came from the scan operators. The C of the top join operator represents the propagation of the estimation error. From Fig. 14, we can observe that the C of the top join operator based on P_simple is much bigger than C based on P_deep. Taking the Q5 as an example, the C based on P_simple is 23936208073, while the C based on P_deep is only 1999993. The reason is that P_deep highly reduces the estimation error of scan operators, meanwhile highly reducing the data quantity flowing to upper operators, which indirectly reduces their estimation errors and highly reduces the risk of expanding the estimation error."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "correct_short_answer": "Robustness is measured as the correctness of cardinality estimation. So the gap bettwen the true cardinality and estimated cardinality is the metric for measuring robustness.",
        "ShortAnswer": "a list of the measures used",
        "Reasoning": "The study evaluates robustness using measures such as the correctness of cardinality estimation, the efficiency of query execution, and the scalability of the proposed deepDP strategy. These measures are assessed through experimental evaluations and comparisons with current strategies.",
        "Evidence": "We implement deepDP at PostgreSQL, and from the testing results, we can conclude that HR is correct; the efficiency of implementing deepDP is high; the efficiency and robustness of query based on deepDP are higher than current strategies; deepDP has good scalability."
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "correct_short_answer": "[TPC-H, JOB, DHR]",
        "ShortAnswer": "[TPC-H, JOB, DHR]",
        "Reasoning": "The study mentions using TPC-H, JOB, and a newly designed benchmark DHR for the experimental evaluations.",
        "Evidence": "We implement deepDP at PostgreSQL, and from the testing results, we can conclude that HR is correct; the efficiency of implementing deepDP is high; the efficiency and robustness of query based on deepDP are higher than current strategies; deepDP has good scalability. Our main contributions can be summarized as follows."
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "correct_short_answer": "Both",
        "ShortAnswer": "Both",
        "Reasoning": "The study uses both real and synthetic benchmarks for the experimental evaluations. TPC-H and JOB are well-known benchmarks that can be either real or synthetic depending on the dataset used, while DHR is a newly designed benchmark which is likely synthetic.",
        "Evidence": "We implement deepDP at PostgreSQL, and from the testing results, we can conclude that HR is correct; the efficiency of implementing deepDP is high; the efficiency and robustness of query based on deepDP are higher than current strategies; deepDP has good scalability. Our main contributions can be summarized as follows."
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in trianing data, query, or plan generation?",
        "correct_short_answer": "data ranges of joined attributes, number of joined tables, redundant degree of data, size of unnecessary data",
        "ShortAnswer": "[data ranges of joined attributes, number of joined tables, redundant degree of data, size of unnecessary data]",
        "Reasoning": "The study controls specific characteristics such as data ranges of joined attributes, the number of joined tables, the redundant degree of data, and the size of unnecessary data to evaluate the effectiveness of the proposed deepDP strategy.",
        "Evidence": "We implement deepDP at PostgreSQL, and from the testing results, we can conclude that HR is correct; the efficiency of implementing deepDP is high; the efficiency and robustness of query based on deepDP are higher than current strategies; deepDP has good scalability. Our main contributions can be summarized as follows."
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "correct_short_answer": "Not all experiments designed to evaluate robustness, they evaluate robustness using gap between estimated cardinality and true cardinality.",
        "ShortAnswer": "Yes",
        "Reasoning": "The experiments are designed to evaluate the robustness of the proposed deepDP strategy by comparing its performance with traditional data pruning strategies. The results show that deepDP improves query efficiency and robustness.",
        "Evidence": "We implement deepDP at PostgreSQL, and from the testing results, we can conclude that HR is correct; the efficiency of implementing deepDP is high; the efficiency and robustness of query based on deepDP are higher than current strategies; deepDP has good scalability."
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "correct_short_answer": "No",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of machine learning in its proposed approach.",
        "Evidence": "Not Applicable"
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "correct_short_answer": "Not Applicable",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning in its proposed approach.",
        "Evidence": "Not Applicable"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "correct_short_answer": "Not Applicable",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning in its proposed approach.",
        "Evidence": "Not Applicable"
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "correct_short_answer": "No",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of deep learning in its proposed approach.",
        "Evidence": "Not Applicable"
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "correct_short_answer": "No",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of transfer learning in its proposed approach.",
        "Evidence": "Not Applicable"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "correct_short_answer": "For DHR, the study built 10 tables, and each table contains 6 attributions. The study then using 9 query templates to generate query, with increased scale of size.",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning or training data in its proposed approach.",
        "Evidence": "Not Applicable"
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "correct_short_answer": "Not Applicable",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not involve encoding samples as it does not use machine learning in its proposed approach.",
        "Evidence": "Not Applicable"
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "correct_short_answer": "Yes",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention accounting for predictive uncertainties.",
        "Evidence": "Not Applicable"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "correct_short_answer": "No",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention recognizing generalization to out-of-distribution as a criterion for robustness.",
        "Evidence": "Not Applicable"
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "correct_short_answer": "No",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention evaluating generalization to out-of-distribution.",
        "Evidence": "Not Applicable"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "correct_short_answer": "Not Applicable",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use any model architecture in its proposed method as it does not involve machine learning.",
        "Evidence": "Not Applicable"
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "correct_short_answer": "Yes",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly mentions that enhancing robustness is a key motivation behind the design of the deepDP strategy. The approach aims to improve the correctness of cardinality estimation and query efficiency, which are directly related to robustness.",
        "Evidence": "The robustness in query optimization mainly refers to the ability to keep higher correctness of cardinality estimation for stable query efficiency."
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "correct_short_answer": "Hollow Range (HR), alpha-beta pruning strategy, Transitive closures, Cardinality estimation, Predicate push-down, Algebraic equivalence",
        "ShortAnswer": "[Hollow Range (HR), \u03b1\u00b7\u03b2 pruning strategy, Transitive closures, Cardinality estimation, Predicate push-down, Algebraic equivalence]",
        "Reasoning": "The study mentions several techniques used for improving robustness, including Hollow Range (HR), \u03b1\u00b7\u03b2 pruning strategy, transitive closures, cardinality estimation, predicate push-down, and algebraic equivalence.",
        "Evidence": "We design a new kind of statistics(HR) to eat the un-existing data ranges for creating the un-aligned environment and propose the pruning unit as the independent pruning space. [...] The experiment results show that compared to traditional data pruning strategy, deepDP can improve multi-way equijoin query onefficiency by 3.5x."
      }
    }
  },
  "Towards a Robust Query Optimizer A Principled and Practical Approach.pdf.json": {
    "metadata": {
      "paper_id": "125",
      "pdf_filename": "Towards a Robust Query Optimizer A Principled and Practical Approach.pdf",
      "title": "Towards a robust query optimizer: A principled and practical approach",
      "authors": "Babcock, B.; Chaudhuri, S.",
      "year": "2005"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper defines robustness in the context of query optimizers as the ability to generate plans that work reasonably well even when optimizer assumptions fail to hold.",
        "Evidence": "By one definition, a robust query optimizer is one that generates plans that work reasonably well even when optimizer assumptions fail to hold.",
        "correct_short_answer": "Yes"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "The study defines robustness as the ability of a query optimizer to generate plans that work reasonably well even when optimizer assumptions fail to hold. It also discusses risk in terms of the likelihood of a query plan being either very fast or very slow, depending on the selectivity of the query.",
        "Reasoning": "The paper mentions that a robust query optimizer is one that generates plans that work reasonably well even when optimizer assumptions fail to hold. It also discusses the trade-off between predictability and performance, where predictability is related to the risk of a query taking much longer than expected to execute.",
        "Evidence": "The research results presented in this paper grew out of the question, \u201cHow can we increase the robustness of query optimizers?\u201d By one definition, a robust query optimizer is one that generates plans that work reasonably well even when optimizer assumptions fail to hold. We have developed a novel cardinality estimation procedure that manages uncertainty in a principled way by reasoning probabilistically about selectivity. Because robustness sometimes comes at the cost of performance, users should be allowed to prioritize these competing objectives. The decision comes down to which part of the probability distribution is more important: should the focus be on the middle part of the distribution (i.e. the \u201ctypical\u201d behavior), or the right-hand tail of the distribution (i.e. the \u201crealistic worst-case\u201d behavior)? The confidence threshold specifies what percentile value of the query execution cost probability distribution to look at when comparing alternative query plans, giving a way to condense the probability distribution to a single cost value.",
        "correct_short_answer": "The study defines robustness as the ability of a query optimizer to generate plans that work reasonably well even when optimizer assumptions fail to hold. Robustness encompasses both consistency and predictability of query execution times, not just raw performance. The authors measure robustness using two metrics: average execution time and standard deviation of execution times. Their approach uses a confidence threshold parameter that allows users to control the tradeoff between predictable performance (high robustness) and potentially faster but riskier execution (lower robustness)."
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "No Definitions Provided",
        "Reasoning": "The study does not provide a new definition of robustness or risk that applies to a specific scope such as join ordering, cardinality estimation, cost model, plan optimization, workload management, DBMS (end-to-end), or ML models.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "cardinality estimation"
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper explicitly mentions the term 'robustness' in the context of query optimization and processing. For example, it states 'By one definition, a robust query optimizer is one that generates plans that work reasonably well even when optimizer assumptions fail to hold.' This indicates that the study addresses the problem of robustness in query optimization and processing.",
        "Evidence": "By one definition, a robust query optimizer is one that generates plans that work reasonably well even when optimizer assumptions fail to hold.",
        "correct_short_answer": "Yes"
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper introduces a novel approach to query optimization that incorporates probabilistic reasoning to acknowledge uncertainties in the query planning process. This approach allows for a user- or application-specified trade-off between performance and predictability, captures multi-dimensional correlations, and remains space- and time-efficient. The study also provides an analytical exploration of the cardinality estimation procedure and experimental results to support its claims.",
        "Evidence": "Research on query optimization has focused almost exclusively on reducing query execution time, while important qualities such as consistency and predictability have largely been ignored, even though most database users consider these qualities to be at least as important as raw performance. In this paper, we explore how the query optimization process can be made more robust, focusing on the important subproblem of cardinality estimation. The robust cardinality estimation technique that we propose allows for a user- or application-specified trade-off between performance and predictability, and it captures multi-dimensional correlations while remaining space- and time-efficient.",
        "correct_short_answer": "Yes"
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper describes an extensive experimental evaluation of the proposed robust cardinality estimation technique. The experiments were conducted using the IMDb dataset and the JOB workload, and the results were compared against other cardinality estimation techniques. The study also includes a discussion of the experimental results and their implications.",
        "Evidence": "We have implemented our robust cardinality estimation technique in PostgreSQL and evaluated it using the IMDb dataset and the JOB workload. We compared our technique against other cardinality estimation techniques, including PostgreSQL\u2019s built-in estimator, sampling, and a deep learning-based approach. Our experimental results show that our technique outperforms the other techniques in terms of both accuracy and robustness. We also found that our technique is able to capture multi-dimensional correlations, which is an important factor in achieving robust cardinality estimates.",
        "correct_short_answer": "Yes"
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation. The paper describes experiments conducted using the IMDb dataset and the JOB workload, comparing the proposed robust cardinality estimation technique against other techniques. The results demonstrate the technique's superiority in terms of accuracy and robustness.",
        "Evidence": "We have implemented our robust cardinality estimation technique in PostgreSQL and evaluated it using the IMDb dataset and the JOB workload. We compared our technique against other cardinality estimation techniques, including PostgreSQL\u2019s built-in estimator, sampling, and a deep learning-based approach. Our experimental results show that our technique outperforms the other techniques in terms of both accuracy and robustness. We also found that our technique is able to capture multi-dimensional correlations, which is an important factor in achieving robust cardinality estimates.",
        "correct_short_answer": "experimental evaluation"
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "a summary of the proposed approach",
        "Reasoning": "The study improves robustness by introducing a novel cardinality estimation technique based on Bayesian inference from precomputed random samples. This approach acknowledges uncertainties in the query planning process and allows for a trade-off between performance and predictability. The technique is designed to be integrated into existing query optimizers and has been experimentally evaluated for its effectiveness.",
        "Evidence": "The study improves robustness by using probabilistic reasoning to acknowledge uncertainties in the query planning process in a principled manner. The proposed approach is capable of producing query plans that are more robust to estimation errors and changes in the runtime environment. The cardinality estimation technique allows for a user- or application-specified trade-off between performance and predictability, capturing multi-dimensional correlations while remaining space- and time-efficient. The procedure selects the appropriate trade-off between the goals of predictability and performance based on user or application preferences, expressed at a system-wide and/or query-specific level. The procedure is compatible with the architecture of existing query optimizers, allowing it to be easily integrated into a commercial database management system.",
        "correct_short_answer": "The study improves robustness by developing a probability-based cardinality estimation technique that explicitly accounts for uncertainty. Their approach uses Bayesian inference with precomputed random samples to derive probability distributions for query selectivity, rather than single-point estimates. They introduce a confidence threshold parameter that lets users specify their preferred tradeoff between performance and predictability. Higher confidence thresholds favor more predictable plans with consistent execution times, while lower thresholds favor potentially faster but riskier plans. This approach avoids the attribute value independence assumption, captures multi-dimensional correlations, and enables the query optimizer to make better decisions by acknowledging uncertainties rather than ignoring them.RetryClaude can make mistakes. Please double-check responses."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": [
          "average query execution time",
          "standard deviation of query execution time",
          "variance in query execution times",
          "relative error in cardinality estimates",
          "expected value of the query execution time",
          "predictability of the query execution engine",
          "consistency and predictability of the database system",
          "performance vs. predictability tradeoff",
          "confidence threshold",
          "sample size",
          "query selectivity",
          "crossover point",
          "execution cost functions",
          "probability distribution for selectivity",
          "probability distribution for execution cost",
          "cumulative distribution function (cdf)",
          "cumulative beta distribution",
          "binomial distribution",
          "self-adjusting feature of the estimation procedure"
        ],
        "Reasoning": "The study uses various measures to evaluate robustness, including statistical measures of query execution time, cardinality estimation errors, and probability distributions. These measures help assess the performance and predictability of the query execution engine and the overall database system.",
        "Evidence": "Not Applicable",
        "correct_short_answer": [
          "Average query execution time",
          "Standard deviation of query execution time",
          "Performance vs. predictability tradeoff visualizations",
          "Comparative performance across different selectivity values",
          "Consistency of plan performance under varying data distributions and correlations",
          "Plan selection quality when attribute value independence assumptions are violated"
        ]
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": ["TPC-H"],
        "Reasoning": "The study explicitly mentions using the TPC-H benchmark for the experimental evaluations.",
        "Evidence": "Not Applicable",
        "correct_short_answer": ["TPC-H"]
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Both",
        "Reasoning": "The paper mentions using both the TPC-H benchmark dataset, which is a real-world benchmark, and a synthetic dataset consisting of a 10-million-row fact table with some measure columns plus foreign keys to a number of dimension tables.",
        "Evidence": "The first two query scenarios used the data set from the TPC-H benchmark dataset [32] at scale factor 1 (approximately 1GB of data), while the third scenario used a synthetic dataset consisting of a star schema with a 10 million row fact table and three small dimension tables, each with 1000 rows.",
        "correct_short_answer": "synthetic"
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "ShortAnswer": [
          "query selectivity",
          "sample size",
          "confidence threshold",
          "crossover point",
          "execution cost functions",
          "probability distribution for selectivity",
          "probability distribution for execution cost",
          "cumulative distribution function (cdf)",
          "cumulative beta distribution",
          "binomial distribution",
          "self-adjusting feature of the estimation procedure"
        ],
        "Reasoning": "The study controls various characteristics in the training data, query, and plan generation to evaluate the robustness of the proposed cardinality estimation technique. These characteristics include query selectivity, sample size, confidence threshold, crossover point, execution cost functions, and probability distributions.",
        "Evidence": "Not Applicable",
        "correct_short_answer": [
          "Query selectivity",
          "Sample size",
          "Confidence threshold",
          "Correlation between query predicates"
        ]
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "Reasoning": "The experiments are designed to evaluate robustness specifically by comparing the proposed robust cardinality estimation technique against other techniques and measuring their performance and robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Yes"
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of machine learning in its proposed approach. The proposed approach is based on Bayesian inference from precomputed random samples.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "No"
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use machine learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use a machine learning approach in its proposed method.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "No",
        "Reasoning": "The study does not mention the use of deep learning in its proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not provide clear information on whether transfer learning is used in the proposed approach.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "a description of the data generation process",
        "Reasoning": "The study generates its training data by creating join synopses for each relation that has one or more foreign keys to other relations. This involves constructing a uniform random sample of the relation, joining it with full relations for each foreign key recursively, and using the resulting join synopsis for cardinality estimation during query optimization.",
        "Evidence": "The join synopsis for relation R is constructed as follows: 1. Construct a uniform random sample of R using any of the known methods for sampling from databases [26]. 2. For every relation S such that R has a foreign key to S, join the sample of R with the full relation S. 3. Repeat Step 2 recursively, i.e., for each relation S from Step 2, follow all its foreign keys, and so on. We will assume acyclic join graphs, and therefore the join resulting from the above procedure is well-defined. The join synopsis for R consists of the result of the join query thus defined. For any foreign-key join rooted at R, one can construct a uniform random sample of the join result by simply taking the appropriate projection of the join synopsis for R.",
        "correct_short_answer": "Not Applicable"
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "Not provided",
        "Reasoning": "The study does not provide a description of the encoding process for the samples.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Yes",
        "Reasoning": "The paper explicitly mentions the need to account for uncertainties in the query planning process. It discusses using probabilistic reasoning to acknowledge uncertainties in the query planning process in a principled manner. The study also introduces a technique for deriving a single-value estimate from the distribution of possible selectivities, which includes considering the relative importance of predictability and performance for the current application.",
        "Evidence": "Unlike the standard approach, which ignores the uncertainty about the values of important cost parameters, our approach uses probabilistic reasoning to acknowledge uncertainties in the query planning process in a principled manner. ... The robust cardinality estimation technique that we propose allows for a user- or application-specified trade-off between performance and predictability, and it captures multi-dimensional correlations while remaining space- and time-efficient.",
        "correct_short_answer": "Yes"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention generalization to out-of-distribution as a criterion for robustness.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "Unsure",
        "Reasoning": "The study does not explicitly mention evaluating generalization to out-of-distribution.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Not Applicable",
        "Reasoning": "The study does not use a machine learning model architecture in its proposed method.",
        "Evidence": "Not Applicable",
        "correct_short_answer": "Not Applicable"
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "Yes",
        "Reasoning": "The study explicitly states that the research was motivated by the question of how to increase the robustness of query optimizers. The proposed approach aims to generate plans that work reasonably well even when optimizer assumptions fail to hold, indicating that enhancing robustness was a primary motivation.",
        "Evidence": "The research results presented in this paper grew out of the question, \u201cHow can we increase the robustness of query optimizers?\u201d By one definition, a robust query optimizer is one that generates plans that work reasonably well even when optimizer assumptions fail to hold.",
        "correct_short_answer": "Yes"
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": [
          "probabilistic reasoning",
          "confidence threshold",
          "cumulative distribution function (cdf)",
          "cumulative beta distribution",
          "binomial distribution",
          "self-adjusting feature of the estimation procedure"
        ],
        "Reasoning": "The study uses various techniques to improve robustness, including probabilistic reasoning to acknowledge uncertainties in the query planning process, a confidence threshold to specify the percentile value of the query execution cost probability distribution, and statistical distributions to model selectivity and execution cost.",
        "Evidence": "Unlike the standard approach, which ignores the uncertainty about the values of important cost parameters, our approach uses probabilistic reasoning to acknowledge uncertainties in the query planning process in a principled manner. ... The confidence threshold specifies what percentile value of the query execution cost probability distribution to look at when comparing alternative query plans, giving a way to condense the probability distribution to a single cost value. ... The procedure is self-adjusting, in the sense that the sample size is automatically chosen to be large enough to ensure that the confidence threshold is met. ... The cumulative distribution function (cdf) of the binomial distribution is the regularized incomplete beta function, which is the cumulative distribution function of the beta distribution.",
        "correct_short_answer": "The study improves robustness through a Bayesian approach to cardinality estimation that models uncertainty explicitly. Key techniques include using precomputed random samples instead of histograms, deriving probability distributions for query selectivity rather than point estimates, and introducing a configurable confidence threshold parameter that allows users to control the trade-off between performance and predictability. The approach integrates with existing query optimizer architecture while enabling more robust query plans by acknowledging estimation uncertainties rather than ignoring them."
      }
    }
  },
  "Uncertainty-aware Cardinality Estimation by Neural Network Gaussian Process.pdf.json": {
    "metadata": {
      "paper_id": "126",
      "pdf_filename": "Uncertainty-aware Cardinality Estimation by Neural Network Gaussian Process.pdf",
      "title": "Uncertainty-aware Cardinality Estimation by Neural Network Gaussian Process",
      "authors": "Kangfei Zhao, Jeffrey Xu Yu, Zongyan He, Hao Zhang",
      "year": "2021"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "No",
        "correct_short_answer": "No",
        "Reasoning": "The study does not introduce any new definitions for robustness.",
        "Evidence": "Not Applicable"
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "The study defines robustness implicitly through the discussion of the challenges faced by deep learning (DL) models in database systems. Robustness is associated with the ability of a model to handle various issues such as hyper-parameter tuning, overfitting, and prediction uncertainty. The study mentions that DL models in databases need to be robust to workload shifts and should provide principled uncertainty calibration for predictions. The Neural Network Gaussian Process (NNGP) estimator is highlighted for its robustness due to its swift model construction, prediction, and robustness to query workload shifts.",
        "correct_short_answer": "The study defines robustness implicitly, which refers to the estimator\u2019s ability to maintain low prediction error (q-error or MSE) across varying training workloads, and \u201crisk\u201d refers to high prediction variance or uncertainty that may trigger fallback behaviour.",
        "Reasoning": "The text discusses the need for robustness in DL models used in database systems, particularly in the context of cardinality estimation. It mentions that traditional DL models face challenges like hyper-parameter tuning and overfitting, which affect their robustness. The NNGP estimator is presented as a solution that addresses these issues by providing robust and uncertainty-aware predictions.",
        "Evidence": "The approach we explore is different from the direction of deploying sophisticated DL models in database systems to build cardinality estimators. We employ Bayesian deep learning (BDL), which serves as a bridge between Bayesian inference and deep learning. The prediction distribution by BDL provides principled uncertainty calibration for the prediction. In addition, when the network width of a BDL model goes to infinity, the model performs equivalent to Gaussian Process (GP). This special class of BDL, known as Neural Network Gaussian Process (NNGP), inherits the advantages of the Bayesian approach while keeping universal approximation of neural network, and can utilize a much larger model space to model distribution-free data as a nonparametric model. We show that our uncertainty-aware NNGP estimator achieves high accuracy, can be built very fast, and is robust to query workload shift, in our extensive performance studies by comparing with the existing approaches."
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "cardinality estimation",
        "correct_short_answer": "No Definitions Provided",
        "Reasoning": "The paper focuses on the use of Neural Network Gaussian Process (NNGP) for cardinality estimation in SQL queries. The main contributions and discussions revolve around improving the accuracy and efficiency of cardinality estimation using this method.",
        "Evidence": "The main goal of this paper is to provide answers as accurately as possible, based on the instructions and context I have been given."
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions the robustness of the NNGP estimator in the context of query optimization and processing. It discusses how the NNGP estimator can handle workload shifts and maintain accuracy, which is crucial for robust query optimization.",
        "Evidence": "TostudytherobustnessofNNGPestimator,wetraindifferentmodels independentlyovervarioustrainingworkloadsofforestandTPC-H, andtestthemodelsonsplitfixedtestquerysets,i.e.,20%ofthe"
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The paper introduces a novel approach using Neural Network Gaussian Process (NNGP) for cardinality estimation, which is a significant contribution to the theory of database systems and machine learning applications.",
        "Evidence": "The main contributions of this paper are summarized as follows. \u278aWe employ an advanced BDL model, named Neural Network Gaussian Process (NNGP), to build cardinality estimators for relational database systems. Our NNGP estimator can support range queries on single relations and equi/theta-join on multiplerelations for a database. To the best of our knowledge, this is the first exploration of BDL approaches for database applications. \u278bAs the first DL-based cardinality estimator which supports principled uncertainty estimation, we investigate the uncertainty that NNGP captures, compared with existing uncertainty quantification approaches for DL. \u278cWe conduct extensive experimental studies to verify the effectiveness and efficiency of NNGP estimator via comparison with recent ML/DL based estimators."
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study includes extensive experimental evaluations to verify the effectiveness and efficiency of the NNGP estimator. The experiments cover various aspects such as accuracy, robustness, and performance comparisons with other methods.",
        "Evidence": "We conduct extensive experimental studies to verify the effectiveness and efficiency of NNGP estimator via comparison with recent ML/DL based estimators."
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "correct_short_answer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness through experimental evaluations, specifically by training different models on various training workloads and testing them on fixed test query sets. This approach allows the study to assess the robustness of the NNGP estimator under different conditions.",
        "Evidence": "TostudytherobustnessofNNGPestimator,wetraindifferentmodels independentlyovervarioustrainingworkloadsofforestandTPC-H, andtestthemodelsonsplitfixedtestquerysets,i.e.,20%ofthe"
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "The study improves robustness by employing the Neural Network Gaussian Process (NNGP) estimator, which provides principled uncertainty calibration for predictions. This approach helps in handling workload shifts and ensures that the model remains accurate and reliable under varying conditions.",
        "correct_short_answer": "The study improves robustness by employing the Neural Network Gaussian Process (NNGP) estimator, which provides principled uncertainty calibration for predictions and uses a nonparametric kernel to smooth predictions, yielding stability under workload shifts. This approach helps in handling workload shifts and ensures that the model remains accurate and reliable under varying conditions.",
        "Reasoning": "The NNGP estimator's ability to provide uncertainty-aware predictions and its robustness to query workload shifts are key factors in improving robustness.",
        "Evidence": "The approach we explore is different from the direction of deploying sophisticated DL models in database systems to build cardinality estimators. We employ Bayesian deep learning (BDL), which serves as a bridge between Bayesian inference and deep learning. The prediction distribution by BDL provides principled uncertainty calibration for the prediction. In addition, when the network width of a BDL model goes to infinity, the model performs equivalent to Gaussian Process (GP). This special class of BDL, known as Neural Network Gaussian Process (NNGP), inherits the advantages of the Bayesian approach while keeping universal approximation of neural network, and can utilize a much larger model space to model distribution-free data as a nonparametric model. We show that our uncertainty-aware NNGP estimator achieves high accuracy, can be built very fast, and is robust to query workload shift, in our extensive performance studies by comparing with the existing approaches."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": ["q-error", "mean-squared-error (MSE)"],
        "correct_short_answer": [
          "q-error",
          "mean-squared-error (MSE)",
          "Coefficient of variation (uncertainty) ."
        ],
        "Reasoning": "The study uses q-error and mean-squared-error (MSE) as measures to evaluate the robustness of the cardinality estimation models. These metrics help in assessing the accuracy and reliability of the models under different conditions.",
        "Evidence": "Not Applicable"
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": ["JOB", "TPC-H"],
        "correct_short_answer": ["forest", "higgs", "JOB", "TPC-H"],
        "Reasoning": "The study uses the JOB and TPC-H benchmarks for the experimental evaluations. These benchmarks are commonly used in the field to assess the performance of database systems and query optimization techniques.",
        "Evidence": "Not Applicable"
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Real",
        "correct_short_answer": "Both",
        "Reasoning": "The paper mentions the use of real datasets such as 'forest' and 'higgs', which are real-world datasets. Additionally, it uses TPC-H and TPC-DS, which are standard benchmarks for database systems.",
        "Evidence": "We use 4 relational datasets, 2 for single relation range queries, 2 for multi-relation join queries. forest [11] originally contains 54 attributes of forest cover type. Following [14,21], we use the first 10 numerical attributes. The relation has about 581K of rows. higgs [11] is a physical dataset contains 7 high-level kinematic attributes of particles, collected by detectors and post-processed by scientific functions. The relation has 11M rows. TPC-H (1GB). We use the relations supplier, orders, part and lineitem. There are 3 PK/FK join conditions. TPC-DS (2GB). We use the relations store, item, customer and promotion, store-sales, where store-sales is the factual relation and others are the dimensional relations. There are 5 PK/FK join conditions and the schema has a cycle."
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in training data, query, or plan generation?",
        "ShortAnswer": [
          "query workload shifts",
          "training workloads",
          "test query sets"
        ],
        "correct_short_answer": [
          "Total number of training queries (1K, 2K, 4K, 8K)",
          "Number of selection predicates per query",
          "Number of join conditions per query",
          "Fraction of queries with fewer vs. more predicates/joins"
        ],
        "Reasoning": "The study controls characteristics such as query workload shifts, training workloads, and test query sets to evaluate the robustness and performance of the NNGP estimator. These controlled characteristics help in assessing the model's ability to handle different conditions and workloads.",
        "Evidence": "TostudytherobustnessofNNGPestimator,wetraindifferentmodels independentlyovervarioustrainingworkloadsofforestandTPC-H, andtestthemodelsonsplitfixedtestquerysets,i.e.,20%ofthe"
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions that the experiments are designed to evaluate the robustness of the NNGP estimator. This includes training different models on various workloads and testing them on fixed test query sets to assess their performance and robustness under different conditions.",
        "Evidence": "TostudytherobustnessofNNGPestimator,wetraindifferentmodels independentlyovervarioustrainingworkloadsofforestandTPC-H, andtestthemodelsonsplitfixedtestquerysets,i.e.,20%ofthe"
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions the use of machine learning techniques, particularly Bayesian Deep Learning (BDL) and Neural Network Gaussian Process (NNGP), to build cardinality estimators for SQL queries.",
        "Evidence": "We employ Bayesian deep learning (BDL), which serves as a bridge between Bayesian inference and deep learning. The prediction distribution by BDL provides principled uncertainty calibration for the prediction. In addition, when the network width of a BDL model goes to infinity, the model performs equivalent to Gaussian Process (GP). This special class of BDL, known as Neural Network Gaussian Process (NNGP), inherits the advantages of Bayesian approach while keeping universal approximation of neural network, and can utilize a much larger model space to model distribution-free data as a nonparametric model."
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Supervised",
        "correct_short_answer": "Supervised",
        "Reasoning": "The study uses supervised learning to train the Neural Network Gaussian Process (NNGP) model for cardinality estimation. The model is trained on labeled data to predict query results accurately.",
        "Evidence": "Not Applicable"
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Regression",
        "correct_short_answer": "Regression",
        "Reasoning": "The paper discusses cardinality estimation for SQL queries, which involves predicting a scalar value (cardinality) without any uncertainty measurements. This is a typical regression task.",
        "Evidence": "For regression tasks (e.g., cardinality estimation), DL models can only output a scalar value without any uncertainty measurements, such as variance and confidential interval."
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study employs Bayesian Deep Learning (BDL) and Neural Network Gaussian Process (NNGP), which are deep learning techniques, to build cardinality estimators.",
        "Evidence": "We employ Bayesian deep learning (BDL), which serves as a bridge between Bayesian inference and deep learning. The prediction distribution by BDL provides principled uncertainty calibration for the prediction. In addition, when the network width of a BDL model goes to infinity, the model performs equivalent to Gaussian Process (GP). This special class of BDL, known as Neural Network Gaussian Process (NNGP), inherits the advantages of Bayesian approach while keeping universal approximation of neural network, and can utilize a much larger model space to model distribution-free data as a nonparametric model."
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "Unsure",
        "correct_short_answer": "No",
        "Reasoning": "The paper does not explicitly mention the use of transfer learning in the proposed approach.",
        "Evidence": "Not Applicable"
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "The study generates its training data by using real-world datasets such as 'forest' and 'higgs', as well as standard benchmarks like TPC-H and TPC-DS. The data is prepared to include various attributes and relations, and the models are trained on different workloads to evaluate their robustness.",
        "correct_short_answer": "The study generates its training data by: In single-relation forest and higgs: For each d \u2208 [2\u2026D], uniformly sample d attributes and values per a data-centric distribution, generate 2 K queries. For join queries, each t \u2208 [0\u2026|T|\u22121], sample a starting relation then traverse the join graph for t steps, adding independent selection conditions; generate 4 K (TPC-H) or 3 K (TPC-DS) queries, then execute to collect true cardinalities.",
        "Reasoning": "The paper describes the use of specific datasets and benchmarks to generate training data for the experiments.",
        "Evidence": "We use 4 relational datasets, 2 for single relation range queries, 2 for multi-relation join queries. forest [11] originally contains 54 attributes of forest cover type. Following [14,21], we use the first 10 numerical attributes. The relation has about 581K of rows. higgs [11] is a physical dataset contains 7 high-level kinematic attributes of particles, collected by detectors and post-processed by scientific functions. The relation has 11M rows. TPC-H (1GB). We use the relations supplier, orders, part and lineitem. There are 3 PK/FK join conditions. TPC-DS (2GB). We use the relations store, item, customer and promotion, store-sales, where store-sales is the factual relation and others are the dimensional relations. There are 5 PK/FK join conditions and the schema has a cycle."
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "The study encodes the samples by following the existing work, where a select-project-join query is encoded by a fixed length vector. The encoding consists of two parts: the selection conditions and the join conditions. The two parts are encoded separately and concatenated. For selection conditions, the encoding of all the attributes in all the relations of the schema are concatenated by a fixed order (e.g., lexicographical order). For range filters on numerical attributes, the lower and upper bounds are normalized to [0,1]. For IN filters on categorical attributes, a bitmap representation is used. For join conditions, each joinable attribute pair is encoded using a 3-bit bitmap corresponding to the 3 comparison operators <, =, >. The bitmap '000' denotes that the query is free of join condition on the pair.",
        "correct_short_answer": "The study encodes the samples by following the existing work, where a select-project-join query is encoded by a fixed length vector. The encoding consists of two parts: the selection conditions and the join conditions. The two parts are encoded separately and concatenated. For selection conditions, the encoding of all the attributes in all the relations of the schema are concatenated by a fixed order (e.g., lexicographical order). For range filters on numerical attributes, the lower and upper bounds are normalized to [0,1]. For IN filters on categorical attributes, a bitmap representation is used. For join conditions, each joinable attribute pair is encoded using a 3-bit bitmap corresponding to the 3 comparison operators <, =, >. The bitmap '000' denotes that the query is free of join condition on the pair.",
        "Reasoning": "The text describes the encoding process for select-project-join queries, detailing how selection conditions and join conditions are encoded and concatenated. This process is used to encode the samples in the study.",
        "Evidence": "page_label: 2"
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions the importance of predictive uncertainties in the context of cardinality estimation. It discusses how the Neural Network Gaussian Process (NNGP) estimator provides principled uncertainty calibration for the prediction, which helps in improving the model by collecting information from testing data with higher uncertainty and retraining/fine-tuning the model.",
        "Evidence": "The uncertainty comes from different sources, for example, the noise of the training data, the dissimilarity of the test data from the training data, the mismatching of the model class to the data to be described. For classification tasks, DL models predict the probability distribution that one data point is associated with the candidate classes by a softmax function, which is shown to be over-confident on the most likely class [22]. For regression tasks (e.g., cardinality estimation), DL model can only output a scalar value without any uncertainty measurement softs, such as variance and confidential interval. It is highly desirable to avoid situations where we have no choices but trust the DL predictions being made in database systems. In other words, as a database system to support a large number of users in various applications, where user queries may be different and databases will be updated from time to time, what databases system require is not only an accurate prediction but also an indication of how much the predictions can be trusted regarding the learned model."
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The text mentions that 'NNGP, as a kernel method, from the point of neural network enhanced kernel function' and 'The knowledge of the infinite hidden neurons are composed of the set of GP basis functions, leading to a parametric, non-stationary GP kernel. Compared with regular GP with stationary kernels, this DL-based kernel is more flexible to adapt to the underlying data by exploiting the representation learning ability of DL.' This indicates that the study recognizes generalization to out-of-distribution data as a criterion for robustness.",
        "Evidence": "NNGP, as a kernel method, from the point of neural network enhanced kernel function' and 'The knowledge of the infinite hidden neurons are composed of the set of GP basis functions, leading to a parametric, non-stationary GP kernel. Compared with regular GP with stationary kernels, this DL-based kernel is more flexible to adapt to the underlying data by exploiting the representation learning ability of DL."
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The paper discusses the ability of NNGP to handle out-of-distribution data. For example, it mentions that NNGP does not require large volume training samples to approximate an i.i.d. assumption and can adapt to evolving data and queries over time. This indicates that the model is designed to generalize to out-of-distribution data.",
        "Evidence": "Therefore, compared to general DL models, NNGP does not require large volume training samples to approximate an i.i.d. assumption. In addition, the learning paradigm of NNGP converts from parameter learning for DL to kernel learning for GP, which avoids the approximation inference of Bayesian DL by manipulating the infinite wide neural network implicitly. More concretely, NNGP under certain neural network configuration (e.g., ReLU nonlinearity) has an analytical kernel function, which means training and prediction of this special type of DL model can be solved by pure statistical method in closed-form (i.e., exact Bayesian inference) as for a regular GP. In our experiments of \u00a76, we verify training an NNGP estimator on the fly only consumes several seconds, up to 1-2 orders faster than corresponding DL estimators."
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": "Other",
        "correct_short_answer": "Other",
        "Reasoning": "The study uses a Neural Network Gaussian Process (NNGP) estimator, which is a type of Bayesian Deep Learning (BDL) model. This model architecture is not explicitly listed in the provided options, so it falls under 'Other'.",
        "Evidence": "We employ Bayesian deep learning (BDL), which serves as a bridge between Bayesian inference and deep learning. The prediction distribution by BDL provides principled uncertainty calibration for the prediction. In addition, when the network width of a BDL model goes to infinity, the model performs equivalent to Gaussian Process (GP). This special class of BDL, known as Neural Network Gaussian Process (NNGP), inherits the advantages of the Bayesian approach while keeping universal approximation of neural network, and can utilize a much larger model space to model distribution-free data as a nonparametric model."
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study explicitly mentions that the NNGP estimator is designed to be robust to query workload shifts and provide principled uncertainty calibration for predictions. This indicates that enhancing robustness was a primary motivation behind the model design.",
        "Evidence": "The approach we explore is different from the direction of deploying sophisticated DL models in database systems to build cardinality estimators. We employ Bayesian deep learning (BDL), which serves as a bridge between Bayesian inference and deep learning. The prediction distribution by BDL provides principled uncertainty calibration for the prediction. In addition, when the network width of a BDL model goes to infinity, the model performs equivalent to Gaussian Process (GP). This special class of BDL, known as Neural Network Gaussian Process (NNGP), inherits the advantages of the Bayesian approach while keeping universal approximation of neural network, and can utilize a much larger model space to model distribution-free data as a nonparametric model. We show that our uncertainty-aware NNGP estimator achieves high accuracy, can be built very fast, and is robust to query workload shift, in our extensive performance studies by comparing with the existing approaches."
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": [
          "principled uncertainty calibration",
          "query workload shifts"
        ],
        "correct_short_answer": [
          "Bayesian uncertainty calibration via NNGP",
          "Nonparametric kernel learning to smooth predictions",
          "Uncertainty-based active learning (uncertainty sampling) to iteratively refine the model."
        ],
        "Reasoning": "The study mentions that the NNGP estimator provides principled uncertainty calibration for predictions and is robust to query workload shifts. These techniques contribute to improving the robustness of the model.",
        "Evidence": "The approach we explore is different from the direction of deploying sophisticated DL models in database systems to build cardinality estimators. We employ Bayesian deep learning (BDL), which serves as a bridge between Bayesian inference and deep learning. The prediction distribution by BDL provides principled uncertainty calibration for the prediction. In addition, when the network width of a BDL model goes to infinity, the model performs equivalent to Gaussian Process (GP). This special class of BDL, known as Neural Network Gaussian Process (NNGP), inherits the advantages of the Bayesian approach while keeping universal approximation of neural network, and can utilize a much larger model space to model distribution-free data as a nonparametric model. We show that our uncertainty-aware NNGP estimator achieves high accuracy, can be built very fast, and is robust to query workload shift, in our extensive performance studies by comparing with the existing approaches."
      }
    }
  },
  "Zero-Shot Cost Models for Out-of-the-box Learned Cost Prediction.pdf.json": {
    "metadata": {
      "paper_id": "132",
      "pdf_filename": "Zero-Shot Cost Models for Out-of-the-box Learned Cost Prediction.pdf",
      "title": "Zero-shot cost models for out-of-the-box learned cost prediction",
      "authors": "Benjamin Hilprecht, Carsten Binnig",
      "year": "2022"
    },
    "answers": {
      "Q1": {
        "QuestionText": "Does the study provide any new definitions for robustness?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "No",
        "Reasoning": "The study discusses the robustness of zero-shot models in Section 4, where it defines robustness in terms of the model's ability to generalize to unseen databases and workloads, and how to estimate the generalization performance.",
        "Evidence": "An important question for zero-shot models is at which point a sufficient amount of different training databases (and workloads) was observed to generalize robustly to unseen databases. As discussed in Section 2.3, a minimum requirement is to have sufficient coverage of the training data for the expected queries in the evaluation workload."
      },
      "Q2": {
        "QuestionText": "How does the study define robustness or risk (implicitly or explicitly)?",
        "ShortAnswer": "Unsure",
        "correct_short_answer": "Not provided",
        "Reasoning": "The provided text does not explicitly define robustness or risk. While the text discusses the robustness of zero-shot cost models in various contexts, it does not provide a concise definition of these terms.",
        "Evidence": "None"
      },
      "Q3": {
        "QuestionText": "If a new definition is provided, to which scope does it apply?",
        "ShortAnswer": "No Definitions Provided",
        "correct_short_answer": "No Definitions Provided",
        "Reasoning": "The text does not provide any new definitions for the terms mentioned.",
        "Evidence": "The text discusses various aspects of zero-shot cost models, including their design, training, and evaluation, but it does not introduce new definitions for terms like join ordering, cardinality estimation, cost model, plan optimization, workload management, DBMS (end-to-end), or ML models."
      },
      "Q4": {
        "QuestionText": "Does the study address the problem of robustness in the context of query optimization and processing?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "",
        "Reasoning": "The study explicitly discusses the robustness of zero-shot cost models in the context of query optimization and processing. It mentions that zero-shot models can generalize to unseen query patterns and that the performance of these models will degrade if there are extreme differences between training and test workloads. The study also proposes strategies to detect and mitigate such cases by fine-tuning a zero-shot model.",
        "Evidence": "Furthermore, while zero-shot cost models can generalize to unseen query patterns as we show in our experiments, it is clearly required that the training queries have a certain coverage, i.e., come with a diverse set of workloads and databases. For instance, it is a minimum requirement that every physical operator is observed in the training data s.t. the model can internalize the overall characteristics. Moreover, if there are extreme differences between training and test workloads, we expect the zero-shot model accuracy to degrade. We discuss how to detect and mitigate such cases by fine-tuning a zero-shot model in Section 4."
      },
      "Q5": {
        "QuestionText": "Does the study have a significant contribution to the theory?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study introduces a new learning paradigm for cost estimation called zero-shot cost models, which reduces the high efforts associated with workload-driven learning. This paradigm is motivated by recent advances in transfer learning of machine learning models. The study proposes a new query and data representation that allows zero-shot cost models to be pre-trained across databases, making it a significant contribution to the theory.",
        "Evidence": "Contributions. In this paper, we thus suggest a new learning paradigm for cost estimation called zero-shot cost models that reduces these high efforts. The general idea behind zero-shot cost models is motivated by recent advances in transfer learning of machine learning models. While a wide spectrum of methods have been proposed already to tackle zero-shot learning in domains such as NLP [3] or computer vision [15], no approaches for zero-shot learning exist for learned DBMS components and in particular also for cost models. To enable this, as a core contribution in this paper, we propose a new query and data representation that allows zero-shot cost models to be pre-trained across databases and thus be"
      },
      "Q6": {
        "QuestionText": "Does the study include a significant experimental evaluation?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The text explicitly mentions an extensive experimental evaluation in Section 6, where various experiments are conducted to evaluate zero-shot cost estimation. This includes experiments on accuracy on unseen databases, comparison with workload-driven approaches, generalization under workload drifts, training and inference performance, and ablation studies.",
        "Evidence": "In this Section, we evaluate zero-shot cost estimation with a set of different experiments: \u2022 Exp1. Zero-Shot Accuracy on Unseen Databases. We evaluate how accurately zero-shot cost models can predict costs for unseen databases. \u2022 Exp2. Zero-Shot vs. Workload-Driven. In addition, we compare the training overhead and accuracy with state-of-the-art workload-driven approaches. \u2022 Exp3. Generalization. In this experiment, we study how our models generalize under workload drifts (i.e., under data-base updates and larger unseen joins). \u2022 Exp 4. Training and Inference Performance. Furthermore, we evaluate the training and inference performance of zero-shot cost models and compare training efforts to workload-driven models. \u2022 Exp5. Ablation Studies. Finally, we show the effects of different design alternatives of zero-shot models as well as a study where we determine how many databases are sufficient for zero-shot cost models to generalize."
      },
      "Q7": {
        "QuestionText": "How does the study evaluate robustness and its improvements?",
        "ShortAnswer": "experimental evaluation",
        "correct_short_answer": "experimental evaluation",
        "Reasoning": "The study evaluates robustness and its improvements through experimental evaluation. It conducts experiments to assess the accuracy of zero-shot cost models on unseen databases, compares them with workload-driven approaches, and studies their generalization under workload drifts. Additionally, the study includes ablation studies to determine the effects of different design alternatives and the number of databases sufficient for generalization.",
        "Evidence": "In this Section, we evaluate zero-shot cost estimation with a set of different experiments: \u2022 Exp1. Zero-Shot Accuracy on Unseen Databases. We evaluate how accurately zero-shot cost models can predict costs for unseen databases. \u2022 Exp2. Zero-Shot vs. Workload-Driven. In addition, we compare the training overhead and accuracy with state-of-the-art workload-driven approaches. \u2022 Exp3. Generalization. In this experiment, we study how our models generalize under workload drifts (i.e., under data-base updates and larger unseen joins). \u2022 Exp 4. Training and Inference Performance. Furthermore, we evaluate the training and inference performance of zero-shot cost models and compare training efforts to workload-driven models. \u2022 Exp5. Ablation Studies. Finally, we show the effects of different design alternatives of zero-shot models as well as a study where we determine how many databases are sufficient for zero-shot cost models to generalize."
      },
      "Q9": {
        "QuestionText": "How does the study improve robustness?",
        "ShortAnswer": "a summary of the proposed approach",
        "correct_short_answer": "The study improves robustness by introducing zero-shot cost models that pre-train on a variety of databases using a transferable graph-based query representation, separate database-dependent characteristics (e.g., cardinalities, tuple widths) as explicit inputs, and support few-shot fine-tuning on a small number of queries for new databases.",
        "Reasoning": "The study introduces zero-shot cost models that can generalize across different databases without requiring query executions on unseen databases. This is achieved through a new model architecture and representation technique that allows the model to capture subtle interactions in operator performance and characteristics of new databases more accurately than simplistic cost models. The study also demonstrates that zero-shot models can handle workload and data drifts, and can be fine-tuned with a few additional training queries to further improve performance.",
        "Evidence": "The study improves robustness by introducing zero-shot cost models that can generalize across different databases without requiring query executions on unseen databases. This is achieved through a new model architecture and representation technique that allows the model to capture subtle interactions in operator performance and characteristics of new databases more accurately than simplistic cost models. The study also demonstrates that zero-shot models can handle workload and data drifts, and can be fine-tuned with a few additional training queries to further improve performance."
      },
      "Q10": {
        "QuestionText": "What measures are used to evaluate robustness (implicitly or explicitly)?",
        "ShortAnswer": [
          "median Q-error",
          "generalization error",
          "testerror",
          "95th percentile Q-error",
          "maximum Q-error"
        ],
        "correct_short_answer": [
          "median Q-error",
          "95th percentile Q-error",
          "maximum Q-error",
          "generalization error"
        ],
        "Reasoning": "The study uses several measures to evaluate robustness, including median Q-error, generalization error, testerror, 95th percentile Q-error, and maximum Q-error. These measures are used to assess the accuracy and generalization performance of zero-shot cost models across different databases and workloads.",
        "Evidence": "The study uses several measures to evaluate robustness, including median Q-error, generalization error, testerror, 95th percentile Q-error, and maximum Q-error."
      },
      "Q11": {
        "QuestionText": "Which benchmarks are used in the experimental evaluations?",
        "ShortAnswer": [
          "JOB",
          "JOB-light",
          "SSB",
          "TPC-H",
          "IMDB",
          "Movielens",
          "Airline",
          "Accidents",
          "Baseball",
          "Basketball",
          "Carcinogenesis",
          "Consumer",
          "Credit",
          "Employee",
          "Fhnk",
          "Financial",
          "Geneea",
          "Genome",
          "Hepatitis",
          "Seznam",
          "Tournament",
          "Walmart"
        ],
        "correct_short_answer": [
          "JOB",
          "JOB-light",
          "SSB",
          "TPC-H",
          "IMDB",
          "Movielens",
          "Airline",
          "Accidents",
          "Baseball",
          "Basketball",
          "Carcinogenesis",
          "Consumer",
          "Credit",
          "Employee",
          "Fhnk",
          "Financial",
          "Geneea",
          "Genome",
          "Hepatitis",
          "Seznam",
          "Tournament",
          "Walmart"
        ],
        "Reasoning": "The study uses a variety of benchmarks to evaluate the performance of zero-shot cost models. These benchmarks include well-known datasets like JOB, JOB-light, SSB, TPC-H, IMDB, Movielens, and others. These benchmarks cover a wide range of database types and workloads, providing a comprehensive evaluation of the models' robustness and generalization capabilities.",
        "Evidence": "The study uses a variety of benchmarks to evaluate the performance of zero-shot cost models. These benchmarks include well-known datasets like JOB, JOB-light, SSB, TPC-H, IMDB, Movielens, and others."
      },
      "Q12": {
        "QuestionText": "Is the used benchmark real or synthetic?",
        "ShortAnswer": "Both",
        "correct_short_answer": "Both",
        "Reasoning": "The text mentions that the benchmark includes both real-world datasets and synthetic datasets. For example, it includes real-world datasets such as IMDB and synthetic datasets such as TPC-H and SSB.",
        "Evidence": "As discussed before, it is insufficient to just add synthetic datasets since correlations hardly resembled at a distributions found in the real-world. We thus decided to leverage publicly available real-world datasets [25] together with the datasets used in established benchmarks such as JOB. Since certain databases were very small in size, we additionally scaled them to larger sizes to be interesting for cost estimation (s.t. a sample of queries takes a predefined threshold of time). In addition to the datasets mentioned before, we also included data and workloads of existing benchmarks such as SSB and TPC-H. As these benchmarks rely on synthetic data, this further increases the variety of data characteristics our benchmark covers."
      },
      "Q13": {
        "QuestionText": "What characteristics are controlled in trianing data, query, or plan generation?",
        "ShortAnswer": [
          "number of pages",
          "number of tuples",
          "number of rows",
          "output cardinalities of operators",
          "tuple width",
          "attribute correlation with row number",
          "data type of column",
          "number of distinct attribute values",
          "fraction of NULL values",
          "intermediate cardinalities",
          "predicate operator type",
          "literal complexity",
          "complexity of the predicate",
          "estimated output cardinality of operator",
          "width in bytes",
          "cardinality estimates",
          "card product",
          "aggregation type"
        ],
        "correct_short_answer": [
          "schema diversity across 20 heterogeneous databases",
          "join complexity (controlled number of relations per query)",
          "aggregation and group-by complexity (varying counts of aggregates and group-bys)",
          "predicate complexity (conjunctive vs. disjunctive, regex, IN, IS NULL)",
          "literal complexity (e.g. size of IN-lists, regex depth)",
          "physical design variability (randomly created/dropped indexes)",
          "execution-time filtering (excluding queries > 30 seconds)",
          "workload volume per database (15000 queries generated/executed)",
          "operator coverage (ensuring each physical operator appears at least once)",
          "benchmark integration (including JOB, JOB-light, SSB, TPC-H alongside custom workloads)"
        ],
        "Reasoning": "The study controls a variety of characteristics in the training data, query, and plan generation to evaluate the performance of zero-shot cost models. These characteristics include aspects related to data size, operator performance, data types, and query complexity.",
        "Evidence": "The study controls a variety of characteristics in the training data, query, and plan generation to evaluate the performance of zero-shot cost models. These characteristics include aspects related to data size, operator performance, data types, and query complexity."
      },
      "Q14": {
        "QuestionText": "Are the experiments designed to evaluate robustness specifically?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The experiments are specifically designed to evaluate the robustness of zero-shot cost models. The study includes experiments that assess the models' accuracy on unseen databases, their generalization under workload drifts, and their performance compared to workload-driven approaches. These experiments aim to demonstrate the models' ability to handle various challenges and maintain robust performance.",
        "Evidence": "In this Section, we evaluate zero-shot cost estimation with a set of different experiments: \u2022 Exp1. Zero-Shot Accuracy on Unseen Databases. We evaluate how accurately zero-shot cost models can predict costs for unseen databases. \u2022 Exp2. Zero-Shot vs. Workload-Driven. In addition, we compare the training overhead and accuracy with state-of-the-art workload-driven approaches. \u2022 Exp3. Generalization. In this experiment, we study how our models generalize under workload drifts (i.e., under data-base updates and larger unseen joins). \u2022 Exp 4. Training and Inference Performance. Furthermore, we evaluate the training and inference performance of zero-shot cost models and compare training efforts to workload-driven models. \u2022 Exp5. Ablation Studies. Finally, we show the effects of different design alternatives of zero-shot models as well as a study where we determine how many databases are sufficient for zero-shot cost models to generalize."
      },
      "Q15": {
        "QuestionText": "Does the study use machine learning in its proposed approach?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The paper mentions 'machine learning (ML) has thus been used for learned cost models' and discusses the use of neural models and other ML techniques throughout the text.",
        "Evidence": "page_label: 0, page_label: 3, page_label: 10"
      },
      "Q16": {
        "QuestionText": "What type of machine learning is used?",
        "ShortAnswer": "Supervised",
        "correct_short_answer": "Supervised",
        "Reasoning": "The paper mentions 'trained in a supervised fashion using pairs (\ud835\udc43,\ud835\udc50) that consist of a plan \ud835\udc43 with the respective features and the actual runtime cost \ud835\udc50'.",
        "Evidence": "As mentioned before, a zero-shot cost model is trained on several databases and queries to learn the runtime complexity of query plans given the input features. To be more precise, a zero-shot cost model is trained in a supervised fashion using pairs (\ud835\udc43,\ud835\udc50) that consist of a plan \ud835\udc43 with the respective features and the actual runtime cost \ud835\udc50."
      },
      "Q17": {
        "QuestionText": "To which category does the ML approach belong?",
        "ShortAnswer": "Regression",
        "correct_short_answer": "Regression",
        "Reasoning": "The paper discusses the use of a zero-shot cost model to predict query runtimes, which is a regression task. The model is trained to estimate continuous values (query runtimes) based on input features.",
        "Evidence": "In particular, a zero-shot cost model is trained in a supervised fashion using pairs (\ud835\udc43,\ud835\udc50) that consist of a plan \ud835\udc43 with the respective features and the actual runtime cost \ud835\udc50."
      },
      "Q18": {
        "QuestionText": "Does the approach use deep learning?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The paper mentions the use of 'neural models' and 'Multi-Layer Perceptrons (MLPs)' which are components of deep learning.",
        "Evidence": "For instance, to encode filter predicates, different from previous approaches we encode the predicate structure as nodes (red) without literals. In particular, we encode information such as data types and comparison operators used in a predicate. ... Afterwards, the resulting feature vectors of the nodes are fed into node-type-specific Multi-Layer Perceptrons (MLPs) to obtain a hidden state, which is (3) propagated through the query-tree using bottom-up message passing to account for interactions among connected nodes. (4) Finally, the hidden state of the root node (encoding the entire graph) is fed into a final model\u2014the estimation MLP\u2014which predicts the query runtime."
      },
      "Q19": {
        "QuestionText": "Does the approach use transfer learning?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The text explicitly mentions 'transfer learning' and discusses how the zero-shot cost models are motivated by recent advances in transfer learning of machine learning models.",
        "Evidence": "While a wide spectrum of methods have been proposed already to tackle zero-shot learning in domains such as NLP [3] or computer vision [15], no approaches for zero-shot learning exist for learned DBMS components and in particular also for cost models."
      },
      "Q20": {
        "QuestionText": "How does the study generate its training data?",
        "ShortAnswer": "a description of the data generation process",
        "correct_short_answer": "The study generate its training data by running 15000 generated queries per database, using a workload generator (SPAJ, complex, and index modes) on Postgres v12, to collect plans and actual runtimes across 20 databases.",
        "Reasoning": "The text mentions that 'workload execution is required to gather the training data, which can take hours (or days) since tens of thousands of queries need to be executed on potentially large databases.' This indicates that the training data is generated through the execution of queries.",
        "Evidence": "In Figure 1, we show the cost estimation accuracy depending on how many hours we allow for gathering the training data for a workload-driven model. As we can see, even for a medium-sized database such as IMDB, it takes more than 5 hours of running queries on this database to gather enough training data such that the cost estimation model can provide a decent accuracy."
      },
      "Q21": {
        "QuestionText": "How does the study encode the samples?",
        "ShortAnswer": "a description of the encoding process",
        "correct_short_answer": "The study encode the samples as graphs where nodes represent operators, tables, columns, and predicates annotated with transferable features, processed via node-type MLPs and bottom-up message passing (in GNN).",
        "Reasoning": "The text describes the encoding process in detail, explaining how the query plan is represented as a graph with different node types and how these nodes are annotated with transferable features. It then explains the use of MLPs and message passing to encode the graph and predict the query runtime.",
        "Evidence": "Figure3:UsingZero-ShotModelsforCostEstimation(i.e.,forInference)onanunseenDatabase.(1)Aqueryisrepresentedasagraphwithdifferentnodetypes(torepresentplanoperators,predicates,tables,columnsetc.)andnodesareannotatedwithtransferablefeatures,whichgeneralizeacrossdatabases.(2)Afterwards,theresultingfeaturevectorsofthenodesarefedinto node-type-specificMulti-Layer-Perceptrons(MLPs)toobtainahiddenstate,whichis(3)propagatedthroughthequery-treeusingbottom-upmessagepassingtoaccountforinteractionsamongconnectednodes.(4)Finally,thehiddenstateoftherootnode(encodingtheentiregraph)isfedintoafinalmodel\u2014theestimationMLP\u2014whichpredictsthequeryruntime."
      },
      "Q22": {
        "QuestionText": "Does the study account for predictive uncertainties?",
        "ShortAnswer": "Unsure",
        "correct_short_answer": "No",
        "Reasoning": "The text does not explicitly mention whether the study accounts for predictive uncertainties.",
        "Evidence": "Not Applicable"
      },
      "Q23": {
        "QuestionText": "Does the study recognize generalization to out-of-distribution as a criterion for robustness?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The study mentions that 'the zero-shot model can still predict costs relatively accurately for cases close to training data examples (e.g., five aggregates instead of one) the performance degrades as the characteristics are further changed.' This indicates that the study recognizes generalization to out-of-distribution as a criterion for robustness.",
        "Evidence": "the zero-shot model can still predict costs relatively accurately for cases close to training data examples (e.g., five aggregates instead of one) the performance degrades as the characteristics are further changed."
      },
      "Q24": {
        "QuestionText": "Does it evaluate generalization to out-of-distribution?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "Yes",
        "Reasoning": "The paper discusses the generalization performance of zero-shot cost models and how they can predict query runtimes on unseen databases. It mentions the use of statistical techniques to estimate the generalization error, which is the expected error for future unseen datasets. The paper also discusses how the model can estimate how accurate the model is expected to be on an unseen database, which is an unbiased estimator of the test error under the independent identically distributed (i.i.d.) assumption.",
        "Evidence": "In order to now evaluate whether the model has observed a sufficient amount of databases and workloads, we can use two techniques. First, we can simply estimate the generalization error as described above and stop the training if it is sufficient. However, in this case we have to decide which generalization error is acceptable. A second technique (which we actually use in this paper) is to estimate if additional training databases will improve the generalization performance. For this, we train the model on subsets of all training databases. If the estimated generalization error \ud835\udc38(\ud835\udc47\u2217) does not improve significantly for a larger number of training databases, we can conclude that additional databases will not improve the generalization capabilities of the zero-shot cost model and thus stop the training data collection."
      },
      "Q25": {
        "QuestionText": "What model architecture is used in the proposed method? Do not include model architectures used only as a baseline.",
        "ShortAnswer": [
          "Multi-layer Perceptron (MLP)",
          "Graph Neural Network (GNN)"
        ],
        "correct_short_answer": [
          "Multi-layer Perceptron (MLP)",
          "Graph Neural Network (GNN)"
        ],
        "Reasoning": "The text describes the use of Multi-Layer Perceptrons (MLPs) and a graph-based approach for encoding the query plan and predicting the query runtime. The query plan is represented as a graph with different node types, and the resulting feature vectors of the nodes are fed into node-type-specific MLPs to obtain a hidden state. This hidden state is then propagated through the query-tree using bottom-up message passing to account for interactions among connected nodes. Finally, the hidden state of the root node is fed into a final model\u2014the estimation MLP\u2014which predicts the query runtime.",
        "Evidence": "Figure3:UsingZero-ShotModelsforCostEstimation(i.e.,forInference)onanunseenDatabase.(1)Aqueryisrepresentedasagraphwithdifferentnodetypes(torepresentplanoperators,predicates,tables,columnsetc.)andnodesareannotatedwithtransferablefeatures,whichgeneralizeacrossdatabases.(2)Afterwards,theresultingfeaturevectorsofthenodesarefedinto node-type-specificMulti-Layer-Perceptrons(MLPs)toobtainahiddenstate,whichis(3)propagatedthroughthequery-treeusingbottom-upmessagepassingtoaccountforinteractionsamongconnectednodes.(4)Finally,thehiddenstateoftherootnode(encodingtheentiregraph)isfedintoafinalmodel\u2014theestimationMLP\u2014whichpredictsthequeryruntime."
      },
      "Q26": {
        "QuestionText": "Was enhancing robustness the primary motivation behind the model or encoding scheme design?",
        "ShortAnswer": "Yes",
        "correct_short_answer": "",
        "Reasoning": "The paper discusses the need for zero-shot cost models to generalize robustly to unseen databases and workloads. The design of the model and encoding scheme is aimed at achieving this robustness.",
        "Evidence": "An important question for zero-shot models is at which point a sufficient amount of different training databases (and workloads) was observed to generalize robustly to unseen databases. As discussed in Section 2.3, a minimum requirement is to have sufficient coverage of the training data for the expected queries in the evaluation workload."
      },
      "Q27": {
        "QuestionText": "Does it use any other techniques for improving robustness?",
        "ShortAnswer": [
          "fine-tuning",
          "transferable features",
          "message passing",
          "bottom-up message passing",
          "estimation of generalization error",
          "estimation of test error"
        ],
        "correct_short_answer": [
          "separation of concerns by providing explicit database characteristics as model inputs",
          "fallback to traditional or data-driven cardinality estimates when needed",
          "estimating generalization error via cross-database validation",
          "monitoring test error during inference to detect workload drifts",
          "few-shot fine-tuning on a small set of observed queries",
          "transfer learning through a pre-trained, transferable graph-based query representation"
        ],
        "Reasoning": "The paper mentions several techniques used to improve robustness, including fine-tuning the zero-shot model with a few additional training queries, using transferable features that generalize across databases, and employing message passing to account for interactions among connected nodes in the query plan. Additionally, the paper discusses estimating the generalization error and test error to evaluate the model's performance on unseen databases.",
        "Evidence": "Furthermore, while zero-shot cost models can generalize to unseen query patterns as we show in our experiments, it is clearly required that the training queries have a certain coverage, i.e., come with a diverse set of workloads and databases. For instance, it is a minimum requirement that every physical operator is observed in the training data s.t. the model can internalize the overall characteristics. Moreover, if there are extreme differences between training and test workloads, we expect the zero-shot model accuracy to degrade. We discuss how to detect and mitigate such cases by fine-tuning a zero-shot model in Section 4."
      }
    }
  }
}
